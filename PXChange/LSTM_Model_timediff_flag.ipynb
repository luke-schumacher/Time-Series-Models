{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow.keras.backend as K\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data Loaded:\n",
      "   SeqOrder  sourceID  timediff     PTAB  BodyGroup_from  BodyGroup_to\n",
      "0         0      10.0       0.0 -1182200               9             9\n",
      "1         1       0.0      40.0 -1182200               9             9\n",
      "2         2       4.0      45.0 -1181050               9             9\n",
      "3         3       5.0      52.0 -1181050               9             9\n",
      "4         4       5.0      68.0 -1181050               9             9\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "data = pd.read_csv('encoded_182625.csv')\n",
    "print(\"Original Data Loaded:\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print unique values to inspect for unexpected cases\n",
    "print(\"Unique sourceID values:\", data['sourceID'].unique())\n",
    "print(\"Unique BodyGroup_from values:\", data['BodyGroup_from'].unique())\n",
    "print(\"Unique BodyGroup_to values:\", data['BodyGroup_to'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure sourceID is string for mapping (if not already)\n",
    "data['sourceID'] = data['sourceID'].astype(str)\n",
    "\n",
    "# Provided encoding legends (as per your updated mapping)\n",
    "sourceID_mapping = {\n",
    "    'Not Vital': 0, 'MRI_CCS_11': 1, 'MRI_EXU_95': 2, 'MRI_FRR_18': 3,\n",
    "    'MRI_FRR_257': 4, 'MRI_FRR_264': 5, 'MRI_FRR_3': 6, 'MRI_FRR_34': 7,\n",
    "    'MRI_MPT_1005': 8, 'MRI_MSR_100': 9, 'MRI_MSR_104': 10, 'MRI_MSR_21': 11, 'MRI_MSR_34': 12\n",
    "}\n",
    "\n",
    "BODYGROUP_ENCODING = {\n",
    "    'ABDOMEN': 1, 'ARM': 2, 'HEAD': 3, 'HEART': 4, 'HIP': 5,\n",
    "    'KNEE': 6, 'LEG': 7, 'PELVIS': 8, 'SHOULDER': 9, 'SPINE': 10\n",
    "}\n",
    "\n",
    "# Encode categorical features using the mappings\n",
    "data['sourceID_encoded'] = data['sourceID'].map(sourceID_mapping)\n",
    "data['BodyGroup_from_encoded'] = data['BodyGroup_from'].map(BODYGROUP_ENCODING)\n",
    "data['BodyGroup_to_encoded'] = data['BodyGroup_to'].map(BODYGROUP_ENCODING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_seq: (3790, 10, 5)\n",
      "Shape of y_seq: (3790,)\n"
     ]
    }
   ],
   "source": [
    "# Prepare input (X) and output (y) using encoded values\n",
    "# Leaving numeric features (PTAB and SeqOrder) in their original scale.\n",
    "X = data[['sourceID_encoded', 'PTAB', 'BodyGroup_from_encoded', 'BodyGroup_to_encoded', 'SeqOrder']].values\n",
    "y = data['timediff'].values\n",
    "\n",
    "# Create sequences for sequential processing\n",
    "sequence_length = 10  # number of past steps used per prediction\n",
    "X_seq, y_seq = [], []\n",
    "for i in range(len(X) - sequence_length):\n",
    "    X_seq.append(X[i:i+sequence_length])\n",
    "    # Here, summing the target values over the sequence window; change if needed.\n",
    "    y_seq.append(np.sum(y[i:i+sequence_length]))\n",
    "\n",
    "X_seq, y_seq = np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "print(\"Shape of X_seq:\", X_seq.shape)\n",
    "print(\"Shape of y_seq:\", y_seq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (2274, 10, 5) (2274,)\n",
      "Validation set shape: (568, 10, 5) (568,)\n",
      "Test set shape: (948, 10, 5) (948,)\n"
     ]
    }
   ],
   "source": [
    "# Split dataset\n",
    "indices = np.arange(len(X_seq))\n",
    "train_indices, temp_indices = train_test_split(indices, test_size=0.4, random_state=42)\n",
    "val_indices, test_indices = train_test_split(temp_indices, test_size=0.625, random_state=42)\n",
    "\n",
    "X_train, y_train = X_seq[train_indices], y_seq[train_indices]\n",
    "X_val, y_val = X_seq[val_indices], y_seq[val_indices]\n",
    "X_test, y_test = X_seq[test_indices], y_seq[test_indices]\n",
    "\n",
    "print(\"Training set shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Validation set shape:\", X_val.shape, y_val.shape)\n",
    "print(\"Test set shape:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom loss function (if required)\n",
    "def custom_loss(y_true, y_pred):\n",
    "    mse_loss = K.mean(K.square(y_true - y_pred))\n",
    "    zero_penalty = K.sum(K.square(y_pred) * K.cast(K.equal(y_true, 0), K.floatx()))\n",
    "    return mse_loss + zero_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any NaNs in features?  11400\n",
      "Any NaNs in target?  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Any NaNs in features? \", np.isnan(X).sum())\n",
    "print(\"Any NaNs in target? \", np.isnan(y).sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 12/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
      "Epoch 13/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 14/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 15/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 16/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 17/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 18/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 19/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 20/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 21/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 22/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 23/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
      "Epoch 24/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 25/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 26/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 27/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 28/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 29/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 30/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 31/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 32/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 33/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 34/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 35/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 36/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 37/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 38/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 39/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 40/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 41/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 42/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 43/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 44/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 45/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 46/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 47/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 48/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 49/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 50/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 51/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 52/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 53/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 54/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 55/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 56/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 57/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 58/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 59/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 60/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 61/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 62/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 63/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 64/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 65/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 66/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 67/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 68/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 69/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 70/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 71/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 72/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 73/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 74/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 75/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 76/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 77/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 78/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 79/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 80/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 81/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 82/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 83/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 84/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 85/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 86/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 87/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 88/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 89/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 90/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 91/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 92/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 93/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 94/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 95/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 96/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 97/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 98/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 99/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 100/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n"
     ]
    }
   ],
   "source": [
    "# Build the LSTM model\n",
    "model = Sequential([\n",
    "    Input(shape=(X_train.shape[1], X_train.shape[2])),  # (sequence_length, num_features)\n",
    "    LSTM(64, activation='relu', return_sequences=True),\n",
    "    Dropout(0.3),\n",
    "    LSTM(32, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "# You can adjust the learning rate if needed; here we use 0.01 as in your original code.\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_val, y_val),\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: nan\n",
      "\n",
      "Test Loss: nan\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Save the model (optional)\n",
    "model.save('trained_model.h5')\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss = model.evaluate(X_test, y_test)\n",
    "print(f\"\\nTest Loss: {test_loss}\")\n",
    "\n",
    "# Visualize training and validation loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot convert float NaN to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [36]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Decode sourceIDs for readability using the inverse of the mapping:\u001b[39;00m\n\u001b[0;32m      8\u001b[0m inv_sourceID_mapping \u001b[38;5;241m=\u001b[39m {v: k \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m sourceID_mapping\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m----> 9\u001b[0m decoded_sourceIDs \u001b[38;5;241m=\u001b[39m [inv_sourceID_mapping[\u001b[38;5;28mint\u001b[39m(data\u001b[38;5;241m.\u001b[39mloc[idx, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msourceID_encoded\u001b[39m\u001b[38;5;124m'\u001b[39m])] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m test_indices]\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Combine predictions with sourceIDs\u001b[39;00m\n\u001b[0;32m     12\u001b[0m results_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSourceID\u001b[39m\u001b[38;5;124m'\u001b[39m: decoded_sourceIDs,\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrue Timediff\u001b[39m\u001b[38;5;124m'\u001b[39m: y_test,\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPredicted Timediff\u001b[39m\u001b[38;5;124m'\u001b[39m: predictions\n\u001b[0;32m     16\u001b[0m })\n",
      "Input \u001b[1;32mIn [36]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Decode sourceIDs for readability using the inverse of the mapping:\u001b[39;00m\n\u001b[0;32m      8\u001b[0m inv_sourceID_mapping \u001b[38;5;241m=\u001b[39m {v: k \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m sourceID_mapping\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m----> 9\u001b[0m decoded_sourceIDs \u001b[38;5;241m=\u001b[39m [inv_sourceID_mapping[\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msourceID_encoded\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m test_indices]\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Combine predictions with sourceIDs\u001b[39;00m\n\u001b[0;32m     12\u001b[0m results_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSourceID\u001b[39m\u001b[38;5;124m'\u001b[39m: decoded_sourceIDs,\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrue Timediff\u001b[39m\u001b[38;5;124m'\u001b[39m: y_test,\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPredicted Timediff\u001b[39m\u001b[38;5;124m'\u001b[39m: predictions\n\u001b[0;32m     16\u001b[0m })\n",
      "\u001b[1;31mValueError\u001b[0m: cannot convert float NaN to integer"
     ]
    }
   ],
   "source": [
    "# Make predictions on test set\n",
    "predictions = model.predict(X_test).flatten()\n",
    "\n",
    "# Enforce a zero constraint on predictions where y_test is zero\n",
    "predictions = np.where(y_test == 0, 0, predictions)\n",
    "\n",
    "# Decode sourceIDs for readability using the inverse of the mapping:\n",
    "inv_sourceID_mapping = {v: k for k, v in sourceID_mapping.items()}\n",
    "decoded_sourceIDs = [inv_sourceID_mapping[int(data.loc[idx, 'sourceID_encoded'])] for idx in test_indices]\n",
    "\n",
    "# Combine predictions with sourceIDs\n",
    "results_df = pd.DataFrame({\n",
    "    'SourceID': decoded_sourceIDs,\n",
    "    'True Timediff': y_test,\n",
    "    'Predicted Timediff': predictions\n",
    "})\n",
    "\n",
    "print(results_df.head())\n",
    "results_df.to_csv('initial_throwaway_predictions_results.csv', index=False)\n",
    "print(\"Results saved to initial_throwaway_predictions_results.csv\")\n",
    "\n",
    "# Plot true vs predicted values\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(y_test, label='True Values', marker='o')\n",
    "plt.plot(predictions, label='Predicted Values', marker='x')\n",
    "plt.title('True vs Predicted Timediff on Test Set')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Timediff')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Evaluate performance metrics\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "r2 = r2_score(y_test, predictions)\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"R-Squared (R²): {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Data Loaded:\n",
      "   SeqOrder     sourceID BodyGroup_from BodyGroup_to\n",
      "0         0  MRI_MSR_104        ABDOMEN      ABDOMEN\n",
      "1         1   MRI_MSR_21        ABDOMEN      ABDOMEN\n",
      "2         2  MRI_FRR_257        ABDOMEN      ABDOMEN\n",
      "3         3  MRI_FRR_264        ABDOMEN      ABDOMEN\n",
      "4         4    MRI_FRR_3        ABDOMEN      ABDOMEN\n"
     ]
    }
   ],
   "source": [
    "# Load new dataset\n",
    "df = pd.read_csv(\"predicSourceIDandBodyGroup_182625.csv\")\n",
    "\n",
    "print(\"New Data Loaded:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding legend\n",
    "ENCODING_LEGEND = {\n",
    "    'Not Vital': 0, 'MRI_CCS_11': 1, 'MRI_EXU_95': 2, 'MRI_FRR_18': 3, 'MRI_FRR_257': 4,\n",
    "    'MRI_FRR_264': 5, 'MRI_FRR_3': 6, 'MRI_FRR_34': 7, 'MRI_MPT_1005': 8,\n",
    "    'MRI_MSR_100': 9, 'MRI_MSR_104': 10, 'MRI_MSR_21': 11, 'MRI_MSR_34': 12\n",
    "}\n",
    "\n",
    "BODYGROUP_ENCODING = {\n",
    "    'ABDOMEN': 1, 'ARM': 2, 'HEAD': 3, 'HEART': 4, 'HIP': 5,\n",
    "    'KNEE': 6, 'LEG': 7, 'PELVIS': 8, 'SHOULDER': 9, 'SPINE': 10\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode sourceID and BodyGroup columns using predefined legends\n",
    "df['sourceID_encoded'] = df['sourceID'].map(ENCODING_LEGEND)\n",
    "df['BodyGroup_from_encoded'] = df['BodyGroup_from'].map(BODYGROUP_ENCODING)\n",
    "df['BodyGroup_to_encoded'] = df['BodyGroup_to'].map(BODYGROUP_ENCODING)\n",
    "\n",
    "# Ensure no NaNs exist (handle unknown sourceIDs or body groups)\n",
    "df['sourceID_encoded'].fillna(-1, inplace=True)  # Use -1 for unknown values\n",
    "df['BodyGroup_from_encoded'].fillna(0, inplace=True)\n",
    "df['BodyGroup_to_encoded'].fillna(0, inplace=True)\n",
    "\n",
    "# Convert to integer type after filling NaNs\n",
    "df['sourceID_encoded'] = df['sourceID_encoded'].astype(int)\n",
    "df['BodyGroup_from_encoded'] = df['BodyGroup_from_encoded'].astype(int)\n",
    "df['BodyGroup_to_encoded'] = df['BodyGroup_to_encoded'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New X shape: (1156, 1, 2)\n",
      "New y shape: (1156,)\n"
     ]
    }
   ],
   "source": [
    "# Create the reset_flag column (AFTER encoding)\n",
    "df['reset_flag'] = (df['sourceID_encoded'] == 10).astype(int)\n",
    "\n",
    "# Ensure timediff is exactly 0 where reset_flag is 1\n",
    "df.loc[df['reset_flag'] == 1, 'timediff'] = 0\n",
    "\n",
    "# Add PTAB column if missing\n",
    "if 'PTAB' not in df.columns:\n",
    "    df['PTAB'] = 0  # Use default 0 (or replace with training data mean)\n",
    "\n",
    "# Select the features for training\n",
    "X = df[['sourceID_encoded', 'reset_flag']].values.astype(np.float32)  # Convert to float32\n",
    "y = df['timediff'].values.astype(np.float32)  # Convert target to float32\n",
    "\n",
    "# Reshape X for LSTM (samples, time steps, features)\n",
    "X = X.reshape((X.shape[0], 1, X.shape[1]))  # Shape: (samples, 1 timestep, 2 features)\n",
    "\n",
    "print(\"New X shape:\", X.shape)  # Should be (samples, 1, 2)\n",
    "print(\"New y shape:\", y.shape)  # Should be (samples,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/20\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/20\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/20\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/20\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/20\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/20\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/20\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/20\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/20\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/20\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 12/20\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 13/20\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 14/20\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 15/20\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 16/20\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 17/20\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 18/20\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 19/20\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 20/20\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1740f1ce380>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define LSTM Model\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=64, return_sequences=True, input_shape=(1, 2)))  # 2 features\n",
    "model.add(LSTM(units=32, return_sequences=False))\n",
    "model.add(Dense(units=1, activation='linear'))  # Output layer\n",
    "\n",
    "#Compile Model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, y, epochs=20, batch_size=32, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Predictions: [ 111.975784   15.802075   93.0547     15.061905   15.061905  299.48364\n",
      "   15.061905   15.061905 1098.2986     15.061905  100.66293    15.061905\n",
      "   15.061905  945.35645  1569.008      15.061905  931.49133    15.061905\n",
      "   15.061905 1052.5536  ]\n",
      "Unique y values: [ 0. nan]\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model\n",
    "model.save(\"trained_lstm_model.h5\")\n",
    "\n",
    "# Load the trained model for inference\n",
    "model = load_model(\"trained_lstm_model.h5\")\n",
    "\n",
    "# Predict timediff\n",
    "df['Predicted_timediff'] = model.predict(X).flatten()\n",
    "print(\"Predictions:\", predictions[:20])  # See first few predictions\n",
    "\n",
    "\n",
    "print(\"Unique y values:\", np.unique(y))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated dataset with resets saved!\n"
     ]
    }
   ],
   "source": [
    "# Apply cumulative sum but reset when sourceID == 10\n",
    "cumulative_timediff = []\n",
    "current_sum = 0\n",
    "\n",
    "for i in range(len(df)):\n",
    "    if df.iloc[i]['sourceID_encoded'] == 10:  # Reset when sourceID is MSR_104\n",
    "        current_sum = 0\n",
    "        cumulative_timediff.append(0)  # Ensure exact 0 for sourceID 10\n",
    "    else:\n",
    "        current_sum += df.iloc[i]['Predicted_timediff']\n",
    "        cumulative_timediff.append(current_sum)\n",
    "\n",
    "# Update the dataframe with final cumulative values\n",
    "df['Cumulative_timediff'] = cumulative_timediff\n",
    "\n",
    "# Save the updated dataset\n",
    "df.to_csv('new_data_with_reset_predictions_flag_test.csv', index=False)\n",
    "print(\"Updated dataset with resets saved!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
