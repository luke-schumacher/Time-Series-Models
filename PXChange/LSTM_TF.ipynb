{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "import os # For checking file existence\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler # For target scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Constants and Configuration ---\n",
    "\n",
    "MAX_SEQ_LEN = 128\n",
    "# --- UPDATED FEATURES ---\n",
    "# Give the model more context by including the sourceID and step number.\n",
    "FEATURE_COLUMNS = ['predicted_proportion', 'sourceID', 'Step']\n",
    "\n",
    "# --- 2. Data Loading and Preparation for LSTM ---\n",
    "\n",
    "def load_and_prepare_data(file_path):\n",
    "    \"\"\"\n",
    "    Loads proportion data, determines the true total time for each sequence\n",
    "    using the final cumulative timediff, and prepares data for the LSTM.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"❌ Error: Predictions file not found at '{file_path}'\")\n",
    "        return None, None, None\n",
    "\n",
    "    df = pd.read_csv(file_path)\n",
    "    df['true_total_time'] = df.groupby('SeqOrder')['timediff'].transform('max')\n",
    "\n",
    "    grouped = df.groupby('SeqOrder')\n",
    "    sequences = []\n",
    "    total_times = []\n",
    "    \n",
    "    print(f\"Processing {len(grouped)} sequences for the LSTM model...\")\n",
    "    for _, group in grouped:\n",
    "        sequences.append(group[FEATURE_COLUMNS].values)\n",
    "        total_times.append(group['true_total_time'].iloc[0])\n",
    "\n",
    "    return sequences, np.array(total_times), df\n",
    "\n",
    "# --- 3. LSTM Model Architecture (Improved) ---\n",
    "\n",
    "def build_lstm_model(input_shape):\n",
    "    \"\"\"\n",
    "    Builds a more powerful LSTM model for total time prediction.\n",
    "    \"\"\"\n",
    "    inputs = layers.Input(shape=(None, input_shape[-1]))\n",
    "    masking = layers.Masking(mask_value=0.0)(inputs)\n",
    "    # Increased complexity to capture non-linear patterns\n",
    "    lstm1 = layers.LSTM(64, return_sequences=True)(masking)\n",
    "    lstm2 = layers.LSTM(32, return_sequences=False)(lstm1)\n",
    "    # Dropout helps prevent overfitting\n",
    "    dropout = layers.Dropout(0.2)(lstm2)\n",
    "    dense1 = layers.Dense(16, activation='relu')(dropout)\n",
    "    outputs = layers.Dense(1)(dense1)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "# --- 4. Visualization Function ---\n",
    "\n",
    "def create_visualizations(history, results_df):\n",
    "    \"\"\"\n",
    "    Generates and saves plots for model analysis for ALL sequences.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Generating Visualizations ---\")\n",
    "    \n",
    "    output_plot_dir = 'sequence_plots'\n",
    "    os.makedirs(output_plot_dir, exist_ok=True)\n",
    "    \n",
    "    # Plot 1: Training & Validation Loss (Global)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Model Training and Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss (MSE)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig('training_loss_plot.png')\n",
    "    print(\"✅ Saved training loss plot.\")\n",
    "    plt.close()\n",
    "\n",
    "    all_seq_orders = results_df['SeqOrder'].unique()\n",
    "    print(f\"Generating comparison plots for {len(all_seq_orders)} sequences...\")\n",
    "\n",
    "    for seq_order in all_seq_orders:\n",
    "        sample_df = results_df[results_df['SeqOrder'] == seq_order]\n",
    "\n",
    "        # Plot 2: Cumulative Time Comparison\n",
    "        plt.figure(figsize=(12, 7))\n",
    "        plt.plot(sample_df['Step'], sample_df['timediff'], label='True Cumulative Time', marker='o')\n",
    "        plt.plot(sample_df['Step'], sample_df['predicted_cumulative_time'], label='Predicted Cumulative Time', marker='x', linestyle='--')\n",
    "        plt.title(f'Cumulative Time Comparison for Sequence {seq_order}')\n",
    "        plt.xlabel('Step in Sequence')\n",
    "        plt.ylabel('Time (seconds)')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.savefig(os.path.join(output_plot_dir, f'cumulative_time_comparison_seq_{seq_order}.png'))\n",
    "        plt.close()\n",
    "        \n",
    "        # Plot 3: Time Increment Comparison\n",
    "        true_increments = sample_df['timediff'].diff().fillna(sample_df['timediff'].iloc[0])\n",
    "        plt.figure(figsize=(12, 7))\n",
    "        plt.plot(sample_df['Step'], true_increments, label='True Time Increment', marker='o')\n",
    "        plt.plot(sample_df['Step'], sample_df['predicted_time_increment'], label='Predicted Time Increment', marker='x', linestyle='--')\n",
    "        plt.title(f'Time Increment Comparison for Sequence {seq_order}')\n",
    "        plt.xlabel('Step in Sequence')\n",
    "        plt.ylabel('Time (seconds)')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.savefig(os.path.join(output_plot_dir, f'time_increment_comparison_seq_{seq_order}.png'))\n",
    "        plt.close()\n",
    "\n",
    "    print(f\"✅ Saved individual sequence plots to the '{output_plot_dir}' directory.\")\n",
    "\n",
    "    # Plot 4: Total Time Prediction Analysis (Global)\n",
    "    total_time_analysis = results_df[['SeqOrder', 'true_total_time', 'predicted_total_time']].drop_duplicates()\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.scatter(total_time_analysis['true_total_time'], total_time_analysis['predicted_total_time'], alpha=0.6, label='Predictions')\n",
    "    plt.plot([0, total_time_analysis['true_total_time'].max()], [0, total_time_analysis['true_total_time'].max()], color='red', linestyle='--', label='Perfect Prediction Line')\n",
    "    plt.title('True vs. Predicted Total Time')\n",
    "    plt.xlabel('True Total Time (s)')\n",
    "    plt.ylabel('Predicted Total Time (s)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.axis('equal')\n",
    "    plt.savefig('total_time_prediction_analysis.png')\n",
    "    print(\"✅ Saved total time prediction analysis plot.\")\n",
    "    plt.close()\n",
    "\n",
    "# --- 5. Main Orchestration ---\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to run the data processing, training, and prediction.\"\"\"\n",
    "    \n",
    "    proportions_file = 'prediction_176401_proportions.csv'\n",
    "    output_file = 'predictions_total_time_176401.csv'\n",
    "    \n",
    "    sequences, total_times, original_df = load_and_prepare_data(proportions_file)\n",
    "    if sequences is None: return\n",
    "\n",
    "    indices = np.arange(len(sequences))\n",
    "    train_indices, val_indices = train_test_split(indices, test_size=0.2, random_state=42)\n",
    "\n",
    "    X_train_unpadded = [sequences[i] for i in train_indices]\n",
    "    y_train_raw = total_times[train_indices]\n",
    "    X_val_unpadded = [sequences[i] for i in val_indices]\n",
    "    y_val_raw = total_times[val_indices]\n",
    "    \n",
    "    # --- SCALING INPUT AND OUTPUT ---\n",
    "    # Scale the input features (X)\n",
    "    scaler_X = StandardScaler()\n",
    "    # Fit the scaler ONLY on the training data to avoid data leakage\n",
    "    X_train_combined = np.vstack(X_train_unpadded)\n",
    "    scaler_X.fit(X_train_combined)\n",
    "    \n",
    "    # Transform both training and validation sets\n",
    "    X_train_scaled = [scaler_X.transform(seq) for seq in X_train_unpadded]\n",
    "    X_val_scaled = [scaler_X.transform(seq) for seq in X_val_unpadded]\n",
    "\n",
    "    # Scale the output/target variable (y)\n",
    "    scaler_y = StandardScaler()\n",
    "    y_train = scaler_y.fit_transform(y_train_raw.reshape(-1, 1))\n",
    "    y_val = scaler_y.transform(y_val_raw.reshape(-1, 1))\n",
    "\n",
    "    X_train = tf.keras.preprocessing.sequence.pad_sequences(X_train_scaled, maxlen=MAX_SEQ_LEN, padding='post', dtype='float32')\n",
    "    X_val = tf.keras.preprocessing.sequence.pad_sequences(X_val_scaled, maxlen=MAX_SEQ_LEN, padding='post', dtype='float32')\n",
    "\n",
    "    model = build_lstm_model(X_train.shape)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mean_squared_error')\n",
    "    model.summary()\n",
    "\n",
    "    print(\"\\n--- Starting LSTM Model Training ---\")\n",
    "    \n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    reduce_lr_on_plateau = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.0001)\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=100,\n",
    "        batch_size=16,\n",
    "        callbacks=[early_stopping, reduce_lr_on_plateau]\n",
    "    )\n",
    "    print(\"--- LSTM Model Training Finished ---\\n\")\n",
    "\n",
    "    print(\"--- Generating total time predictions for all sequences ---\")\n",
    "    # Scale and pad all sequences for the final prediction\n",
    "    all_sequences_scaled = [scaler_X.transform(seq) for seq in sequences]\n",
    "    X_all_padded = tf.keras.preprocessing.sequence.pad_sequences(all_sequences_scaled, maxlen=MAX_SEQ_LEN, padding='post', dtype='float32')\n",
    "    \n",
    "    scaled_predictions = model.predict(X_all_padded)\n",
    "    predicted_total_times = scaler_y.inverse_transform(scaled_predictions).flatten()\n",
    "\n",
    "    seq_order_to_time = {seq_order: time for seq_order, time in zip(original_df['SeqOrder'].unique(), predicted_total_times)}\n",
    "    \n",
    "    results_df = original_df.copy()\n",
    "    results_df['predicted_total_time'] = results_df['SeqOrder'].map(seq_order_to_time)\n",
    "    results_df['predicted_time_increment'] = results_df['predicted_proportion'] * results_df['predicted_total_time']\n",
    "    results_df['predicted_cumulative_time'] = results_df.groupby('SeqOrder')['predicted_time_increment'].cumsum()\n",
    "\n",
    "    results_df.to_csv(output_file, index=False)\n",
    "    print(f\"✅ Final predictions saved to '{output_file}'\")\n",
    "    \n",
    "    create_visualizations(history, results_df)\n",
    "    \n",
    "    print(\"\\n--- Sample of Final Output ---\")\n",
    "    print(results_df[['SeqOrder', 'Step', 'timediff', 'true_total_time', 'predicted_total_time', 'predicted_cumulative_time']].head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 35 sequences for the LSTM model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_4         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ masking_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Masking</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ any_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Any</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ not_equal_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">17,408</span> │ masking_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │                   │            │ any_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> │ lstm_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│                     │                   │            │ any_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │ dense_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_4         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ input_layer_4[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ masking_4 (\u001b[38;5;33mMasking\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ input_layer_4[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ any_4 (\u001b[38;5;33mAny\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ not_equal_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_9 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │     \u001b[38;5;34m17,408\u001b[0m │ masking_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                     │                   │            │ any_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_10 (\u001b[38;5;33mLSTM\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │     \u001b[38;5;34m12,416\u001b[0m │ lstm_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│                     │                   │            │ any_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ lstm_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │        \u001b[38;5;34m528\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m17\u001b[0m │ dense_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">30,369</span> (118.63 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m30,369\u001b[0m (118.63 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">30,369</span> (118.63 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m30,369\u001b[0m (118.63 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting LSTM Model Training ---\n",
      "Epoch 1/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 554ms/step - loss: 0.8876 - val_loss: 21.6243 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.9026 - val_loss: 21.4303 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.9920 - val_loss: 21.1980 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.8372 - val_loss: 20.8934 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.8049 - val_loss: 20.6654 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 1.0071 - val_loss: 20.4016 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.8315 - val_loss: 20.1998 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.9449 - val_loss: 20.0945 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.7358 - val_loss: 20.0212 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.8819 - val_loss: 19.9276 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.9704 - val_loss: 19.8890 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.7523 - val_loss: 19.8915 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.8864 - val_loss: 19.7813 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.8554 - val_loss: 19.7523 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.8942 - val_loss: 19.7379 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.7677 - val_loss: 19.7771 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.8755 - val_loss: 19.7558 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.9367 - val_loss: 19.7208 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.8924 - val_loss: 19.6967 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 1.0477 - val_loss: 19.7496 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.7945 - val_loss: 19.8101 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.8569 - val_loss: 19.8064 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.7737 - val_loss: 19.7700 - learning_rate: 0.0010\n",
      "Epoch 24/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.9166 - val_loss: 19.6548 - learning_rate: 0.0010\n",
      "Epoch 25/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.8291 - val_loss: 19.6014 - learning_rate: 0.0010\n",
      "Epoch 26/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 1.0070 - val_loss: 19.5853 - learning_rate: 0.0010\n",
      "Epoch 27/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.8853 - val_loss: 19.5583 - learning_rate: 0.0010\n",
      "Epoch 28/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.6686 - val_loss: 19.6628 - learning_rate: 0.0010\n",
      "Epoch 29/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.7144 - val_loss: 19.7254 - learning_rate: 0.0010\n",
      "Epoch 30/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.8494 - val_loss: 19.7372 - learning_rate: 0.0010\n",
      "Epoch 31/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.7188 - val_loss: 19.7953 - learning_rate: 0.0010\n",
      "Epoch 32/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.9414 - val_loss: 19.7246 - learning_rate: 0.0010\n",
      "Epoch 33/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.6940 - val_loss: 19.7529 - learning_rate: 2.0000e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.9469 - val_loss: 19.7545 - learning_rate: 2.0000e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.7281 - val_loss: 19.7585 - learning_rate: 2.0000e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.6827 - val_loss: 19.7560 - learning_rate: 2.0000e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.7580 - val_loss: 19.7457 - learning_rate: 2.0000e-04\n",
      "--- LSTM Model Training Finished ---\n",
      "\n",
      "--- Generating total time predictions for all sequences ---\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 492ms/step\n",
      "✅ Final predictions saved to 'predictions_total_time_176401.csv'\n",
      "\n",
      "--- Generating Visualizations ---\n",
      "✅ Saved training loss plot.\n",
      "Generating comparison plots for 35 sequences...\n",
      "✅ Saved individual sequence plots to the 'sequence_plots' directory.\n",
      "✅ Saved total time prediction analysis plot.\n",
      "\n",
      "--- Sample of Final Output ---\n",
      "    SeqOrder  Step  timediff  true_total_time  predicted_total_time  \\\n",
      "0          0     0         0              339            311.931458   \n",
      "1          0     1         4              339            311.931458   \n",
      "2          0     2        13              339            311.931458   \n",
      "3          0     3        14              339            311.931458   \n",
      "4          0     4        28              339            311.931458   \n",
      "5          0     5        28              339            311.931458   \n",
      "6          0     6        36              339            311.931458   \n",
      "7          0     7        45              339            311.931458   \n",
      "8          0     8       106              339            311.931458   \n",
      "9          0     9       140              339            311.931458   \n",
      "10         0    10       195              339            311.931458   \n",
      "11         0    11       269              339            311.931458   \n",
      "12         0    12       270              339            311.931458   \n",
      "13         0    13       276              339            311.931458   \n",
      "14         0    14       276              339            311.931458   \n",
      "15         0    15       278              339            311.931458   \n",
      "16         0    16       279              339            311.931458   \n",
      "17         0    17       279              339            311.931458   \n",
      "18         0    18       279              339            311.931458   \n",
      "19         0    19       285              339            311.931458   \n",
      "\n",
      "    predicted_cumulative_time  \n",
      "0                   14.102078  \n",
      "1                   24.092363  \n",
      "2                   34.082648  \n",
      "3                   44.072928  \n",
      "4                   54.063195  \n",
      "5                   64.053463  \n",
      "6                   74.043729  \n",
      "7                   84.034002  \n",
      "8                   94.024287  \n",
      "9                  104.014570  \n",
      "10                 114.004860  \n",
      "11                 130.633727  \n",
      "12                 147.262534  \n",
      "13                 163.891310  \n",
      "14                 175.742747  \n",
      "15                 187.594183  \n",
      "16                 199.445643  \n",
      "17                 211.297069  \n",
      "18                 223.007796  \n",
      "19                 234.718530  \n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
