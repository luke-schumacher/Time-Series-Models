{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "import os # For checking file existence\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler # For target scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Constants and Configuration ---\n",
    "\n",
    "MAX_SEQ_LEN = 128\n",
    "# --- UPDATED FEATURES ---\n",
    "# Give the model more context by including the sourceID and step number.\n",
    "FEATURE_COLUMNS = ['predicted_proportion', 'sourceID', 'Step']\n",
    "\n",
    "# --- 2. Data Loading and Preparation for LSTM ---\n",
    "\n",
    "def load_and_prepare_data(file_path):\n",
    "    \"\"\"\n",
    "    Loads proportion data, determines the true total time for each sequence\n",
    "    using the final cumulative timediff, and prepares data for the LSTM.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"❌ Error: Predictions file not found at '{file_path}'\")\n",
    "        return None, None, None\n",
    "\n",
    "    df = pd.read_csv(file_path)\n",
    "    df['true_total_time'] = df.groupby('SeqOrder')['timediff'].transform('max')\n",
    "\n",
    "    grouped = df.groupby('SeqOrder')\n",
    "    sequences = []\n",
    "    total_times = []\n",
    "    \n",
    "    print(f\"Processing {len(grouped)} sequences for the LSTM model...\")\n",
    "    for _, group in grouped:\n",
    "        sequences.append(group[FEATURE_COLUMNS].values)\n",
    "        total_times.append(group['true_total_time'].iloc[0])\n",
    "\n",
    "    return sequences, np.array(total_times), df\n",
    "\n",
    "# --- 3. LSTM Model Architecture (Improved) ---\n",
    "\n",
    "def build_lstm_model(input_shape):\n",
    "    \"\"\"\n",
    "    Builds a more powerful LSTM model for total time prediction.\n",
    "    \"\"\"\n",
    "    inputs = layers.Input(shape=(None, input_shape[-1]))\n",
    "    masking = layers.Masking(mask_value=0.0)(inputs)\n",
    "    # Increased complexity to capture non-linear patterns\n",
    "    lstm1 = layers.LSTM(64, return_sequences=True)(masking)\n",
    "    lstm2 = layers.LSTM(32, return_sequences=False)(lstm1)\n",
    "    # Dropout helps prevent overfitting\n",
    "    dropout = layers.Dropout(0.2)(lstm2)\n",
    "    dense1 = layers.Dense(16, activation='relu')(dropout)\n",
    "    outputs = layers.Dense(1)(dense1)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "# --- 4. Visualization Function ---\n",
    "\n",
    "def create_visualizations(history, results_df):\n",
    "    \"\"\"\n",
    "    Generates and saves plots for model analysis for ALL sequences.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Generating Visualizations ---\")\n",
    "    \n",
    "    output_plot_dir = 'sequence_plots'\n",
    "    os.makedirs(output_plot_dir, exist_ok=True)\n",
    "    \n",
    "    # Plot 1: Training & Validation Loss (Global)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Model Training and Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss (MSE)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig('training_loss_plot.png')\n",
    "    print(\"✅ Saved training loss plot.\")\n",
    "    plt.close()\n",
    "\n",
    "    all_seq_orders = results_df['SeqOrder'].unique()\n",
    "    print(f\"Generating comparison plots for {len(all_seq_orders)} sequences...\")\n",
    "\n",
    "    for seq_order in all_seq_orders:\n",
    "        sample_df = results_df[results_df['SeqOrder'] == seq_order]\n",
    "\n",
    "        # Plot 2: Cumulative Time Comparison\n",
    "        plt.figure(figsize=(12, 7))\n",
    "        plt.plot(sample_df['Step'], sample_df['timediff'], label='True Cumulative Time', marker='o')\n",
    "        plt.plot(sample_df['Step'], sample_df['predicted_cumulative_time'], label='Predicted Cumulative Time', marker='x', linestyle='--')\n",
    "        plt.title(f'Cumulative Time Comparison for Sequence {seq_order}')\n",
    "        plt.xlabel('Step in Sequence')\n",
    "        plt.ylabel('Time (seconds)')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.savefig(os.path.join(output_plot_dir, f'cumulative_time_comparison_seq_{seq_order}.png'))\n",
    "        plt.close()\n",
    "        \n",
    "        # Plot 3: Time Increment Comparison\n",
    "        true_increments = sample_df['timediff'].diff().fillna(sample_df['timediff'].iloc[0])\n",
    "        plt.figure(figsize=(12, 7))\n",
    "        plt.plot(sample_df['Step'], true_increments, label='True Time Increment', marker='o')\n",
    "        plt.plot(sample_df['Step'], sample_df['predicted_time_increment'], label='Predicted Time Increment', marker='x', linestyle='--')\n",
    "        plt.title(f'Time Increment Comparison for Sequence {seq_order}')\n",
    "        plt.xlabel('Step in Sequence')\n",
    "        plt.ylabel('Time (seconds)')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.savefig(os.path.join(output_plot_dir, f'time_increment_comparison_seq_{seq_order}.png'))\n",
    "        plt.close()\n",
    "\n",
    "    print(f\"✅ Saved individual sequence plots to the '{output_plot_dir}' directory.\")\n",
    "\n",
    "    # Plot 4: Total Time Prediction Analysis (Global)\n",
    "    total_time_analysis = results_df[['SeqOrder', 'true_total_time', 'predicted_total_time']].drop_duplicates()\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.scatter(total_time_analysis['true_total_time'], total_time_analysis['predicted_total_time'], alpha=0.6, label='Predictions')\n",
    "    plt.plot([0, total_time_analysis['true_total_time'].max()], [0, total_time_analysis['true_total_time'].max()], color='red', linestyle='--', label='Perfect Prediction Line')\n",
    "    plt.title('True vs. Predicted Total Time')\n",
    "    plt.xlabel('True Total Time (s)')\n",
    "    plt.ylabel('Predicted Total Time (s)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.axis('equal')\n",
    "    plt.savefig('total_time_prediction_analysis.png')\n",
    "    print(\"✅ Saved total time prediction analysis plot.\")\n",
    "    plt.close()\n",
    "\n",
    "# --- 5. Main Orchestration ---\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to run the data processing, training, and prediction.\"\"\"\n",
    "    \n",
    "    proportions_file = 'prediction_176401_proportions.csv'\n",
    "    output_file = 'predictions_total_time_176401.csv'\n",
    "    \n",
    "    sequences, total_times, original_df = load_and_prepare_data(proportions_file)\n",
    "    if sequences is None: return\n",
    "\n",
    "    indices = np.arange(len(sequences))\n",
    "    train_indices, val_indices = train_test_split(indices, test_size=0.2, random_state=42)\n",
    "\n",
    "    X_train_unpadded = [sequences[i] for i in train_indices]\n",
    "    y_train_raw = total_times[train_indices]\n",
    "    X_val_unpadded = [sequences[i] for i in val_indices]\n",
    "    y_val_raw = total_times[val_indices]\n",
    "    \n",
    "    # --- SCALING INPUT AND OUTPUT ---\n",
    "    # Scale the input features (X)\n",
    "    scaler_X = StandardScaler()\n",
    "    # Fit the scaler ONLY on the training data to avoid data leakage\n",
    "    X_train_combined = np.vstack(X_train_unpadded)\n",
    "    scaler_X.fit(X_train_combined)\n",
    "    \n",
    "    # Transform both training and validation sets\n",
    "    X_train_scaled = [scaler_X.transform(seq) for seq in X_train_unpadded]\n",
    "    X_val_scaled = [scaler_X.transform(seq) for seq in X_val_unpadded]\n",
    "\n",
    "    # Scale the output/target variable (y)\n",
    "    scaler_y = StandardScaler()\n",
    "    y_train = scaler_y.fit_transform(y_train_raw.reshape(-1, 1))\n",
    "    y_val = scaler_y.transform(y_val_raw.reshape(-1, 1))\n",
    "\n",
    "    X_train = tf.keras.preprocessing.sequence.pad_sequences(X_train_scaled, maxlen=MAX_SEQ_LEN, padding='post', dtype='float32')\n",
    "    X_val = tf.keras.preprocessing.sequence.pad_sequences(X_val_scaled, maxlen=MAX_SEQ_LEN, padding='post', dtype='float32')\n",
    "\n",
    "    model = build_lstm_model(X_train.shape)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mean_squared_error')\n",
    "    model.summary()\n",
    "\n",
    "    print(\"\\n--- Starting LSTM Model Training ---\")\n",
    "    \n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    reduce_lr_on_plateau = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.0001)\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=100,\n",
    "        batch_size=16,\n",
    "        callbacks=[early_stopping, reduce_lr_on_plateau]\n",
    "    )\n",
    "    print(\"--- LSTM Model Training Finished ---\\n\")\n",
    "\n",
    "    print(\"--- Generating total time predictions for all sequences ---\")\n",
    "    # Scale and pad all sequences for the final prediction\n",
    "    all_sequences_scaled = [scaler_X.transform(seq) for seq in sequences]\n",
    "    X_all_padded = tf.keras.preprocessing.sequence.pad_sequences(all_sequences_scaled, maxlen=MAX_SEQ_LEN, padding='post', dtype='float32')\n",
    "    \n",
    "    scaled_predictions = model.predict(X_all_padded)\n",
    "    predicted_total_times = scaler_y.inverse_transform(scaled_predictions).flatten()\n",
    "\n",
    "    seq_order_to_time = {seq_order: time for seq_order, time in zip(original_df['SeqOrder'].unique(), predicted_total_times)}\n",
    "    \n",
    "    results_df = original_df.copy()\n",
    "    results_df['predicted_total_time'] = results_df['SeqOrder'].map(seq_order_to_time)\n",
    "    results_df['predicted_time_increment'] = results_df['predicted_proportion'] * results_df['predicted_total_time']\n",
    "    results_df['predicted_cumulative_time'] = results_df.groupby('SeqOrder')['predicted_time_increment'].cumsum()\n",
    "\n",
    "    results_df.to_csv(output_file, index=False)\n",
    "    print(f\"✅ Final predictions saved to '{output_file}'\")\n",
    "    \n",
    "    create_visualizations(history, results_df)\n",
    "    \n",
    "    print(\"\\n--- Sample of Final Output ---\")\n",
    "    print(results_df[['SeqOrder', 'Step', 'timediff', 'true_total_time', 'predicted_total_time', 'predicted_cumulative_time']].head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 223 sequences for the LSTM model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ masking (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Masking</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ any (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Any</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ not_equal[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">17,408</span> │ masking[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│                     │                   │            │ any[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
       "│                     │                   │            │ any[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ masking (\u001b[38;5;33mMasking\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ any (\u001b[38;5;33mAny\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ not_equal[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │     \u001b[38;5;34m17,408\u001b[0m │ masking[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│                     │                   │            │ any[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │     \u001b[38;5;34m12,416\u001b[0m │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
       "│                     │                   │            │ any[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │        \u001b[38;5;34m528\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m17\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">30,369</span> (118.63 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m30,369\u001b[0m (118.63 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">30,369</span> (118.63 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m30,369\u001b[0m (118.63 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting LSTM Model Training ---\n",
      "Epoch 1/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 77ms/step - loss: 0.8289 - val_loss: 1.1893 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 0.9161 - val_loss: 1.1886 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 0.4570 - val_loss: 1.1883 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 1.3536 - val_loss: 1.1858 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 0.6621 - val_loss: 1.1863 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 0.8333 - val_loss: 1.1940 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 1.2280 - val_loss: 1.2004 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 1.8139 - val_loss: 1.2001 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 1.4437 - val_loss: 1.1934 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 1.5614 - val_loss: 1.1945 - learning_rate: 2.0000e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 1.1851 - val_loss: 1.1964 - learning_rate: 2.0000e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 1.6299 - val_loss: 1.2001 - learning_rate: 2.0000e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 0.8904 - val_loss: 1.2003 - learning_rate: 2.0000e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 0.7266 - val_loss: 1.2027 - learning_rate: 2.0000e-04\n",
      "--- LSTM Model Training Finished ---\n",
      "\n",
      "--- Generating total time predictions for all sequences ---\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step\n",
      "✅ Final predictions saved to 'predictions_total_time_176401.csv'\n",
      "\n",
      "--- Generating Visualizations ---\n",
      "✅ Saved training loss plot.\n",
      "Generating comparison plots for 223 sequences...\n",
      "✅ Saved individual sequence plots to the 'sequence_plots' directory.\n",
      "✅ Saved total time prediction analysis plot.\n",
      "\n",
      "--- Sample of Final Output ---\n",
      "    SeqOrder  Step  timediff  true_total_time  predicted_total_time  \\\n",
      "0          0     0         0              339            468.496094   \n",
      "1          0     1         4              339            468.496094   \n",
      "2          0     2        13              339            468.496094   \n",
      "3          0     3        14              339            468.496094   \n",
      "4          0     4        28              339            468.496094   \n",
      "5          0     5        28              339            468.496094   \n",
      "6          0     6        36              339            468.496094   \n",
      "7          0     7        45              339            468.496094   \n",
      "8          0     8       106              339            468.496094   \n",
      "9          0     9       140              339            468.496094   \n",
      "10         0    10       195              339            468.496094   \n",
      "11         0    11       269              339            468.496094   \n",
      "12         0    12       270              339            468.496094   \n",
      "13         0    13       276              339            468.496094   \n",
      "14         0    14       276              339            468.496094   \n",
      "15         0    15       278              339            468.496094   \n",
      "16         0    16       279              339            468.496094   \n",
      "17         0    17       279              339            468.496094   \n",
      "18         0    18       279              339            468.496094   \n",
      "19         0    19       285              339            468.496094   \n",
      "\n",
      "    predicted_cumulative_time  \n",
      "0                   18.383880  \n",
      "1                   36.767384  \n",
      "2                   55.150887  \n",
      "3                   73.534379  \n",
      "4                   91.917856  \n",
      "5                  110.301321  \n",
      "6                  128.684803  \n",
      "7                  147.068303  \n",
      "8                  165.451815  \n",
      "9                  183.835350  \n",
      "10                 202.218862  \n",
      "11                 223.289324  \n",
      "12                 244.564673  \n",
      "13                 265.990728  \n",
      "14                 284.374452  \n",
      "15                 302.758161  \n",
      "16                 321.141818  \n",
      "17                 339.525510  \n",
      "18                 357.909172  \n",
      "19                 376.292850  \n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
