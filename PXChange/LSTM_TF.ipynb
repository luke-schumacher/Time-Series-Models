{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Constants and Configuration ---\n",
    "\n",
    "# This should match the MAX_SEQ_LEN from the Transformer model for consistency.\n",
    "MAX_SEQ_LEN = 128\n",
    "\n",
    "# --- 2. Data Loading and Preprocessing ---\n",
    "\n",
    "def load_and_preprocess_data(proportions_file, ground_truth_file):\n",
    "    \"\"\"\n",
    "    Loads predicted proportions, extracts statistical features, and aligns them with\n",
    "    the true total time for each sequence.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(proportions_file):\n",
    "        print(f\"❌ Error: Proportions file not found at '{proportions_file}'\")\n",
    "        return None, None, None, None, None\n",
    "    if not os.path.exists(ground_truth_file):\n",
    "        print(f\"❌ Error: Ground truth data file not found at '{ground_truth_file}'\")\n",
    "        return None, None, None, None, None\n",
    "\n",
    "    props_df = pd.read_csv(proportions_file)\n",
    "    truth_df = pd.read_csv(ground_truth_file)\n",
    "    \n",
    "    # --- Re-calculate the true total time using the definitive logic ---\n",
    "    truth_df['step_duration'] = truth_df.groupby('SeqOrder')['timediff'].diff().fillna(truth_df['timediff'])\n",
    "    truth_df['step_duration'] = truth_df['step_duration'].clip(lower=0)\n",
    "    truth_df['Step'] = truth_df.groupby('SeqOrder').cumcount()\n",
    "    \n",
    "    end_marker_step = truth_df[truth_df['sourceID'] == 10].groupby('SeqOrder')['Step'].first()\n",
    "    truth_df['end_marker_step'] = truth_df['SeqOrder'].map(end_marker_step)\n",
    "    truth_df.loc[truth_df['Step'] > truth_df['end_marker_step'], 'step_duration'] = 0\n",
    "    \n",
    "    total_times = truth_df.groupby('SeqOrder')['step_duration'].sum()\n",
    "\n",
    "    # --- Prepare data for the Models ---\n",
    "    X_sequences, X_num_steps, X_stats = [], [], []\n",
    "    \n",
    "    for _, g in props_df.groupby('SeqOrder'):\n",
    "        proportions = g['predicted_proportion'].values\n",
    "        X_sequences.append(proportions.reshape(-1, 1))\n",
    "        X_num_steps.append(len(g))\n",
    "        \n",
    "        # --- Feature Engineering: Create a richer set of statistical features ---\n",
    "        stats = [\n",
    "            np.mean(proportions), np.std(proportions), np.max(proportions),\n",
    "            np.percentile(proportions, 25), np.median(proportions), np.percentile(proportions, 75)\n",
    "        ]\n",
    "        X_stats.append(stats)\n",
    "    \n",
    "    y_total_times = props_df['SeqOrder'].unique()\n",
    "    y_sequences = np.array([total_times.get(seq_id, 0) for seq_id in y_total_times])\n",
    "\n",
    "    X_padded_seq = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        X_sequences, maxlen=MAX_SEQ_LEN, padding='post', dtype='float32'\n",
    "    )\n",
    "    \n",
    "    X_steps_arr = np.array(X_num_steps, dtype='float32').reshape(-1, 1)\n",
    "    X_stats_arr = np.array(X_stats, dtype='float32')\n",
    "\n",
    "    print(f\"Successfully processed {len(X_padded_seq)} sequences.\")\n",
    "    \n",
    "    return X_padded_seq, X_steps_arr, X_stats_arr, y_sequences.reshape(-1, 1), props_df\n",
    "\n",
    "\n",
    "# --- 3. Model Architectures ---\n",
    "\n",
    "def build_statistical_model(scalar_shape, stats_shape):\n",
    "    \"\"\"Builds a simple MLP model based on high-level statistical features.\"\"\"\n",
    "    scalar_input = layers.Input(shape=scalar_shape, name='scalar_input')\n",
    "    stats_input = layers.Input(shape=stats_shape, name='stats_input')\n",
    "    \n",
    "    concatenated = layers.concatenate([scalar_input, stats_input])\n",
    "    x = layers.Dense(64, activation='relu')(concatenated)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(32, activation='relu')(x)\n",
    "    outputs = layers.Dense(1, name='stat_output')(x)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=[scalar_input, stats_input], outputs=outputs, name=\"StatisticalModel\")\n",
    "    return model\n",
    "\n",
    "def build_sequential_model(sequence_shape):\n",
    "    \"\"\"Builds a powerful sequential model that ONLY sees the proportions.\"\"\"\n",
    "    sequence_input = layers.Input(shape=sequence_shape, name='sequence_input')\n",
    "    \n",
    "    masked_sequence = layers.Masking(mask_value=0.)(sequence_input)\n",
    "    gru_out = layers.Bidirectional(layers.GRU(128, return_sequences=True))(masked_sequence)\n",
    "    attention_out = layers.MultiHeadAttention(num_heads=8, key_dim=256)(query=gru_out, value=gru_out, key=gru_out)\n",
    "    context_vector = layers.GlobalAveragePooling1D()(attention_out)\n",
    "    \n",
    "    x = layers.Dense(128, activation='relu')(context_vector)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    outputs = layers.Dense(1, name='seq_output')(x)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=sequence_input, outputs=outputs, name=\"SequentialModel\")\n",
    "    return model\n",
    "\n",
    "def build_meta_model(n_features):\n",
    "    \"\"\"Builds the meta-learner model.\"\"\"\n",
    "    meta_input = layers.Input(shape=(n_features,), name='meta_input')\n",
    "    x = layers.Dense(32, activation='relu')(meta_input)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    x = layers.Dense(16, activation='relu')(x)\n",
    "    outputs = layers.Dense(1, name='meta_output')(x)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=meta_input, outputs=outputs, name=\"MetaModel\")\n",
    "    return model\n",
    "\n",
    "# --- 4. Visualization Function ---\n",
    "\n",
    "def create_visualizations(results_df, output_dir='visualizations'):\n",
    "    \"\"\"Generates and saves plots comparing true vs. predicted total time.\"\"\"\n",
    "    if not os.path.exists(output_dir): os.makedirs(output_dir)\n",
    "    true_times, predicted_times = results_df['true_total_time'], results_df['predicted_total_time']\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.scatter(true_times, predicted_times, alpha=0.6)\n",
    "    lims = [np.min([plt.xlim(), plt.ylim()]), np.max([plt.xlim(), plt.ylim()])]\n",
    "    plt.plot(lims, lims, 'r--', alpha=0.75, zorder=0)\n",
    "    plt.xlabel(\"True Total Time (seconds)\"), plt.ylabel(\"Predicted Total Time (seconds)\"), plt.title(\"True vs. Predicted Total Time\"), plt.grid(True)\n",
    "    plt.savefig(os.path.join(output_dir, 'true_vs_predicted_scatter.png')), plt.close()\n",
    "    errors = predicted_times - true_times\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(errors, bins=30, alpha=0.7)\n",
    "    plt.xlabel(\"Prediction Error (Predicted - True)\"), plt.ylabel(\"Frequency\"), plt.title(\"Distribution of Prediction Errors\"), plt.grid(True), plt.axvline(x=0, color='r', linestyle='--', linewidth=2)\n",
    "    plt.savefig(os.path.join(output_dir, 'prediction_error_histogram.png')), plt.close()\n",
    "    print(f\"✅ Basic visualizations saved to '{output_dir}' directory.\")\n",
    "\n",
    "def create_advanced_visualizations(results_df, output_dir='visualizations'):\n",
    "    \"\"\"Generates and saves advanced diagnostic plots.\"\"\"\n",
    "    true_times, predicted_times = results_df['true_total_time'], results_df['predicted_total_time']\n",
    "    residuals = true_times - predicted_times\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.scatterplot(x=predicted_times, y=residuals, alpha=0.6)\n",
    "    plt.axhline(y=0, color='r', linestyle='--'), plt.xlabel(\"Predicted Total Time (seconds)\"), plt.ylabel(\"Residuals (True - Predicted)\"), plt.title(\"Residuals vs. Predicted Values\"), plt.grid(True)\n",
    "    plt.savefig(os.path.join(output_dir, 'residuals_vs_predicted.png')), plt.close()\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(true_times, color=\"blue\", label='True Values', kde=True, stat=\"density\", linewidth=0)\n",
    "    sns.histplot(predicted_times, color=\"red\", label='Predicted Values', kde=True, stat=\"density\", linewidth=0)\n",
    "    plt.title(\"Distribution of Predicted vs. True Values\"), plt.xlabel(\"Total Time (seconds)\"), plt.legend()\n",
    "    plt.savefig(os.path.join(output_dir, 'predicted_vs_true_distribution.png')), plt.close()\n",
    "    print(f\"✅ Advanced visualizations saved to '{output_dir}' directory.\")\n",
    "\n",
    "\n",
    "# --- 5. Training and Prediction Orchestration ---\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to run the data processing, training, and prediction.\"\"\"\n",
    "    \n",
    "    proportions_file = 'prediction_176401_proportions_final_all.csv'\n",
    "    ground_truth_file = 'data/176401/encoded_176401_condensed_full.csv'\n",
    "    output_predictions_file = 'prediction_176401_total_time_full.csv'\n",
    "    \n",
    "    X_seq, X_steps, X_stats, y, props_df = load_and_preprocess_data(proportions_file, ground_truth_file)\n",
    "    if X_seq is None: return\n",
    "\n",
    "    X_seq_train, X_seq_val, X_steps_train, X_steps_val, X_stats_train, X_stats_val, y_train, y_val = train_test_split(\n",
    "        X_seq, X_steps, X_stats, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    scaler_steps = StandardScaler(); X_steps_train_scaled, X_steps_val_scaled = scaler_steps.fit_transform(X_steps_train), scaler_steps.transform(X_steps_val)\n",
    "    scaler_stats = StandardScaler(); X_stats_train_scaled, X_stats_val_scaled = scaler_stats.fit_transform(X_stats_train), scaler_stats.transform(X_stats_val)\n",
    "    scaler_y = StandardScaler(); y_train_scaled, y_val_scaled = scaler_y.fit_transform(y_train), scaler_y.transform(y_val)\n",
    "    \n",
    "    # --- Train Statistical Model ---\n",
    "    print(\"\\n--- Training Statistical Model ---\")\n",
    "    stat_model = build_statistical_model((1,), X_stats_train.shape[1:])\n",
    "    stat_model.compile(optimizer='adam', loss='huber', metrics=['mae'])\n",
    "    stat_model.fit(\n",
    "        [X_steps_train_scaled, X_stats_train_scaled], y_train_scaled,\n",
    "        validation_data=([X_steps_val_scaled, X_stats_val_scaled], y_val_scaled),\n",
    "        epochs=300, batch_size=32,\n",
    "        callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True)],\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    # --- Train Sequential Model ---\n",
    "    print(\"\\n--- Training Sequential Model ---\")\n",
    "    seq_model = build_sequential_model(X_seq_train.shape[1:])\n",
    "    seq_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005), loss='huber', metrics=['mae'])\n",
    "    seq_model.fit(\n",
    "        X_seq_train, y_train_scaled,\n",
    "        validation_data=(X_seq_val, y_val_scaled),\n",
    "        epochs=500, batch_size=32,\n",
    "        callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=75, restore_best_weights=True)],\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    # --- Create Training Data for Meta-Model ---\n",
    "    stat_preds_val = stat_model.predict([X_steps_val_scaled, X_stats_val_scaled])\n",
    "    seq_preds_val = seq_model.predict(X_seq_val)\n",
    "    meta_X_train = np.hstack((stat_preds_val, seq_preds_val, X_steps_val_scaled, X_stats_val_scaled))\n",
    "    meta_y_train = y_val_scaled\n",
    "    \n",
    "    # --- Train Meta-Model ---\n",
    "    print(\"\\n--- Training Meta-Model ---\")\n",
    "    meta_model = build_meta_model(meta_X_train.shape[1])\n",
    "    meta_model.compile(optimizer='adam', loss='huber', metrics=['mae'])\n",
    "    meta_model.summary()\n",
    "    meta_model.fit(\n",
    "        meta_X_train, meta_y_train,\n",
    "        epochs=200, batch_size=16,\n",
    "        callbacks=[tf.keras.callbacks.EarlyStopping(monitor='loss', patience=20, restore_best_weights=True)],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # --- Generate Final Predictions ---\n",
    "    print(\"\\n--- Generating Final Ensemble Predictions ---\")\n",
    "    X_steps_scaled, X_stats_scaled = scaler_steps.transform(X_steps), scaler_stats.transform(X_stats)\n",
    "    stat_preds_scaled = stat_model.predict([X_steps_scaled, X_stats_scaled])\n",
    "    seq_preds_scaled = seq_model.predict(X_seq)\n",
    "    \n",
    "    meta_X_final = np.hstack((stat_preds_scaled, seq_preds_scaled, X_steps_scaled, X_stats_scaled))\n",
    "    final_preds_scaled = meta_model.predict(meta_X_final)\n",
    "    \n",
    "    predicted_times = scaler_y.inverse_transform(final_preds_scaled).flatten()\n",
    "    \n",
    "    # --- Final Output ---\n",
    "    seq_order_to_time = dict(zip(props_df['SeqOrder'].unique(), predicted_times))\n",
    "    props_df['predicted_total_time'] = np.nan\n",
    "    end_marker_indices = props_df[props_df['sourceID'] == 10].groupby('SeqOrder')['Step'].idxmin()\n",
    "    for seq_order, idx in end_marker_indices.items():\n",
    "        if seq_order in seq_order_to_time:\n",
    "            props_df.loc[idx, 'predicted_total_time'] = seq_order_to_time[seq_order]\n",
    "\n",
    "    props_df.to_csv(output_predictions_file, index=False)\n",
    "    print(f\"✅ Final predictions saved to '{output_predictions_file}'\")\n",
    "\n",
    "    results_df = pd.DataFrame({\n",
    "        'SeqOrder': props_df['SeqOrder'].unique(),\n",
    "        'true_total_time': scaler_y.inverse_transform(y).flatten(),\n",
    "        'predicted_total_time': predicted_times\n",
    "    })\n",
    "    \n",
    "    create_visualizations(results_df)\n",
    "    create_advanced_visualizations(results_df)\n",
    "\n",
    "    print(\"\\n--- Sample of Final Predictions ---\")\n",
    "    if not props_df.empty: print(props_df[props_df['SeqOrder'] == props_df['SeqOrder'].iloc[0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed 223 sequences.\n",
      "\n",
      "--- Training Statistical Model ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lukis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\models\\functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: ['scalar_input', 'stats_input']. Received: the structure of inputs=('*', '*')\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training Sequential Model ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lukis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'query' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lukis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'key' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lukis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'value' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 495ms/step\n",
      "\n",
      "--- Training Meta-Model ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"MetaModel\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"MetaModel\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ meta_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ meta_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ meta_input (\u001b[38;5;33mInputLayer\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_23 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_12 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_24 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m528\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ meta_output (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m17\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">865</span> (3.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m865\u001b[0m (3.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">865</span> (3.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m865\u001b[0m (3.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.1790 - mae: 0.4035\n",
      "Epoch 2/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2180 - mae: 0.4461 \n",
      "Epoch 3/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1786 - mae: 0.3985 7\n",
      "Epoch 4/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1331 - mae: 0.3426\n",
      "Epoch 5/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1822 - mae: 0.3764  \n",
      "Epoch 6/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2619 - mae: 0.4636\n",
      "Epoch 7/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2713 - mae: 0.4877\n",
      "Epoch 8/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3212 - mae: 0.5218\n",
      "Epoch 9/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3154 - mae: 0.4968\n",
      "Epoch 10/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1685 - mae: 0.3379  \n",
      "Epoch 11/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1787 - mae: 0.3313\n",
      "Epoch 12/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2890 - mae: 0.4936\n",
      "Epoch 13/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1681 - mae: 0.3276\n",
      "Epoch 14/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2691 - mae: 0.4423\n",
      "Epoch 15/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2527 - mae: 0.4218  \n",
      "Epoch 16/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1337 - mae: 0.2887\n",
      "Epoch 17/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1142 - mae: 0.2635\n",
      "Epoch 18/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2197 - mae: 0.383382\n",
      "Epoch 19/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1142 - mae: 0.2632\n",
      "Epoch 20/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2456 - mae: 0.3903  \n",
      "Epoch 21/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3048 - mae: 0.4530  \n",
      "Epoch 22/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1768 - mae: 0.3226\n",
      "Epoch 23/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3045 - mae: 0.4488 \n",
      "Epoch 24/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1064 - mae: 0.2205  \n",
      "Epoch 25/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2667 - mae: 0.4070 \n",
      "Epoch 26/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1024 - mae: 0.2080\n",
      "Epoch 27/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2683 - mae: 0.4151\n",
      "Epoch 28/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3017 - mae: 0.4458\n",
      "Epoch 29/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1576 - mae: 0.3111\n",
      "Epoch 30/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3110 - mae: 0.47994\n",
      "Epoch 31/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2654 - mae: 0.4045   \n",
      "Epoch 32/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1580 - mae: 0.3071\n",
      "Epoch 33/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1662 - mae: 0.2934\n",
      "Epoch 34/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2108 - mae: 0.3342\n",
      "Epoch 35/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1237 - mae: 0.2488   \n",
      "Epoch 36/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1527 - mae: 0.2859\n",
      "Epoch 37/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2506 - mae: 0.3814\n",
      "Epoch 38/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1655 - mae: 0.2940\n",
      "Epoch 39/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1032 - mae: 0.2161\n",
      "Epoch 40/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3010 - mae: 0.4350\n",
      "Epoch 41/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1032 - mae: 0.2154\n",
      "Epoch 42/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2627 - mae: 0.3927  \n",
      "Epoch 43/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1053 - mae: 0.2307   \n",
      "Epoch 44/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1273 - mae: 0.2601\n",
      "Epoch 45/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1037 - mae: 0.2131\n",
      "Epoch 46/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1533 - mae: 0.2884\n",
      "Epoch 47/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2630 - mae: 0.3963\n",
      "Epoch 48/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3040 - mae: 0.4523\n",
      "Epoch 49/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2062 - mae: 0.3429\n",
      "Epoch 50/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1681 - mae: 0.2871\n",
      "Epoch 51/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2051 - mae: 0.3319\n",
      "Epoch 52/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1617 - mae: 0.2927\n",
      "Epoch 53/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2583 - mae: 0.3850\n",
      "Epoch 54/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2548 - mae: 0.3617 \n",
      "Epoch 55/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2064 - mae: 0.3375  \n",
      "Epoch 56/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1670 - mae: 0.2759\n",
      "Epoch 57/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2066 - mae: 0.3461  \n",
      "Epoch 58/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2981 - mae: 0.4397 \n",
      "Epoch 59/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1253 - mae: 0.2398  \n",
      "Epoch 60/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1668 - mae: 0.2829  \n",
      "Epoch 61/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1598 - mae: 0.2774\n",
      "Epoch 62/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1468 - mae: 0.2626\n",
      "Epoch 63/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2610 - mae: 0.3909\n",
      "Epoch 64/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1207 - mae: 0.2472\n",
      "Epoch 65/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1024 - mae: 0.2158\n",
      "Epoch 66/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2596 - mae: 0.38468\n",
      "Epoch 67/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2597 - mae: 0.3828\n",
      "Epoch 68/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2997 - mae: 0.4351  \n",
      "Epoch 69/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2429 - mae: 0.3754 \n",
      "Epoch 70/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2574 - mae: 0.3629  \n",
      "Epoch 71/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1214 - mae: 0.2554\n",
      "Epoch 72/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2594 - mae: 0.3855\n",
      "Epoch 73/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2934 - mae: 0.4073 \n",
      "Epoch 74/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2023 - mae: 0.3082\n",
      "\n",
      "--- Generating Final Ensemble Predictions ---\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "✅ Final predictions saved to 'prediction_176401_total_time_full.csv'\n",
      "✅ Basic visualizations saved to 'visualizations' directory.\n",
      "✅ Advanced visualizations saved to 'visualizations' directory.\n",
      "\n",
      "--- Sample of Final Predictions ---\n",
      "    SeqOrder  Step  sourceID  timediff  step_duration  true_proportion  \\\n",
      "0          0     0        11         0            0.0         0.000000   \n",
      "1          0     1         4         4            4.0         0.011799   \n",
      "2          0     2         5        13            9.0         0.026549   \n",
      "3          0     3         5        14            1.0         0.002950   \n",
      "4          0     4         5        28           14.0         0.041298   \n",
      "5          0     5         0        28            0.0         0.000000   \n",
      "6          0     6         1        36            8.0         0.023599   \n",
      "7          0     7         1        45            9.0         0.026549   \n",
      "8          0     8         1       106           61.0         0.179941   \n",
      "9          0     9         5       140           34.0         0.100295   \n",
      "10         0    10         1       195           55.0         0.162242   \n",
      "11         0    11         4       269           74.0         0.218289   \n",
      "12         0    12         5       270            1.0         0.002950   \n",
      "13         0    13         5       276            6.0         0.017699   \n",
      "14         0    14         4       276            0.0         0.000000   \n",
      "15         0    15         5       278            2.0         0.005900   \n",
      "16         0    16         0       279            1.0         0.002950   \n",
      "17         0    17         8       279            0.0         0.000000   \n",
      "18         0    18         4       279            0.0         0.000000   \n",
      "19         0    19         5       285            6.0         0.017699   \n",
      "20         0    20         0       315           30.0         0.088496   \n",
      "21         0    21         0       315            0.0         0.000000   \n",
      "22         0    22         9       315            0.0         0.000000   \n",
      "23         0    23         0       321            6.0         0.017699   \n",
      "24         0    24        10       339           18.0         0.053097   \n",
      "\n",
      "    predicted_proportion  predicted_total_time  \n",
      "0               0.022637                   NaN  \n",
      "1               0.050908                   NaN  \n",
      "2               0.050908                   NaN  \n",
      "3               0.050908                   NaN  \n",
      "4               0.050908                   NaN  \n",
      "5               0.050907                   NaN  \n",
      "6               0.050907                   NaN  \n",
      "7               0.050907                   NaN  \n",
      "8               0.050907                   NaN  \n",
      "9               0.050907                   NaN  \n",
      "10              0.050907                   NaN  \n",
      "11              0.030270                   NaN  \n",
      "12              0.030270                   NaN  \n",
      "13              0.030270                   NaN  \n",
      "14              0.033662                   NaN  \n",
      "15              0.033662                   NaN  \n",
      "16              0.033662                   NaN  \n",
      "17              0.033662                   NaN  \n",
      "18              0.034597                   NaN  \n",
      "19              0.034597                   NaN  \n",
      "20              0.034596                   NaN  \n",
      "21              0.034596                   NaN  \n",
      "22              0.034597                   NaN  \n",
      "23              0.034597                   NaN  \n",
      "24              0.034597            341.800812  \n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
