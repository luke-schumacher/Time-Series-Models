{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "import os # For checking file existence\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler # For target scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to compute increments and cumulative times from proportions and total time\n",
    "def calculate_times_from_proportions(proportions_per_step, total_time_for_sequence, mask_per_step):\n",
    "    \"\"\"\n",
    "    Calculates time increments and cumulative times from step-wise proportions and a total time.\n",
    "    \"\"\"\n",
    "    proportions_tf = tf.cast(proportions_per_step, tf.float32)\n",
    "    total_time_tf = tf.cast(total_time_for_sequence, tf.float32)\n",
    "    mask_tf = tf.cast(mask_per_step, tf.float32)\n",
    "\n",
    "    if len(tf.shape(total_time_tf)) == 1:\n",
    "        total_time_tf = tf.expand_dims(total_time_tf, axis=-1)\n",
    "\n",
    "    masked_proportions = proportions_tf * mask_tf\n",
    "    row_sums = tf.reduce_sum(masked_proportions, axis=1, keepdims=True)\n",
    "    row_sums = tf.where(tf.equal(row_sums, 0), tf.ones_like(row_sums), row_sums) \n",
    "    normalized_proportions = masked_proportions / row_sums\n",
    "    increments = normalized_proportions * total_time_tf \n",
    "    cumulative_times = tf.cumsum(increments, axis=1)\n",
    "    \n",
    "    increments *= mask_tf\n",
    "    cumulative_times *= mask_tf\n",
    "    normalized_proportions *= mask_tf\n",
    "\n",
    "    return normalized_proportions, increments, cumulative_times\n",
    "\n",
    "# %%\n",
    "class TotalTimeLSTM(tf.keras.Model):\n",
    "    \"\"\"\n",
    "    Enhanced LSTM model with Attention to predict the total time of a sequence.\n",
    "    Architecture: \n",
    "        Input1 (Sequential): BiLSTM -> Attention\n",
    "        Input2 (Global): Global Features\n",
    "        Concatenate [Attention_Output, Global_Features] -> Dense -> Dropout -> Dense (Output)\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_units=256, # Increased LSTM units\n",
    "                 dense_units_1=128, # First dense layer after concat\n",
    "                 dense_units_2=64,  # Second intermediate dense layer\n",
    "                 dropout_rate=0.4): # Increased dropout slightly\n",
    "        super(TotalTimeLSTM, self).__init__()\n",
    "        \n",
    "        self.hidden_units = hidden_units\n",
    "        self.dense_units_1 = dense_units_1\n",
    "        self.dense_units_2 = dense_units_2\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "        # --- Layers for sequential input ---\n",
    "        self.bi_lstm_layer = layers.Bidirectional(\n",
    "            layers.LSTM(self.hidden_units, \n",
    "                        return_sequences=True, \n",
    "                        dropout=self.dropout_rate,\n",
    "                        recurrent_dropout=0.25),\n",
    "            name=\"bidirectional_lstm_v12\"\n",
    "        )\n",
    "        \n",
    "        # Attention layer to create a weighted summary of the sequence\n",
    "        self.attention = layers.Attention(name=\"attention_layer_v12\")\n",
    "        \n",
    "        # --- Layers for combined features ---\n",
    "        self.concat_layer = layers.Concatenate(name=\"concatenate_features_v12\")\n",
    "        \n",
    "        self.dense_1 = layers.Dense(\n",
    "            self.dense_units_1, \n",
    "            activation='relu',\n",
    "            kernel_regularizer=tf.keras.regularizers.l2(0.001),\n",
    "            name=\"dense_1_v12\"\n",
    "        )\n",
    "        self.dropout_1 = layers.Dropout(self.dropout_rate, name=\"dropout_1_v12\")\n",
    "        \n",
    "        self.dense_2 = layers.Dense(\n",
    "            self.dense_units_2,\n",
    "            activation='relu',\n",
    "            kernel_regularizer=tf.keras.regularizers.l2(0.001),\n",
    "            name=\"dense_2_v12\"\n",
    "        )\n",
    "        self.dropout_2 = layers.Dropout(self.dropout_rate, name=\"dropout_2_v12\")\n",
    "\n",
    "        self.total_time_head = layers.Dense(1, activation='linear', name=\"total_time_dense_v12\") \n",
    "        \n",
    "    def call(self, inputs, training=False): \n",
    "        sequence_input, global_features_input = inputs \n",
    "\n",
    "        mask_bool_seq = tf.reduce_any(tf.not_equal(sequence_input, 0.0), axis=-1)\n",
    "        \n",
    "        # Process sequence with BiLSTM\n",
    "        lstm_output = self.bi_lstm_layer(sequence_input, mask=mask_bool_seq, training=training)\n",
    "        \n",
    "        # Apply self-attention on the LSTM outputs\n",
    "        # For self-attention, the query and value are the same.\n",
    "        # The output is a weighted sum of the values (the LSTM outputs).\n",
    "        attention_output = self.attention([lstm_output, lstm_output], mask=[mask_bool_seq, mask_bool_seq])\n",
    "        \n",
    "        # Concatenate the attention-weighted sequence summary with the global features\n",
    "        combined_features = self.concat_layer([attention_output, global_features_input])\n",
    "        \n",
    "        # Pass combined features through final dense layers\n",
    "        x = self.dense_1(combined_features)\n",
    "        x = self.dropout_1(x, training=training)\n",
    "        x = self.dense_2(x)\n",
    "        x = self.dropout_2(x, training=training)\n",
    "        total_time_pred = self.total_time_head(x)\n",
    "        \n",
    "        return total_time_pred\n",
    "\n",
    "# %%\n",
    "def process_input_data_for_lstm(transformer_predictions_file):\n",
    "    \"\"\"\n",
    "    Process the transformer predictions CSV to prepare data for LSTM training.\n",
    "    Adds more global features: length, sum, mean, std, and max of Transformer proportions.\n",
    "    \"\"\"\n",
    "    print(f\"Processing data from: {transformer_predictions_file}\")\n",
    "    if not os.path.exists(transformer_predictions_file):\n",
    "        raise FileNotFoundError(f\"Transformer predictions file not found: {transformer_predictions_file}\")\n",
    "    df = pd.read_csv(transformer_predictions_file)\n",
    "    \n",
    "    required_cols = ['Predicted_Proportion', 'GroundTruth_Cumulative', 'GroundTruth_Increment', 'Sequence', 'Step']\n",
    "    for col in required_cols:\n",
    "        if col not in df.columns: raise ValueError(f\"CSV must contain '{col}' column.\")\n",
    "\n",
    "    sequences = df['Sequence'].unique()\n",
    "    \n",
    "    X_sequential_data_list = []; X_global_features_list = []\n",
    "    y_total_times_list = []; original_dfs_list = [] \n",
    "    transformer_proportions_list = []; ground_truth_increments_list = []\n",
    "    ground_truth_cumulative_list = [] \n",
    "\n",
    "    for seq_id in sequences:\n",
    "        seq_df = df[df['Sequence'] == seq_id].sort_values('Step').copy()\n",
    "        if seq_df.empty:\n",
    "            original_dfs_list.append(seq_df); continue\n",
    "        original_dfs_list.append(seq_df) \n",
    "\n",
    "        actual_sequence_length = float(len(seq_df))\n",
    "        props_for_seq = seq_df['Predicted_Proportion'].values\n",
    "        \n",
    "        # --- Enhanced Global Features ---\n",
    "        sum_props = np.sum(props_for_seq)\n",
    "        mean_props = np.mean(props_for_seq) if actual_sequence_length > 0 else 0.0\n",
    "        std_props = np.std(props_for_seq) if actual_sequence_length > 1 else 0.0\n",
    "        max_prop = np.max(props_for_seq) if actual_sequence_length > 0 else 0.0\n",
    "\n",
    "        current_max_steps = seq_df['Step'].max()\n",
    "        if current_max_steps == 0: current_max_steps = 1 \n",
    "        \n",
    "        sequential_features = np.column_stack([props_for_seq, seq_df['Step'].values / current_max_steps])\n",
    "        X_sequential_data_list.append(sequential_features)\n",
    "        \n",
    "        global_features_for_seq = np.array([\n",
    "            actual_sequence_length, sum_props, mean_props, std_props, max_prop\n",
    "        ], dtype=np.float32)\n",
    "        X_global_features_list.append(global_features_for_seq)\n",
    "        \n",
    "        gt_cumulative_for_seq = seq_df['GroundTruth_Cumulative'].values\n",
    "        total_time_for_seq = np.max(gt_cumulative_for_seq) if len(gt_cumulative_for_seq) > 0 else 0.0\n",
    "        y_total_times_list.append(total_time_for_seq)\n",
    "        \n",
    "        transformer_proportions_list.append(props_for_seq)\n",
    "        ground_truth_increments_list.append(seq_df['GroundTruth_Increment'].values)\n",
    "        ground_truth_cumulative_list.append(gt_cumulative_for_seq) \n",
    "\n",
    "    if not X_sequential_data_list: raise ValueError(\"No valid sequences processed.\")\n",
    "\n",
    "    y_total_times_array_unpadded = np.array(y_total_times_list)\n",
    "    print(f\"\\nStatistics for TARGET y_total_times_list (max GT_Cumulative per seq, {len(y_total_times_array_unpadded)} sequences):\")\n",
    "    print(f\"  Mean: {np.mean(y_total_times_array_unpadded):.4f}, Std Dev: {np.std(y_total_times_array_unpadded):.4f}\")\n",
    "    print(f\"  Min: {np.min(y_total_times_array_unpadded):.4f}, Max: {np.max(y_total_times_array_unpadded):.4f}\")\n",
    "    print(f\"  Number of zeros (<=1e-6): {np.sum(y_total_times_array_unpadded <= 1e-6)}\\n\")\n",
    "\n",
    "    max_length_sequential = max(len(x) for x in X_sequential_data_list) if X_sequential_data_list else 0\n",
    "    if max_length_sequential == 0: raise ValueError(\"Max length for sequential features is 0.\")\n",
    "    num_sequential_features = X_sequential_data_list[0].shape[1]\n",
    "    num_global_features = X_global_features_list[0].shape[0]\n",
    "\n",
    "    X_sequential_padded = np.zeros((len(X_sequential_data_list), max_length_sequential, num_sequential_features), dtype=np.float32)\n",
    "    masks_padded_float = np.zeros((len(X_sequential_data_list), max_length_sequential), dtype=np.float32) \n",
    "    transformer_proportions_padded = np.zeros((len(X_sequential_data_list), max_length_sequential), dtype=np.float32)\n",
    "    gt_increments_padded_original = np.zeros((len(X_sequential_data_list), max_length_sequential), dtype=np.float32)\n",
    "    gt_cumulative_padded_original = np.zeros((len(X_sequential_data_list), max_length_sequential), dtype=np.float32)\n",
    "\n",
    "    for i, seq_data in enumerate(X_sequential_data_list):\n",
    "        seq_len = len(seq_data)\n",
    "        if seq_len > 0:\n",
    "            X_sequential_padded[i, :seq_len, :] = seq_data\n",
    "            masks_padded_float[i, :seq_len] = 1.0 \n",
    "            transformer_proportions_padded[i, :seq_len] = transformer_proportions_list[i]\n",
    "            gt_increments_padded_original[i, :seq_len] = ground_truth_increments_list[i]\n",
    "            gt_cumulative_padded_original[i, :seq_len] = ground_truth_cumulative_list[i]\n",
    "        \n",
    "    y_total_times_np = np.array(y_total_times_list, dtype=np.float32)\n",
    "    X_global_features_np = np.array(X_global_features_list, dtype=np.float32)\n",
    "\n",
    "    return {\n",
    "        'X_sequential_input': X_sequential_padded, \n",
    "        'X_global_features_input': X_global_features_np, \n",
    "        'y_lstm_target_total_times': y_total_times_np,\n",
    "        'masks_for_calc': masks_padded_float, \n",
    "        'sequences_ids': sequences, \n",
    "        'original_dfs': original_dfs_list, \n",
    "        'transformer_proportions_padded': transformer_proportions_padded, \n",
    "        'gt_increments_padded_original': gt_increments_padded_original,\n",
    "        'gt_cumulative_padded_original': gt_cumulative_padded_original,\n",
    "        'max_len_sequential': max_length_sequential,\n",
    "        'num_sequential_features': num_sequential_features,\n",
    "        'num_global_features': num_global_features\n",
    "    }\n",
    "\n",
    "# %%\n",
    "def train_total_time_lstm(transformer_predictions_file, epochs=50, batch_size=32, val_split_ratio=0.2):\n",
    "    \"\"\"\n",
    "    Train the enhanced LSTM model to predict total_time.\n",
    "    \"\"\"\n",
    "    print(\"Processing data for LSTM training...\")\n",
    "    data_for_lstm = process_input_data_for_lstm(transformer_predictions_file)\n",
    "    \n",
    "    print(f\"Num sequential features: {data_for_lstm['num_sequential_features']}, Max seq length: {data_for_lstm['max_len_sequential']}\")\n",
    "    print(f\"Num global features: {data_for_lstm['num_global_features']}\")\n",
    "\n",
    "    lstm_model = TotalTimeLSTM(hidden_units=256, dense_units_1=128, dense_units_2=64, dropout_rate=0.4) \n",
    "    \n",
    "    X_sequential_all = data_for_lstm['X_sequential_input']\n",
    "    X_global_all = data_for_lstm['X_global_features_input']\n",
    "    y_targets_all = data_for_lstm['y_lstm_target_total_times']\n",
    "    \n",
    "    if len(X_sequential_all) > 0:\n",
    "        sample_seq_input_for_build = tf.convert_to_tensor(X_sequential_all[:1], dtype=tf.float32)\n",
    "        sample_glob_input_for_build = tf.convert_to_tensor(X_global_all[:1], dtype=tf.float32)\n",
    "        _ = lstm_model((sample_seq_input_for_build, sample_glob_input_for_build)) \n",
    "        print(\"\\nEnhanced LSTM Model Summary (v12 - after sample call):\")\n",
    "        lstm_model.summary(expand_nested=True) \n",
    "    else: print(\"Warning: No data to build model with sample call.\")\n",
    "\n",
    "    lstm_model.compile(optimizer=Adam(learning_rate=0.001), loss='mse' ) # Start with a slightly higher LR\n",
    "    \n",
    "    if np.any(np.isnan(X_sequential_all)) or np.any(np.isinf(X_sequential_all)): print(\"CRITICAL WARNING: NaN/Inf in X_sequential_all.\")\n",
    "    if np.any(np.isnan(X_global_all)) or np.any(np.isinf(X_global_all)): print(\"CRITICAL WARNING: NaN/Inf in X_global_all.\")\n",
    "    if np.any(np.isnan(y_targets_all)) or np.any(np.isinf(y_targets_all)): print(\"CRITICAL WARNING: NaN/Inf in y_targets_all.\")\n",
    "    if len(y_targets_all) > 0 and np.all(np.abs(y_targets_all) <= 1e-6) : print(\"CRITICAL WARNING: All target total times are near zero.\")\n",
    "\n",
    "    target_scaler = StandardScaler()\n",
    "    y_targets_all_reshaped = y_targets_all.reshape(-1, 1)\n",
    "    global_feature_scaler = StandardScaler()\n",
    "    indices = np.arange(len(X_sequential_all))\n",
    "\n",
    "    if len(X_sequential_all) < 10: \n",
    "        print(\"Warning: Very few samples (<10), using all for training.\")\n",
    "        X_train_seq = X_sequential_all\n",
    "        X_train_glob_scaled = global_feature_scaler.fit_transform(X_global_all)\n",
    "        y_train_scaled = target_scaler.fit_transform(y_targets_all_reshaped)\n",
    "        validation_data_for_fit = None\n",
    "    else:\n",
    "        train_indices, val_indices = train_test_split(indices, test_size=val_split_ratio, random_state=42, shuffle=True)\n",
    "        X_train_seq = X_sequential_all[train_indices]; X_val_seq = X_sequential_all[val_indices]\n",
    "        X_train_glob = X_global_all[train_indices]; X_val_glob = X_global_all[val_indices]\n",
    "        X_train_glob_scaled = global_feature_scaler.fit_transform(X_train_glob) \n",
    "        X_val_glob_scaled = global_feature_scaler.transform(X_val_glob)     \n",
    "        y_train_orig_reshaped = y_targets_all_reshaped[train_indices]; y_val_orig_reshaped = y_targets_all_reshaped[val_indices]\n",
    "        y_train_scaled = target_scaler.fit_transform(y_train_orig_reshaped) \n",
    "        y_val_scaled = target_scaler.transform(y_val_orig_reshaped)         \n",
    "        validation_data_for_fit = ([X_val_seq, X_val_glob_scaled], y_val_scaled) \n",
    "        print(f\"\\nManually split data: {len(X_train_seq)} train, {len(X_val_seq)} validation samples.\")\n",
    "        print(f\"Training target stats (orig scale): Mean={np.mean(y_train_orig_reshaped):.2f}, Std={np.std(y_train_orig_reshaped):.2f}\")\n",
    "        print(f\"Validation target stats (orig scale): Mean={np.mean(y_val_orig_reshaped):.2f}, Std={np.std(y_val_orig_reshaped):.2f}\\n\")\n",
    "\n",
    "    callbacks_list = [\n",
    "        EarlyStopping(monitor='val_loss', patience=40, restore_best_weights=True, verbose=1), \n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=15, min_lr=1e-7, verbose=1) # Adjusted patience\n",
    "    ]\n",
    "    \n",
    "    print(\"Starting LSTM model training (with scaled targets and global features)...\")\n",
    "    history = lstm_model.fit(\n",
    "        [X_train_seq, X_train_glob_scaled], y_train_scaled,          \n",
    "        epochs=epochs, batch_size=batch_size,\n",
    "        validation_data=validation_data_for_fit, \n",
    "        callbacks=callbacks_list, verbose=1\n",
    "    )\n",
    "    \n",
    "    print(\"LSTM training finished.\")\n",
    "    data_for_lstm['target_scaler'] = target_scaler\n",
    "    data_for_lstm['global_feature_scaler'] = global_feature_scaler \n",
    "    return lstm_model, history, data_for_lstm\n",
    "\n",
    "# %%\n",
    "def generate_refined_predictions_with_lstm(lstm_model, processed_data):\n",
    "    \"\"\"\n",
    "    Generate refined time predictions with a cleaned-up CSV output.\n",
    "    Output CSV changed to _v12.\n",
    "    \"\"\"\n",
    "    print(\"Generating refined predictions using LSTM's total time...\")\n",
    "    \n",
    "    X_sequential_input_all = processed_data['X_sequential_input']\n",
    "    X_global_features_input_all_unscaled = processed_data['X_global_features_input']\n",
    "    \n",
    "    global_feature_scaler = processed_data['global_feature_scaler']\n",
    "    X_global_features_input_all_scaled = global_feature_scaler.transform(X_global_features_input_all_unscaled)\n",
    "\n",
    "    lstm_predicted_scaled_total_times = lstm_model.predict(\n",
    "        [X_sequential_input_all, X_global_features_input_all_scaled] \n",
    "    ) \n",
    "    \n",
    "    target_scaler = processed_data['target_scaler']\n",
    "    lstm_predicted_total_times_original_scale = target_scaler.inverse_transform(lstm_predicted_scaled_total_times)\n",
    "    lstm_predicted_total_times_original_scale = np.squeeze(lstm_predicted_total_times_original_scale)\n",
    "    lstm_predicted_total_times_original_scale = np.maximum(0, lstm_predicted_total_times_original_scale) \n",
    "\n",
    "    transformer_step_proportions = processed_data['transformer_proportions_padded'] \n",
    "    masks_for_calc = processed_data['masks_for_calc'] \n",
    "\n",
    "    _, lstm_refined_increments, lstm_refined_cumulative = calculate_times_from_proportions(\n",
    "        transformer_step_proportions,\n",
    "        lstm_predicted_total_times_original_scale, \n",
    "        masks_for_calc \n",
    "    )\n",
    "\n",
    "    lstm_refined_increments_np = lstm_refined_increments.numpy()\n",
    "    lstm_refined_cumulative_np = lstm_refined_cumulative.numpy()\n",
    "\n",
    "    results_list_df = []\n",
    "    original_dfs_from_processing = processed_data['original_dfs'] \n",
    "    gt_total_times_all = processed_data['y_lstm_target_total_times'] \n",
    "\n",
    "    for i, seq_id in enumerate(processed_data['sequences_ids']):\n",
    "        if i >= len(original_dfs_from_processing): continue\n",
    "        original_seq_df = original_dfs_from_processing[i]\n",
    "        seq_len = len(original_seq_df)\n",
    "        if seq_len == 0:\n",
    "            if original_seq_df.empty: results_list_df.append(original_seq_df) \n",
    "            continue\n",
    "        if i >= len(lstm_predicted_total_times_original_scale): continue\n",
    "\n",
    "        source_ids = original_seq_df['SourceID'].values\n",
    "        \n",
    "        output_dict = {\n",
    "            'Sequence': seq_id, 'Step': np.arange(1, seq_len + 1), 'SourceID': source_ids,\n",
    "            'GroundTruth_Increment': processed_data['gt_increments_padded_original'][i, :seq_len],\n",
    "            'GroundTruth_Cumulative': processed_data['gt_cumulative_padded_original'][i, :seq_len],\n",
    "            'LSTM_Predicted_Increment': lstm_refined_increments_np[i, :seq_len],\n",
    "            'LSTM_Predicted_Cumulative': lstm_refined_cumulative_np[i, :seq_len],\n",
    "            'LSTM_Predicted_TotalTime': np.full(seq_len, np.nan, dtype=np.float32),\n",
    "            'TotalTime_Difference': np.full(seq_len, np.nan, dtype=np.float32) \n",
    "        }\n",
    "        \n",
    "        predicted_total = lstm_predicted_total_times_original_scale[i]\n",
    "        gt_total = gt_total_times_all[i]\n",
    "        \n",
    "        output_dict['LSTM_Predicted_TotalTime'][-1] = predicted_total\n",
    "        output_dict['TotalTime_Difference'][-1] = gt_total - predicted_total \n",
    "\n",
    "        transformer_pred_increment = original_seq_df['Predicted_Increment'].fillna(0).values\n",
    "        transformer_pred_cumulative = original_seq_df['Predicted_Cumulative'].fillna(0).values\n",
    "        diff_transformer_inc = np.abs(output_dict['GroundTruth_Increment'] - transformer_pred_increment)\n",
    "        diff_lstm_inc = np.abs(output_dict['GroundTruth_Increment'] - output_dict['LSTM_Predicted_Increment'])\n",
    "        output_dict['Increment_Improvement_Pct'] = np.where(diff_transformer_inc > 1e-6, (diff_transformer_inc - diff_lstm_inc) / diff_transformer_inc * 100, 0 )\n",
    "        diff_transformer_cum = np.abs(output_dict['GroundTruth_Cumulative'] - transformer_pred_cumulative)\n",
    "        diff_lstm_cum = np.abs(output_dict['GroundTruth_Cumulative'] - output_dict['LSTM_Predicted_Cumulative'])\n",
    "        output_dict['Cumulative_Improvement_Pct'] = np.where(diff_transformer_cum > 1e-6, (diff_transformer_cum - diff_lstm_cum) / diff_transformer_cum * 100, 0 )\n",
    "        \n",
    "        clean_seq_df = pd.DataFrame(output_dict)\n",
    "        results_list_df.append(clean_seq_df)\n",
    "\n",
    "    if not results_list_df: return pd.DataFrame()\n",
    "    final_results_df = pd.concat(results_list_df, ignore_index=True)\n",
    "    \n",
    "    output_filename = 'predictions_lstm_refined_total_time_v12.csv' # Changed filename\n",
    "    final_results_df.to_csv(output_filename, index=False)\n",
    "    print(f\"Combined and refined predictions saved to {output_filename}\")\n",
    "    \n",
    "    if not final_results_df.empty:\n",
    "        original_df_full = pd.concat(original_dfs_from_processing, ignore_index=True)\n",
    "        merged_for_summary = pd.merge(final_results_df, original_df_full[['Sequence', 'Step', 'Predicted_Increment', 'Predicted_Cumulative']], on=['Sequence', 'Step'])\n",
    "        if 'Predicted_Increment' in merged_for_summary.columns and 'LSTM_Predicted_Increment' in merged_for_summary.columns:\n",
    "            mae_transformer = np.mean(np.abs(merged_for_summary['GroundTruth_Increment'] - merged_for_summary['Predicted_Increment']))\n",
    "            mae_lstm = np.mean(np.abs(merged_for_summary['GroundTruth_Increment'] - merged_for_summary['LSTM_Predicted_Increment']))\n",
    "            print(f\"\\nTransformer MAE (Increments): {mae_transformer:.4f}, LSTM-Refined MAE (Increments): {mae_lstm:.4f}\")\n",
    "            if mae_transformer > 1e-6: print(f\"Improvement (Increments): {(mae_transformer - mae_lstm) / mae_transformer * 100:.2f}%\")\n",
    "        if 'Predicted_Cumulative' in merged_for_summary.columns and 'LSTM_Predicted_Cumulative' in merged_for_summary.columns:\n",
    "            mae_transformer_cum = np.mean(np.abs(merged_for_summary['GroundTruth_Cumulative'] - merged_for_summary['Predicted_Cumulative']))\n",
    "            mae_lstm_cum = np.mean(np.abs(merged_for_summary['GroundTruth_Cumulative'] - merged_for_summary['LSTM_Predicted_Cumulative']))\n",
    "            print(f\"Transformer MAE (Cumulative): {mae_transformer_cum:.4f}, LSTM-Refined MAE (Cumulative): {mae_lstm_cum:.4f}\")\n",
    "            if mae_transformer_cum > 1e-6: print(f\"Improvement (Cumulative): {(mae_transformer_cum - mae_lstm_cum) / mae_transformer_cum * 100:.2f}%\")\n",
    "\n",
    "    gt_total_times_for_lstm_training = processed_data['y_lstm_target_total_times'] \n",
    "    if len(lstm_predicted_total_times_original_scale) == len(gt_total_times_for_lstm_training):\n",
    "        mae_total_time_lstm = np.mean(np.abs(gt_total_times_for_lstm_training - lstm_predicted_total_times_original_scale))\n",
    "        print(f\"\\nLSTM MAE for Total Time (vs Max GT Cumulative): {mae_total_time_lstm:.4f}\")\n",
    "\n",
    "    return final_results_df\n",
    "\n",
    "# %%\n",
    "def visualize_lstm_results(results_df, processed_data, lstm_model, training_history):\n",
    "    if results_df.empty: print(\"Results DataFrame is empty, skipping visualizations.\"); return\n",
    "    print(\"Generating visualizations for LSTM results...\")\n",
    "    plt.style.use('ggplot')\n",
    "    if training_history and hasattr(training_history, 'history'):\n",
    "        if 'loss' in training_history.history and 'val_loss' in training_history.history:\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            plt.plot(training_history.history['loss'], label='Training Loss')\n",
    "            plt.plot(training_history.history['val_loss'], label='Validation Loss')\n",
    "            if 'lr' in training_history.history:\n",
    "                ax2 = plt.gca().twinx(); ax2.plot(training_history.history['lr'], label='Learning Rate', color='g', linestyle='--')\n",
    "                ax2.set_ylabel('Learning Rate'); ax2.legend(loc='upper center')\n",
    "            plt.title('LSTM Model Loss (Predicting Scaled Total Time)') \n",
    "            plt.xlabel('Epoch'); plt.ylabel('Mean Squared Error (Scaled Loss)'); plt.legend(loc='upper left'); plt.tight_layout()\n",
    "            plt.savefig('lstm_total_time_training_loss_v12.png'); print(\"Saved LSTM training loss plot.\"); plt.close() # v12\n",
    "    else: print(\"Warning: Training history not available or malformed.\")\n",
    "\n",
    "    sample_sequence_ids = results_df['Sequence'].unique()\n",
    "    if len(sample_sequence_ids) == 0 : print(\"No sequences in results_df for plotting.\"); return\n",
    "    sample_sequence_ids = sample_sequence_ids[:min(5, len(sample_sequence_ids))]\n",
    "    \n",
    "    original_df_full = pd.concat(processed_data['original_dfs'], ignore_index=True)\n",
    "    plot_df = pd.merge(results_df, original_df_full[['Sequence', 'Step', 'Predicted_Cumulative', 'Predicted_Increment']], on=['Sequence', 'Step'], how='left')\n",
    "    \n",
    "    if len(sample_sequence_ids) > 0:\n",
    "        num_plots = len(sample_sequence_ids); fig_height = max(8, 3 * num_plots) \n",
    "        plt.figure(figsize=(15, fig_height)) # Cumulative Plot\n",
    "        for i, seq_id in enumerate(sample_sequence_ids):\n",
    "            seq_data_plot = plot_df[plot_df['Sequence'] == seq_id].sort_values('Step')\n",
    "            if seq_data_plot.empty: continue\n",
    "            plt.subplot(num_plots, 1, i + 1)\n",
    "            plt.plot(seq_data_plot['Step'], seq_data_plot['GroundTruth_Cumulative'], 'o-', label='GT Cumul.', ms=4)\n",
    "            if 'Predicted_Cumulative' in seq_data_plot.columns: plt.plot(seq_data_plot['Step'], seq_data_plot['Predicted_Cumulative'], 's--', label='Transformer Cumul.', ms=4)\n",
    "            if 'LSTM_Predicted_Cumulative' in seq_data_plot.columns: plt.plot(seq_data_plot['Step'], seq_data_plot['LSTM_Predicted_Cumulative'], '^-.', label='LSTM-Refined Cumul.', ms=4)\n",
    "            lstm_total_time_for_seq = seq_data_plot['LSTM_Predicted_TotalTime'].dropna().unique()\n",
    "            if len(lstm_total_time_for_seq) == 1: plt.axhline(y=lstm_total_time_for_seq[0], color='purple', linestyle=':', label=f'LSTM Total Pred: {lstm_total_time_for_seq[0]:.2f}')\n",
    "            plt.title(f'Cumulative Times: Seq {seq_id}'); plt.xlabel('Step'); plt.ylabel('Cumulative Time'); plt.legend()\n",
    "        plt.tight_layout(); plt.savefig('lstm_refined_cumulative_time_comparison_v12.png'); print(\"Saved cumulative time comparison plot.\"); plt.close() # v12\n",
    "\n",
    "        plt.figure(figsize=(15, fig_height)) # Increment Plot\n",
    "        for i, seq_id in enumerate(sample_sequence_ids):\n",
    "            seq_data_plot = plot_df[plot_df['Sequence'] == seq_id].sort_values('Step')\n",
    "            if seq_data_plot.empty: continue\n",
    "            plt.subplot(num_plots, 1, i + 1)\n",
    "            plt.plot(seq_data_plot['Step'], seq_data_plot['GroundTruth_Increment'], 'o-', label='GT Incr.', ms=4)\n",
    "            if 'Predicted_Increment' in seq_data_plot.columns: plt.plot(seq_data_plot['Step'], seq_data_plot['Predicted_Increment'], 's--', label='Transformer Incr.', ms=4)\n",
    "            if 'LSTM_Predicted_Increment' in seq_data_plot.columns: plt.plot(seq_data_plot['Step'], seq_data_plot['LSTM_Predicted_Increment'], '^-.', label='LSTM-Refined Incr.', ms=4)\n",
    "            plt.title(f'Time Increments: Seq {seq_id}'); plt.xlabel('Step'); plt.ylabel('Time Increment'); plt.legend()\n",
    "        plt.tight_layout(); plt.savefig('lstm_refined_increment_comparison_v12.png'); print(\"Saved increment comparison plot.\"); plt.close() # v12\n",
    "\n",
    "    gt_total_times_for_lstm_training = processed_data.get('y_lstm_target_total_times', np.array([])) \n",
    "    if lstm_model is not None and 'X_sequential_input' in processed_data and 'X_global_features_input' in processed_data and 'target_scaler' in processed_data:\n",
    "        X_seq_tensor = tf.convert_to_tensor(processed_data['X_sequential_input'], dtype=tf.float32)\n",
    "        X_glob_unscaled = processed_data['X_global_features_input']\n",
    "        X_glob_scaled_for_plot = processed_data['global_feature_scaler'].transform(X_glob_unscaled)\n",
    "        X_glob_tensor = tf.convert_to_tensor(X_glob_scaled_for_plot, dtype=tf.float32)\n",
    "        \n",
    "        lstm_pred_scaled_total_t = lstm_model.predict([X_seq_tensor, X_glob_tensor])\n",
    "        lstm_pred_original_scale_total_t = processed_data['target_scaler'].inverse_transform(lstm_pred_scaled_total_t).squeeze()\n",
    "        \n",
    "        if lstm_pred_original_scale_total_t.ndim == 0: lstm_pred_original_scale_total_t = np.array([lstm_pred_original_scale_total_t])\n",
    "            \n",
    "        if gt_total_times_for_lstm_training.size > 0 and lstm_pred_original_scale_total_t.size > 0:\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            plt.subplot(1, 2, 1); \n",
    "            plt.hist(gt_total_times_for_lstm_training, bins=30, alpha=0.7, label='GT Total Times (Max Cumul.)')\n",
    "            plt.hist(lstm_pred_original_scale_total_t, bins=30, alpha=0.7, label='LSTM Pred Total Times (Original Scale)')\n",
    "            plt.xlabel('Total Time'); plt.ylabel('Frequency'); plt.title('Distribution of Total Times'); plt.legend()\n",
    "            plt.subplot(1, 2, 2); \n",
    "            if len(gt_total_times_for_lstm_training) == len(lstm_pred_original_scale_total_t):\n",
    "                errors_total_time = gt_total_times_for_lstm_training - lstm_pred_original_scale_total_t\n",
    "                plt.hist(errors_total_time, bins=30, alpha=0.7, color='red')\n",
    "                plt.xlabel('Prediction Error (GT Max Cumul. - Pred)'); plt.ylabel('Frequency'); plt.title('LSTM Total Time Prediction Errors')\n",
    "                if errors_total_time.size > 0: \n",
    "                    mean_error_val = errors_total_time.mean(); plt.axvline(mean_error_val, color='k', ls='--', lw=1, label=f'Mean Error: {mean_error_val:.2f}')\n",
    "                plt.legend()\n",
    "            else: print(\"Warning: Mismatch length GT total times and predictions for error histogram.\")\n",
    "            plt.tight_layout(); plt.savefig('lstm_total_time_prediction_analysis_v12.png'); print(\"Saved total time prediction analysis plot.\"); plt.close() # v12\n",
    "        else: print(\"Warning: Not enough data for total time distribution plots.\")\n",
    "    else: print(\"Warning: LSTM model, input data, or scaler missing for total time prediction plot.\")\n",
    "    print(\"Visualizations for LSTM completed!\")\n",
    "\n",
    "# %%\n",
    "def main_lstm_total_time_flow():\n",
    "    try:\n",
    "        transformer_predictions_file = \"predictions_transformer_182625.csv\" \n",
    "        if not os.path.exists(transformer_predictions_file):\n",
    "            print(f\"Error: Transformer predictions file not found: {transformer_predictions_file}\")\n",
    "            print(\"Creating DUMMY CSV for testing flow.\")\n",
    "            dummy_data = []\n",
    "            for seq_idx in range(300): \n",
    "                num_steps = np.random.randint(10, 60) \n",
    "                steps = np.arange(1, num_steps + 1)\n",
    "                gt_increments = np.random.lognormal(mean=2.0, sigma=0.7, size=num_steps) + 0.1 \n",
    "                gt_increments = np.maximum(gt_increments, 0.01) \n",
    "                gt_cumulative = np.cumsum(gt_increments)\n",
    "                \n",
    "                raw_props = np.random.rand(num_steps) + 0.05 \n",
    "                pred_proportions = raw_props / raw_props.sum() \n",
    "                \n",
    "                actual_sequence_total_time = gt_cumulative[-1] if num_steps > 0 else 1.0\n",
    "                actual_sequence_total_time = max(actual_sequence_total_time, 1.0) \n",
    "\n",
    "                dummy_transformer_effective_total_time = actual_sequence_total_time * np.random.normal(loc=1.0, scale=0.4) \n",
    "                dummy_transformer_effective_total_time = max(dummy_transformer_effective_total_time, 0.1)\n",
    "\n",
    "                pred_increments_from_transformer = pred_proportions * dummy_transformer_effective_total_time\n",
    "                pred_cumulative_from_transformer = np.cumsum(pred_increments_from_transformer)\n",
    "\n",
    "                for s_idx in range(num_steps):\n",
    "                    dummy_data.append({\n",
    "                        'Sequence': seq_idx, 'Step': steps[s_idx], 'SourceID': f'MRI_DUMMY_{s_idx%5 +1}',\n",
    "                        'Predicted_Proportion': pred_proportions[s_idx], \n",
    "                        'Predicted_Increment': pred_increments_from_transformer[s_idx],\n",
    "                        'Predicted_Cumulative': pred_cumulative_from_transformer[s_idx], \n",
    "                        'GroundTruth_Increment': gt_increments[s_idx], \n",
    "                        'GroundTruth_Cumulative': gt_cumulative[s_idx]  })\n",
    "            if not dummy_data: \n",
    "                 dummy_data.append({ 'Sequence': 0, 'Step': 1, 'SourceID': 'MRI_DUMMY_0', 'Predicted_Proportion': 1.0, \n",
    "                                     'Predicted_Increment': 10.0, 'Predicted_Cumulative': 10.0, \n",
    "                                     'GroundTruth_Increment': 10.0, 'GroundTruth_Cumulative': 10.0})\n",
    "            dummy_df = pd.DataFrame(dummy_data)\n",
    "            dummy_df.to_csv(transformer_predictions_file, index=False)\n",
    "            print(f\"Dummy '{transformer_predictions_file}' created with {len(dummy_df)} rows and {len(dummy_df['Sequence'].unique())} sequences.\")\n",
    "        \n",
    "        lstm_model, lstm_history, processed_lstm_data = train_total_time_lstm(\n",
    "            transformer_predictions_file, epochs=200, batch_size=32 ) \n",
    "        \n",
    "        if lstm_model is None or processed_lstm_data is None:\n",
    "            print(\"LSTM training failed or returned None. Exiting.\"); return\n",
    "\n",
    "        refined_results_df = generate_refined_predictions_with_lstm(lstm_model, processed_lstm_data)\n",
    "        if not refined_results_df.empty:\n",
    "            print(\"\\nSample of Refined Predictions (LSTM Total Time Approach - v12):\")\n",
    "            display_cols = [ 'Sequence', 'Step', 'SourceID', \n",
    "                             'LSTM_Predicted_Increment', 'GroundTruth_Increment', \n",
    "                             'LSTM_Predicted_Cumulative', 'GroundTruth_Cumulative',\n",
    "                             'LSTM_Predicted_TotalTime', 'TotalTime_Difference', 'Increment_Improvement_Pct']\n",
    "            actual_display_cols = [col for col in display_cols if col in refined_results_df.columns]\n",
    "            print(refined_results_df[actual_display_cols].head(20))\n",
    "            print(\"\\nGenerating visualizations for LSTM (total time approach - v12)...\")\n",
    "            visualize_lstm_results(refined_results_df, processed_lstm_data, lstm_model, lstm_history)\n",
    "        else: print(\"No refined predictions were generated by the LSTM flow.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error in LSTM (total time) main function: {e}\"); import traceback; traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data for LSTM training...\n",
      "Processing data from: predictions_transformer_182625.csv\n",
      "\n",
      "Statistics for TARGET y_total_times_list (max GT_Cumulative per seq, 186 sequences):\n",
      "  Mean: 374.8065, Std Dev: 348.4868\n",
      "  Min: 0.0000, Max: 2900.0000\n",
      "  Number of zeros (<=1e-6): 5\n",
      "\n",
      "Num sequential features: 2, Max seq length: 42\n",
      "Num global features: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lukis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\layers\\layer.py:1381: UserWarning: Layer 'total_time_lstm_3' looks like it has unbuilt state, but Keras is not able to trace the layer `call()` in order to build it automatically. Possible causes:\n",
      "1. The `call()` method of your layer may be crashing. Try to `__call__()` the layer eagerly on some test input first to see if it works. E.g. `x = np.random.random((3, 4)); y = layer(x)`\n",
      "2. If the `call()` method is correct, then you may need to implement the `def build(self, input_shape)` method on your layer. It should create all variables used by the layer (e.g. by calling `layer.build()` on all its children layers).\n",
      "Exception encountered: ''A `Concatenate` layer requires inputs with matching shapes except for the concatenation axis. Received: input_shape=[(1, 42, 512), (1, 5)]''\n",
      "  warnings.warn(\n",
      "C:\\Users\\lukis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\layers\\layer.py:391: UserWarning: `build()` was called on layer 'total_time_lstm_3', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in LSTM (total time) main function: Exception encountered when calling TotalTimeLSTM.call().\n",
      "\n",
      "\u001b[1mA `Concatenate` layer requires inputs with matching shapes except for the concatenation axis. Received: input_shape=[(1, 42, 512), (1, 5)]\u001b[0m\n",
      "\n",
      "Arguments received by TotalTimeLSTM.call():\n",
      "  • inputs=('tf.Tensor(shape=(1, 42, 2), dtype=float32)', 'tf.Tensor(shape=(1, 5), dtype=float32)')\n",
      "  • training=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\lukis\\AppData\\Local\\Temp\\ipykernel_58968\\3352933476.py\", line 513, in main_lstm_total_time_flow\n",
      "    lstm_model, lstm_history, processed_lstm_data = train_total_time_lstm(\n",
      "  File \"C:\\Users\\lukis\\AppData\\Local\\Temp\\ipykernel_58968\\3352933476.py\", line 226, in train_total_time_lstm\n",
      "    _ = lstm_model((sample_seq_input_for_build, sample_glob_input_for_build))\n",
      "  File \"C:\\Users\\lukis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\lukis\\AppData\\Local\\Temp\\ipykernel_58968\\3352933476.py\", line 93, in call\n",
      "    combined_features = self.concat_layer([attention_output, global_features_input])\n",
      "ValueError: Exception encountered when calling TotalTimeLSTM.call().\n",
      "\n",
      "\u001b[1mA `Concatenate` layer requires inputs with matching shapes except for the concatenation axis. Received: input_shape=[(1, 42, 512), (1, 5)]\u001b[0m\n",
      "\n",
      "Arguments received by TotalTimeLSTM.call():\n",
      "  • inputs=('tf.Tensor(shape=(1, 42, 2), dtype=float32)', 'tf.Tensor(shape=(1, 5), dtype=float32)')\n",
      "  • training=False\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "if __name__ == \"__main__\":\n",
    "    main_lstm_total_time_flow()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
