{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "7ef0a5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "1dbc4cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants and Encoding\n",
    "START_TOKEN = 13\n",
    "END_TOKEN = 14\n",
    "# Add a PAD token if not using mask_zero, but we are using mask_zero=END_TOKEN\n",
    "# So tokens 0-12 are source IDs, 13 is START, 14 is END (and PAD)\n",
    "ENCODING_LEGEND = {\n",
    "    'MRI_CCS_11': 1, 'MRI_EXU_95': 2, 'MRI_FRR_18': 3, 'MRI_FRR_257': 4,\n",
    "    'MRI_FRR_264': 5, 'MRI_FRR_2': 6, 'MRI_FRR_3': 7, 'MRI_FRR_34': 8, 'MRI_MPT_1005': 9,\n",
    "    'MRI_MSR_100': 10, 'MRI_MSR_104': 11, 'MRI_MSR_21': 12, 'MRI_MSR_24': 99,\n",
    "    'START': START_TOKEN, 'END': END_TOKEN\n",
    "}\n",
    "reverse_encoding = {v: k for k, v in ENCODING_LEGEND.items()}\n",
    "\n",
    "# Define valid source IDs for filtering (excluding START and END tokens)\n",
    "VALID_SOURCE_IDS = set([k for k in ENCODING_LEGEND.keys() if k not in ['START', 'END']])\n",
    "\n",
    "# Define the columns from the original data to keep in the final output\n",
    "COLUMNS_TO_KEEP = [\n",
    "    'timediff', 'PTAB', 'BodyGroup_from', 'BodyGroup_to', 'PatientID_from',\n",
    "    'PatientID_to', 'patient_height', 'patient_weight', 'patient_age', 'patient_gender'\n",
    "]\n",
    "\n",
    "# Binning parameters\n",
    "NUM_BINS = 250\n",
    "# Define bin edges from 0 to 1 (inclusive of 0, exclusive of 1 for all but the last bin)\n",
    "# The last bin will include 1.0\n",
    "BIN_EDGES = np.linspace(0.0, 1.0, NUM_BINS + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c212b712",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data(data_file):\n",
    "    \"\"\"\n",
    "    Loads and preprocesses data from a CSV file, filtering out invalid sourceIDs.\n",
    "    Splits data into sequences based on 'MRI_MSR_104' (start) and 'MRI_MSR_100' (end).\n",
    "    Assigns a sequence number during loading and keeps specified additional columns.\n",
    "    \"\"\"\n",
    "    print(f\"Loading data from {data_file}...\")\n",
    "    data = pd.read_csv(data_file)\n",
    "\n",
    "    all_sequences_tokens = []\n",
    "    all_sequences_times = []\n",
    "    all_sequences_sourceids = []\n",
    "    all_sequences_extra_data = [] # New: To store the extra columns\n",
    "\n",
    "    current_tokens = []\n",
    "    current_times = []\n",
    "    current_sourceids = []\n",
    "    current_extra_data = [] # New: For the current sequence\n",
    "\n",
    "    # Iterate through rows to build sequences\n",
    "    for idx, row in data.iterrows():\n",
    "        s_id = str(row['sourceID'])\n",
    "        t_diff = float(row['timediff'])\n",
    "\n",
    "        if s_id not in VALID_SOURCE_IDS:\n",
    "            continue\n",
    "\n",
    "        # New: Extract extra data for the current valid row\n",
    "        extra_data = {col: row.get(col) for col in COLUMNS_TO_KEEP}\n",
    "\n",
    "        if s_id == 'MRI_MSR_104':\n",
    "            if current_tokens:\n",
    "                token_seq = [START_TOKEN] + [int(ENCODING_LEGEND[x]) for x in current_tokens] + [END_TOKEN]\n",
    "                time_seq = [0.0] + current_times\n",
    "                all_sequences_tokens.append(token_seq)\n",
    "                all_sequences_times.append(time_seq)\n",
    "                all_sequences_sourceids.append(current_sourceids)\n",
    "                all_sequences_extra_data.append(current_extra_data) # New\n",
    "\n",
    "            current_tokens = [s_id]\n",
    "            current_times = [t_diff]\n",
    "            current_sourceids = [s_id]\n",
    "            current_extra_data = [extra_data] # New\n",
    "\n",
    "        elif s_id == 'MRI_MSR_100':\n",
    "            if current_tokens:\n",
    "                current_tokens.append(s_id)\n",
    "                current_times.append(t_diff)\n",
    "                current_sourceids.append(s_id)\n",
    "                current_extra_data.append(extra_data) # New\n",
    "\n",
    "                token_seq = [START_TOKEN] + [int(ENCODING_LEGEND[x]) for x in current_tokens] + [END_TOKEN]\n",
    "                time_seq = [0.0] + current_times\n",
    "                all_sequences_tokens.append(token_seq)\n",
    "                all_sequences_times.append(time_seq)\n",
    "                all_sequences_sourceids.append(current_sourceids)\n",
    "                all_sequences_extra_data.append(current_extra_data) # New\n",
    "\n",
    "                current_tokens, current_times, current_sourceids, current_extra_data = [], [], [], [] # New\n",
    "\n",
    "        elif current_tokens:\n",
    "            current_tokens.append(s_id)\n",
    "            current_times.append(t_diff)\n",
    "            current_sourceids.append(s_id)\n",
    "            current_extra_data.append(extra_data) # New\n",
    "\n",
    "    if current_tokens:\n",
    "        token_seq = [START_TOKEN] + [int(ENCODING_LEGEND[x]) for x in current_tokens] + [END_TOKEN]\n",
    "        time_seq = [0.0] + current_times\n",
    "        all_sequences_tokens.append(token_seq)\n",
    "        all_sequences_times.append(time_seq)\n",
    "        all_sequences_sourceids.append(current_sourceids)\n",
    "        all_sequences_extra_data.append(current_extra_data) # New\n",
    "\n",
    "    print(f\"Loaded {len(all_sequences_tokens)} sequences.\")\n",
    "    # New: Return the extra data list as well\n",
    "    return all_sequences_tokens, all_sequences_times, all_sequences_sourceids, all_sequences_extra_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "08ed1488",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bin_indices(proportions, bin_edges):\n",
    "    \"\"\"\n",
    "    Maps continuous proportions to discrete bin indices.\n",
    "    Handles the edge case for the maximum value (1.0).\n",
    "    \"\"\"\n",
    "    proportions = np.clip(proportions, bin_edges[0], bin_edges[-1])\n",
    "    bin_indices = np.digitize(proportions, bin_edges, right=True) - 1\n",
    "    bin_indices[proportions == bin_edges[-1]] = len(bin_edges) - 2\n",
    "    bin_indices = np.clip(bin_indices, 0, len(bin_edges) - 2)\n",
    "    return bin_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "fc835006",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bin_centers(bin_indices, bin_edges):\n",
    "    \"\"\"\n",
    "    Returns the center value for a given array of bin indices.\n",
    "    \"\"\"\n",
    "    bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "    return bin_centers[bin_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "f9962b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_training_data(sequences_tokens, sequences_times, bin_edges):\n",
    "    \"\"\"\n",
    "    Prepares sequences for transformer training, including padding and masks.\n",
    "    Calculates target cumulative times, total times, and binned proportion targets.\n",
    "    \"\"\"\n",
    "    X_list, Y_list, masks_list, total_times_list, Y_binned_list = [], [], [], [], []\n",
    "\n",
    "    for tokens, times in zip(sequences_tokens, sequences_times):\n",
    "        if len(tokens) < 3:\n",
    "            continue\n",
    "        total_time = times[-1]\n",
    "        x_seq = tokens[:-1]\n",
    "        y_seq = times[1:]\n",
    "        time_diffs_unpadded = np.diff(times)\n",
    "        true_total = times[-1]\n",
    "        true_total_safe = true_total if true_total > 0 else 1.0\n",
    "        true_props_unpadded = time_diffs_unpadded / true_total_safe\n",
    "        true_props_padded = np.pad(true_props_unpadded, (1, 0), constant_values=0.0)\n",
    "        y_binned_seq = get_bin_indices(true_props_padded, bin_edges)\n",
    "        mask_seq = [1 if t != END_TOKEN else 0 for t in x_seq]\n",
    "\n",
    "        X_list.append(x_seq)\n",
    "        Y_list.append(y_seq)\n",
    "        masks_list.append(mask_seq)\n",
    "        total_times_list.append(total_time)\n",
    "        Y_binned_list.append(y_binned_seq)\n",
    "\n",
    "    if not X_list:\n",
    "        print(\"No valid sequences found after preprocessing.\")\n",
    "        return np.array([]), np.array([]), np.array([]), np.array([]), np.array([])\n",
    "\n",
    "    max_len = max(len(x) for x in X_list)\n",
    "    print(f\"Padding sequences to max length: {max_len}\")\n",
    "\n",
    "    X_train = pad_sequences(X_list, maxlen=max_len, padding='post', value=END_TOKEN)\n",
    "    Y_cum_target = pad_sequences(Y_list, maxlen=max_len, padding='post', value=0.0)\n",
    "    mask_train = pad_sequences(masks_list, maxlen=max_len, padding='post', value=0)\n",
    "    Y_binned_target = pad_sequences(Y_binned_list, maxlen=max_len, padding='post', value=0)\n",
    "\n",
    "    X_train = np.array(X_train, dtype=np.int32)\n",
    "    Y_cum_target = np.array(Y_cum_target, dtype=np.float32)\n",
    "    mask_train = np.array(mask_train, dtype=np.float32)\n",
    "    total_times = np.array(total_times_list, dtype=np.float32)\n",
    "    Y_binned_target = np.array(Y_binned_target, dtype=np.int32)\n",
    "\n",
    "    print(f\"Prepared {X_train.shape[0]} sequences for training.\")\n",
    "    return X_train, Y_cum_target, mask_train, total_times, Y_binned_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "a0d10f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Transformer Components (unchanged)\n",
    "# ----------------------------\n",
    "def positional_encoding(length, depth):\n",
    "    depth = depth / 2\n",
    "    positions = np.arange(length)[:, np.newaxis]\n",
    "    depths = np.arange(depth)[np.newaxis, :] / depth\n",
    "    angle_rates = 1 / (10000 ** depths)\n",
    "    angle_rads = positions * angle_rates\n",
    "    pos_encoding = np.concatenate([np.sin(angle_rads), np.cos(angle_rads)], axis=-1)\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)\n",
    "\n",
    "class PositionalEmbedding(layers.Layer):\n",
    "    def __init__(self, vocab_size, d_model, max_len=16384, use_embedding=True):\n",
    "        super(PositionalEmbedding, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.use_embedding = use_embedding\n",
    "        if self.use_embedding:\n",
    "            # Set mask_zero to the actual padding value (END_TOKEN)\n",
    "            self.embedding = layers.Embedding(vocab_size, d_model, mask_zero=END_TOKEN)\n",
    "        else:\n",
    "            # If not using embedding, assume input is already dense (e.g., time features)\n",
    "            self.embedding = layers.Dense(d_model, activation=\"relu\")\n",
    "        self.max_len = max_len\n",
    "        # Ensure pos_encoding is created once and is large enough\n",
    "        self.pos_encoding = positional_encoding(self.max_len, d_model)\n",
    "\n",
    "    # Correct compute_mask signature to accept optional mask argument\n",
    "    def compute_mask(self, x, mask=None):\n",
    "         # If using embedding with mask_zero, the mask is computed based on mask_zero value\n",
    "         if self.use_embedding:\n",
    "              # Return a boolean mask indicating which elements are NOT the mask_zero value\n",
    "              return tf.math.not_equal(x, self.embedding.mask_zero)\n",
    "         # Otherwise, assume all steps are valid unless explicitly masked later\n",
    "         return None\n",
    "\n",
    "    def call(self, x):\n",
    "        # x is assumed to be token IDs if use_embedding is True, otherwise dense features\n",
    "        if self.use_embedding:\n",
    "            # The embedding layer itself computes and propagates the mask because mask_zero is set\n",
    "            x = self.embedding(x)\n",
    "        else:\n",
    "             # Apply dense layer if input is not token IDs\n",
    "             x = self.embedding(x)\n",
    "\n",
    "        # Scale the embedding output\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "\n",
    "        # Add positional encoding\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        # Ensure positional encoding slice matches sequence length\n",
    "        x += self.pos_encoding[tf.newaxis, :seq_len, :]\n",
    "        return x\n",
    "\n",
    "class FeedForward(layers.Layer):\n",
    "    def __init__(self, d_model, dff, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.seq = tf.keras.Sequential([\n",
    "            layers.Dense(dff, activation='relu'),\n",
    "            layers.Dense(d_model),\n",
    "            layers.Dropout(dropout_rate)\n",
    "        ])\n",
    "        self.add = layers.Add()\n",
    "        self.layer_norm = layers.LayerNormalization()\n",
    "\n",
    "    def call(self, x):\n",
    "        # Apply feed forward network with residual connection and layer normalization\n",
    "        x = self.add([x, self.seq(x)])\n",
    "        x = self.layer_norm(x)\n",
    "        return x\n",
    "\n",
    "class CausalSelfAttention(layers.Layer):\n",
    "    def __init__(self, num_heads, d_model, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        # MultiHeadAttention layer with causal mask\n",
    "        self.mha = layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model, dropout=dropout_rate)\n",
    "        self.add = layers.Add()\n",
    "        self.layer_norm = layers.LayerNormalization()\n",
    "\n",
    "    def call(self, x):\n",
    "        # Apply multi-head self-attention\n",
    "        # Keras automatically uses the mask attached to the input 'x'\n",
    "        attn_output = self.mha(query=x, key=x, value=x, use_causal_mask=True)\n",
    "        # Add residual connection and layer normalization\n",
    "        x = self.add([x, attn_output])\n",
    "        x = self.layer_norm(x)\n",
    "        return x\n",
    "\n",
    "class SelfAttentionFeedForwardLayer(layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        # Composes CausalSelfAttention and FeedForward layers\n",
    "        self.self_attention = CausalSelfAttention(num_heads=num_heads, d_model=d_model, dropout_rate=dropout_rate)\n",
    "        self.ffn = FeedForward(d_model, dff, dropout_rate)\n",
    "\n",
    "    def call(self, x):\n",
    "        # Pass input through self-attention and then feed-forward network\n",
    "        # Mask from 'x' is propagated through these layers\n",
    "        x = self.self_attention(x)\n",
    "        x = self.ffn(x)\n",
    "        return x\n",
    "\n",
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, vocab_size, dropout_rate=0.1, max_len=16384):\n",
    "        super().__init__()\n",
    "        # Positional embedding for the input tokens\n",
    "        self.pos_embedding = PositionalEmbedding(vocab_size, d_model, max_len=max_len)\n",
    "        # Stack of encoder layers\n",
    "        self.enc_layers = [SelfAttentionFeedForwardLayer(d_model, num_heads, dff, dropout_rate)\n",
    "                           for _ in range(num_layers)]\n",
    "        self.dropout = layers.Dropout(dropout_rate)\n",
    "\n",
    "    def call(self, x):\n",
    "        # Apply positional embedding and dropout.\n",
    "        # The output 'x' from pos_embedding will carry the mask computed by PositionalEmbedding.compute_mask.\n",
    "        x = self.pos_embedding(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # Pass through encoder layers. Keras will automatically propagate the mask\n",
    "        # through the layers that support masking (like MultiHeadAttention).\n",
    "        for layer in self.enc_layers:\n",
    "            x = layer(x)\n",
    "\n",
    "        return x # The output tensor carries the mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "513c2d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeDiffTransformer(tf.keras.Model):\n",
    "    \"\"\"\n",
    "    Transformer model predicting proportions of total time for each sequence step.\n",
    "    This version predicts a probability distribution over bins for proportions.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, num_bins, dropout_rate=0.1, max_len=16384):\n",
    "        super().__init__()\n",
    "        # Encoder processes the input sequence of tokens\n",
    "        self.encoder = Encoder(num_layers, d_model, num_heads, dff, input_vocab_size, dropout_rate, max_len)\n",
    "\n",
    "        # Head to predict the probability distribution over bins for proportions\n",
    "        # Output is NUM_BINS values per sequence step with softmax activation\n",
    "        self.proportion_head = layers.Dense(num_bins, activation='softmax')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Pass input through the encoder\n",
    "        encoder_out = self.encoder(inputs) # encoder_out shape: (batch_size, seq_len, d_model)\n",
    "        # The mask from the embedding layer is propagated to encoder_out\n",
    "\n",
    "        # Predict probability distribution over bins for each step\n",
    "        # pred_bin_probs shape: (batch_size, seq_len, num_bins)\n",
    "        pred_bin_probs = self.proportion_head(encoder_out)\n",
    "\n",
    "        # Return the predicted bin probabilities\n",
    "        return pred_bin_probs # pred_bin_probs shape: (batch_size, seq_len, num_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "b0b8175a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_transformer(data_file, epochs=50, batch_size=32, num_bins=NUM_BINS, bin_edges=BIN_EDGES):\n",
    "    try:\n",
    "        sequences_tokens, sequences_times, sequences_sourceids, sequences_extra_data = load_and_preprocess_data(data_file)\n",
    "        X_train, Y_cum_target, mask_train, total_times, Y_binned_target = prepare_training_data(\n",
    "            sequences_tokens, sequences_times, bin_edges\n",
    "        )\n",
    "\n",
    "        if X_train.shape[0] == 0:\n",
    "            print(\"No data available for training after preprocessing.\")\n",
    "            return None, None, None, None, None, None, None, None\n",
    "\n",
    "        vocab_size = max(ENCODING_LEGEND.values()) + 1\n",
    "        max_seq_len = X_train.shape[1]\n",
    "        model = TimeDiffTransformer(\n",
    "            num_layers=3, d_model=64, num_heads=8, dff=128,\n",
    "            input_vocab_size=vocab_size, num_bins=num_bins,\n",
    "            dropout_rate=0.1, max_len=max_seq_len\n",
    "        )\n",
    "        optimizer = tf.keras.optimizers.Adam()\n",
    "        proportion_loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "\n",
    "        @tf.function\n",
    "        def train_step(x, y_binned, mask):\n",
    "            with tf.GradientTape() as tape:\n",
    "                pred_bin_probs = model(x)\n",
    "                mask_float = tf.cast(mask, tf.float32)\n",
    "                masked_props_loss = proportion_loss_fn(y_binned, pred_bin_probs, sample_weight=mask_float)\n",
    "                total_loss = masked_props_loss\n",
    "            grads = tape.gradient(total_loss, model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "            return total_loss, masked_props_loss\n",
    "\n",
    "        print(\"Starting training...\")\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices((X_train, Y_binned_target, mask_train)).batch(batch_size)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            total_epoch_loss, total_proportion_loss, num_batches = 0, 0, 0\n",
    "            for step, (batch_x, batch_y_binned, batch_mask) in enumerate(train_dataset):\n",
    "                loss, props_loss = train_step(batch_x, batch_y_binned, batch_mask)\n",
    "                total_epoch_loss += loss\n",
    "                total_proportion_loss += props_loss\n",
    "                num_batches += 1\n",
    "            avg_epoch_loss = total_epoch_loss / num_batches if num_batches > 0 else 0\n",
    "            avg_proportion_loss = total_proportion_loss / num_batches if num_batches > 0 else 0\n",
    "            if (epoch + 1) % 10 == 0:\n",
    "                print(f\"Epoch {epoch+1}/{epochs} - Total Loss: {avg_epoch_loss.numpy():.4f} - Proportion Loss: {avg_proportion_loss.numpy():.4f}\")\n",
    "\n",
    "        print(\"Training finished.\")\n",
    "        return model, X_train, Y_cum_target, mask_train, total_times, sequences_sourceids, Y_binned_target, sequences_extra_data\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in train_transformer: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None, None, None, None, None, None, None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "fa84d146",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_time_differences(proportions, total_time, mask):\n",
    "    proportions *= tf.cast(mask, tf.float32)\n",
    "    row_sums = tf.reduce_sum(proportions, axis=1, keepdims=True)\n",
    "    row_sums = tf.where(tf.equal(row_sums, 0), tf.ones_like(row_sums), row_sums)\n",
    "    proportions /= row_sums\n",
    "    increments = proportions * total_time\n",
    "    cumulative_times = tf.math.cumsum(increments, axis=1)\n",
    "    return proportions, increments, cumulative_times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "87e14b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_predictions_csv(model, X_train, Y_cum_target, mask_train, total_times, sequences_sourceids, sequences_extra_data, bin_edges):\n",
    "    \"\"\"\n",
    "    Generates predictions and saves to CSV, including additional original data columns.\n",
    "    \"\"\"\n",
    "    if model is None:\n",
    "        print(\"Model is None, cannot generate predictions.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    print(\"Generating predictions...\")\n",
    "\n",
    "    # --- Prediction and calculation logic remains the same ---\n",
    "    pred_bin_probs = model(X_train)\n",
    "    predicted_bin_indices = tf.argmax(pred_bin_probs, axis=-1, output_type=tf.int32)\n",
    "    predicted_proportions_continuous = get_bin_centers(predicted_bin_indices.numpy(), bin_edges)\n",
    "    total_times_tf = tf.constant(total_times, dtype=tf.float32)\n",
    "    total_times_expanded = tf.expand_dims(total_times_tf, axis=1)\n",
    "    proportions_pred_norm, increments_pred, cumulative_pred = compute_time_differences(\n",
    "        tf.constant(predicted_proportions_continuous, dtype=tf.float32),\n",
    "        total_times_expanded,\n",
    "        mask_train\n",
    "    )\n",
    "    proportions_pred_np = proportions_pred_norm.numpy()\n",
    "    increments_pred_np = increments_pred.numpy()\n",
    "    cumulative_pred_np = cumulative_pred.numpy()\n",
    "    X_train_np, Y_cum_target_np, mask_train_np = X_train, Y_cum_target, mask_train\n",
    "    gt_increments = np.zeros_like(Y_cum_target_np)\n",
    "    gt_increments[:, 0] = Y_cum_target_np[:, 0]\n",
    "    gt_increments[:, 1:] = Y_cum_target_np[:, 1:] - Y_cum_target_np[:, :-1]\n",
    "    gt_increments *= mask_train_np\n",
    "    # --- End of unchanged prediction logic ---\n",
    "\n",
    "    output_records = []\n",
    "    for seq_idx in range(X_train_np.shape[0]):\n",
    "        valid_mask = mask_train_np[seq_idx] == 1\n",
    "        valid_indices = np.where(valid_mask)[0]\n",
    "        safe_sourceids = sequences_sourceids[seq_idx] if seq_idx < len(sequences_sourceids) else []\n",
    "        safe_extra_data = sequences_extra_data[seq_idx] if seq_idx < len(sequences_extra_data) else [] # New\n",
    "        step_counter = 1\n",
    "\n",
    "        for i in range(len(valid_indices)):\n",
    "            valid_idx = valid_indices[i]\n",
    "            if valid_idx > 0:\n",
    "                source_id_index = valid_idx - 1\n",
    "                if source_id_index < len(safe_sourceids):\n",
    "                    source_id = safe_sourceids[source_id_index]\n",
    "                    \n",
    "                    # New: Get the extra data for this specific step\n",
    "                    extra_data_record = safe_extra_data[source_id_index] if source_id_index < len(safe_extra_data) else {}\n",
    "\n",
    "                    # Create the base record with predictions and ground truth\n",
    "                    record = {\n",
    "                        'Sequence': seq_idx,\n",
    "                        'Step': step_counter,\n",
    "                        'SourceID': source_id,\n",
    "                        'Predicted_Proportion': proportions_pred_np[seq_idx, valid_idx],\n",
    "                        'Predicted_Increment': increments_pred_np[seq_idx, valid_idx],\n",
    "                        'Predicted_Cumulative': cumulative_pred_np[seq_idx, valid_idx],\n",
    "                        'GroundTruth_Increment': gt_increments[seq_idx, valid_idx],\n",
    "                        'GroundTruth_Cumulative': Y_cum_target_np[seq_idx, valid_idx]\n",
    "                    }\n",
    "                    \n",
    "                    # New: Merge the extra data into the record\n",
    "                    record.update(extra_data_record)\n",
    "                    output_records.append(record)\n",
    "                    step_counter += 1\n",
    "\n",
    "    # New: Define final column order, including the kept columns\n",
    "    final_column_order = [\n",
    "        'Sequence', 'Step', 'SourceID', 'Predicted_Proportion',\n",
    "        'Predicted_Increment', 'Predicted_Cumulative',\n",
    "        'GroundTruth_Increment', 'GroundTruth_Cumulative'\n",
    "    ] + COLUMNS_TO_KEEP\n",
    "\n",
    "    if not output_records:\n",
    "        print(\"Warning: No valid prediction records generated.\")\n",
    "        predictions_df = pd.DataFrame(columns=final_column_order)\n",
    "    else:\n",
    "        predictions_df = pd.DataFrame(output_records)\n",
    "        # Reorder columns and ensure all are present\n",
    "        existing_cols = [col for col in final_column_order if col in predictions_df.columns]\n",
    "        predictions_df = predictions_df[existing_cols]\n",
    "\n",
    "    output_csv_path = 'predictions_transformer_175651_with_details.csv' # New output filename\n",
    "    try:\n",
    "        predictions_df.to_csv(output_csv_path, index=False)\n",
    "        print(f\"Predictions saved successfully to {output_csv_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving predictions to CSV: {e}\")\n",
    "\n",
    "    return predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "db1ca18d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from data/175651/encoded_175651_condensed_with_dummy_data.csv...\n",
      "Loaded 101 sequences.\n",
      "Padding sequences to max length: 54\n",
      "Prepared 101 sequences for training.\n",
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lukis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'query' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lukis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'key' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lukis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'value' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lukis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'causal_self_attention_33' (of type CausalSelfAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lukis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'sequential_33' (of type Sequential) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lukis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'feed_forward_33' (of type FeedForward) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lukis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'self_attention_feed_forward_layer_33' (of type SelfAttentionFeedForwardLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lukis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'causal_self_attention_34' (of type CausalSelfAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lukis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'sequential_34' (of type Sequential) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lukis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'feed_forward_34' (of type FeedForward) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lukis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'self_attention_feed_forward_layer_34' (of type SelfAttentionFeedForwardLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lukis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'causal_self_attention_35' (of type CausalSelfAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lukis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'sequential_35' (of type Sequential) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lukis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'feed_forward_35' (of type FeedForward) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lukis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'self_attention_feed_forward_layer_35' (of type SelfAttentionFeedForwardLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50 - Total Loss: 2.5744 - Proportion Loss: 2.5744\n",
      "Epoch 20/50 - Total Loss: 2.2972 - Proportion Loss: 2.2972\n",
      "Epoch 30/50 - Total Loss: 2.0941 - Proportion Loss: 2.0941\n",
      "Epoch 40/50 - Total Loss: 1.9201 - Proportion Loss: 1.9201\n",
      "Epoch 50/50 - Total Loss: 1.6901 - Proportion Loss: 1.6901\n",
      "Training finished.\n",
      "Generating predictions...\n",
      "Predictions saved successfully to predictions_transformer_175651_with_details.csv\n",
      "\n",
      "Sample Predictions:\n",
      "   Sequence  Step      SourceID  Predicted_Cumulative  GroundTruth_Cumulative  \\\n",
      "0         0     1   MRI_MSR_104              5.682243                    14.0   \n",
      "1         0     2   MRI_FRR_257             19.887852                    24.0   \n",
      "2         0     3   MRI_FRR_264             28.411217                    33.0   \n",
      "3         0     4  MRI_MPT_1005             42.616825                    57.0   \n",
      "4         0     5    MRI_CCS_11             45.457947                    63.0   \n",
      "5         0     6   MRI_FRR_264             71.028046                   179.0   \n",
      "6         0     7   MRI_FRR_257            136.373840                   181.0   \n",
      "7         0     8   MRI_FRR_264            139.214966                   194.0   \n",
      "8         0     9   MRI_FRR_264            142.056091                   210.0   \n",
      "9         0    10    MRI_CCS_11            144.897217                   251.0   \n",
      "\n",
      "   timediff     PTAB BodyGroup_from BodyGroup_to  \\\n",
      "0       0.0  -708250           KNEE     SHOULDER   \n",
      "1      14.0 -1608950           KNEE     SHOULDER   \n",
      "2      24.0 -1608950           KNEE     SHOULDER   \n",
      "3      33.0 -1608950           KNEE     SHOULDER   \n",
      "4      57.0 -1608950           KNEE     SHOULDER   \n",
      "5      63.0 -1608950           KNEE     SHOULDER   \n",
      "6     179.0      550           KNEE     SHOULDER   \n",
      "7     181.0      550           KNEE     SHOULDER   \n",
      "8     194.0      550           KNEE     SHOULDER   \n",
      "9     210.0      550           KNEE     SHOULDER   \n",
      "\n",
      "                             PatientID_from  \\\n",
      "0  8a29d06a4cc1203e141061958fac39a8ad96b36c   \n",
      "1  8a29d06a4cc1203e141061958fac39a8ad96b36c   \n",
      "2  8a29d06a4cc1203e141061958fac39a8ad96b36c   \n",
      "3  8a29d06a4cc1203e141061958fac39a8ad96b36c   \n",
      "4  8a29d06a4cc1203e141061958fac39a8ad96b36c   \n",
      "5  8a29d06a4cc1203e141061958fac39a8ad96b36c   \n",
      "6  8a29d06a4cc1203e141061958fac39a8ad96b36c   \n",
      "7  8a29d06a4cc1203e141061958fac39a8ad96b36c   \n",
      "8  8a29d06a4cc1203e141061958fac39a8ad96b36c   \n",
      "9  8a29d06a4cc1203e141061958fac39a8ad96b36c   \n",
      "\n",
      "                               PatientID_to  patient_height  patient_weight  \\\n",
      "0  38f7f4c6c4a1a5b45dad45032a80d9abe98b187e             158              76   \n",
      "1  38f7f4c6c4a1a5b45dad45032a80d9abe98b187e             184              68   \n",
      "2  38f7f4c6c4a1a5b45dad45032a80d9abe98b187e             160              77   \n",
      "3  38f7f4c6c4a1a5b45dad45032a80d9abe98b187e             173              63   \n",
      "4  38f7f4c6c4a1a5b45dad45032a80d9abe98b187e             177              65   \n",
      "5  38f7f4c6c4a1a5b45dad45032a80d9abe98b187e             158              72   \n",
      "6  38f7f4c6c4a1a5b45dad45032a80d9abe98b187e             157              58   \n",
      "7  38f7f4c6c4a1a5b45dad45032a80d9abe98b187e             160              96   \n",
      "8  38f7f4c6c4a1a5b45dad45032a80d9abe98b187e             165              83   \n",
      "9  38f7f4c6c4a1a5b45dad45032a80d9abe98b187e             185              74   \n",
      "\n",
      "   patient_age  patient_gender  \n",
      "0           48               0  \n",
      "1           79               1  \n",
      "2           44               0  \n",
      "3           85               1  \n",
      "4           82               0  \n",
      "5           30               0  \n",
      "6           32               1  \n",
      "7           56               0  \n",
      "8           21               1  \n",
      "9           87               0  \n"
     ]
    }
   ],
   "source": [
    "# Replace the main function call (cell [44]) with this one.\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to run the training and prediction process.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        data_file = \"data/175651/encoded_175651_condensed_with_dummy_data.csv\"\n",
    "        if not os.path.exists(data_file):\n",
    "            print(f\"Error: Data file not found at {data_file}\")\n",
    "            return\n",
    "\n",
    "        # New: Unpack the extra data from the training result\n",
    "        result = train_transformer(data_file, epochs=50, num_bins=NUM_BINS, bin_edges=BIN_EDGES)\n",
    "\n",
    "        if result is None or result[0] is None:\n",
    "            print(\"Model training failed or no data was available. Exiting.\")\n",
    "            return\n",
    "\n",
    "        model, X_train, Y_cum_target, mask_train, total_times, sequences_sourceids, Y_binned_target, sequences_extra_data = result\n",
    "\n",
    "        # New: Pass the extra data to the prediction function\n",
    "        predictions_df = generate_predictions_csv(\n",
    "            model, X_train, Y_cum_target, mask_train, total_times, sequences_sourceids, sequences_extra_data, BIN_EDGES\n",
    "        )\n",
    "\n",
    "        if not predictions_df.empty:\n",
    "            print(\"\\nSample Predictions:\")\n",
    "            # Display a subset of columns for readability in the console\n",
    "            display_cols = ['Sequence', 'Step', 'SourceID', 'Predicted_Cumulative', 'GroundTruth_Cumulative'] + COLUMNS_TO_KEEP\n",
    "            print(predictions_df[display_cols].head(10))\n",
    "        else:\n",
    "            print(\"\\nNo predictions were generated.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in main: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
