{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7ef0a5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1dbc4cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants and Encoding\n",
    "START_TOKEN = 13\n",
    "END_TOKEN = 14\n",
    "# Add a PAD token if not using mask_zero, but we are using mask_zero=END_TOKEN\n",
    "# So tokens 0-12 are source IDs, 13 is START, 14 is END (and PAD)\n",
    "ENCODING_LEGEND = {\n",
    "    'MRI_CCS_11': 1, 'MRI_EXU_95': 2, 'MRI_FRR_18': 3, 'MRI_FRR_257': 4,\n",
    "    'MRI_FRR_264': 5, 'MRI_FRR_2': 6, 'MRI_FRR_3': 7, 'MRI_FRR_34': 8, 'MRI_MPT_1005': 9,\n",
    "    'MRI_MSR_100': 10, 'MRI_MSR_104': 11, 'MRI_MSR_21': 12, 'MRI_MSR_24': 99,\n",
    "    'START': START_TOKEN, 'END': END_TOKEN\n",
    "}\n",
    "reverse_encoding = {v: k for k, v in ENCODING_LEGEND.items()}\n",
    "\n",
    "# Define valid source IDs for filtering (excluding START and END tokens)\n",
    "VALID_SOURCE_IDS = set([k for k in ENCODING_LEGEND.keys() if k not in ['START', 'END']])\n",
    "\n",
    "# Binning parameters\n",
    "NUM_BINS = 250\n",
    "# Define bin edges from 0 to 1 (inclusive of 0, exclusive of 1 for all but the last bin)\n",
    "# The last bin will include 1.0\n",
    "BIN_EDGES = np.linspace(0.0, 1.0, NUM_BINS + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c212b712",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data(data_file):\n",
    "    \"\"\"\n",
    "    Loads and preprocesses data from a CSV file, filtering out invalid sourceIDs.\n",
    "    Splits data into sequences based on 'MRI_MSR_104' (start) and 'MRI_MSR_100' (end).\n",
    "    Assigns a sequence number during loading.\n",
    "    \"\"\"\n",
    "    print(f\"Loading data from {data_file}...\")\n",
    "    data = pd.read_csv(data_file)\n",
    "\n",
    "    all_sequences_tokens = []\n",
    "    all_sequences_times = []\n",
    "    all_sequences_sourceids = [] # Store original source IDs per sequence\n",
    "\n",
    "    current_tokens = []\n",
    "    current_times = []\n",
    "    current_sourceids = []\n",
    "\n",
    "    # Iterate through rows to build sequences\n",
    "    for idx, row in data.iterrows():\n",
    "        s_id = str(row['sourceID']) # Ensure s_id is string for lookup\n",
    "        t_diff = float(row['timediff'])\n",
    "\n",
    "        # Filter: Only process rows with valid sourceIDs\n",
    "        if s_id not in VALID_SOURCE_IDS:\n",
    "            # print(f\"Skipping row with invalid sourceID: {s_id}\") # Optional: uncomment for debugging\n",
    "            continue\n",
    "\n",
    "        # Check for the start of a new sequence\n",
    "        if s_id == 'MRI_MSR_104':\n",
    "            # If we were already building a sequence, finalize it before starting a new one\n",
    "            if current_tokens:\n",
    "                # Add END token to the previous sequence\n",
    "                token_seq = [START_TOKEN] + [int(ENCODING_LEGEND[x]) for x in current_tokens] + [END_TOKEN]\n",
    "                time_seq = [0.0] + current_times # START token has 0.0 time diff\n",
    "\n",
    "                all_sequences_tokens.append(token_seq)\n",
    "                all_sequences_times.append(time_seq)\n",
    "                all_sequences_sourceids.append(current_sourceids)\n",
    "\n",
    "            # Start a new sequence with the current 'MRI_MSR_104' row's data\n",
    "            current_tokens = [s_id]\n",
    "            current_times = [t_diff]\n",
    "            current_sourceids = [s_id]\n",
    "\n",
    "        # Check for the end of a sequence\n",
    "        elif s_id == 'MRI_MSR_100':\n",
    "             # If we are currently building a sequence, append the end token and finalize\n",
    "             if current_tokens:\n",
    "                current_tokens.append(s_id)\n",
    "                current_times.append(t_diff)\n",
    "                current_sourceids.append(s_id)\n",
    "\n",
    "                # Add END token to the current sequence\n",
    "                token_seq = [START_TOKEN] + [int(ENCODING_LEGEND[x]) for x in current_tokens] + [END_TOKEN]\n",
    "                time_seq = [0.0] + current_times # START token has 0.0 time diff\n",
    "\n",
    "                all_sequences_tokens.append(token_seq)\n",
    "                all_sequences_times.append(time_seq)\n",
    "                all_sequences_sourceids.append(current_sourceids)\n",
    "\n",
    "                # Reset for the next potential sequence\n",
    "                current_tokens = []\n",
    "                current_times = []\n",
    "                current_sourceids = []\n",
    "             # If current_tokens is empty and we see MRI_MSR_100, it's an anomaly or data issue\n",
    "             # We'll just skip it in this case.\n",
    "\n",
    "        # For any other valid source ID, append to the current sequence if one is being built\n",
    "        elif current_tokens:\n",
    "            current_tokens.append(s_id)\n",
    "            current_times.append(t_diff)\n",
    "            current_sourceids.append(s_id)\n",
    "\n",
    "        # If current_tokens is empty and s_id is not MRI_MSR_104,\n",
    "        # it means we are seeing data before the first sequence starts or between sequences.\n",
    "        # These rows are effectively ignored until MRI_MSR_104 is found.\n",
    "\n",
    "\n",
    "    # Add the very last sequence after the loop finishes, if one was being built\n",
    "    # This handles cases where the file ends without an explicit MRI_MSR_100\n",
    "    # but the last sequence was started with MRI_MSR_104.\n",
    "    if current_tokens:\n",
    "         # Add END token to the final sequence\n",
    "         token_seq = [START_TOKEN] + [int(ENCODING_LEGEND[x]) for x in current_tokens] + [END_TOKEN]\n",
    "         time_seq = [0.0] + current_times # START token has 0.0 time diff\n",
    "\n",
    "         all_sequences_tokens.append(token_seq)\n",
    "         all_sequences_times.append(time_seq)\n",
    "         all_sequences_sourceids.append(current_sourceids)\n",
    "\n",
    "\n",
    "    print(f\"Loaded {len(all_sequences_tokens)} sequences.\")\n",
    "    return all_sequences_tokens, all_sequences_times, all_sequences_sourceids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "08ed1488",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bin_indices(proportions, bin_edges):\n",
    "    \"\"\"\n",
    "    Maps continuous proportions to discrete bin indices.\n",
    "    Handles the edge case for the maximum value (1.0).\n",
    "    \"\"\"\n",
    "    # Use np.digitize to find the bin index for each proportion\n",
    "    # digitize returns index i if bin_edges[i-1] <= x < bin_edges[i]\n",
    "    # For the last bin, we want to include the upper edge (1.0)\n",
    "    # np.digitize with right=False is default: bins[i-1] <= x < bins[i]\n",
    "    # To include the rightmost edge in the last bin, we can adjust values >= 1.0\n",
    "    proportions = np.clip(proportions, bin_edges[0], bin_edges[-1]) # Clip to [0, 1] range\n",
    "\n",
    "    # Use right=True to include the rightmost edge in the last bin\n",
    "    # bins[i-1] < x <= bins[i]\n",
    "    bin_indices = np.digitize(proportions, bin_edges, right=True) - 1 # -1 because bin_edges has N+1 edges for N bins\n",
    "\n",
    "    # Handle values exactly equal to the last edge (1.0) - np.digitize with right=True puts them in N+1 bin\n",
    "    # We want them in bin N-1 (0-indexed)\n",
    "    bin_indices[proportions == bin_edges[-1]] = len(bin_edges) - 2 # Index of the last bin (0-indexed)\n",
    "\n",
    "    # Ensure indices are within valid range [0, NUM_BINS - 1]\n",
    "    bin_indices = np.clip(bin_indices, 0, len(bin_edges) - 2)\n",
    "\n",
    "    return bin_indices\n",
    "\n",
    "def get_bin_centers(bin_indices, bin_edges):\n",
    "    \"\"\"\n",
    "    Returns the center value for a given array of bin indices.\n",
    "    \"\"\"\n",
    "    # Calculate bin centers as the midpoint of each bin\n",
    "    bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "    return bin_centers[bin_indices]\n",
    "\n",
    "\n",
    "def prepare_training_data(sequences_tokens, sequences_times, bin_edges):\n",
    "    \"\"\"\n",
    "    Prepares sequences for transformer training, including padding and masks.\n",
    "    Calculates target cumulative times, total times, and binned proportion targets.\n",
    "    \"\"\"\n",
    "    X_list, Y_list, masks_list, total_times_list, Y_binned_list = [], [], [], [], []\n",
    "\n",
    "    for tokens, times in zip(sequences_tokens, sequences_times):\n",
    "        # Ensure sequence has at least START and END tokens plus one event\n",
    "        if len(tokens) < 3:\n",
    "            # print(f\"Skipping short sequence with {len(tokens)} tokens.\") # Optional: uncomment for debugging\n",
    "            continue\n",
    "\n",
    "        # The last element in times should be the cumulative time of the last event\n",
    "        # which corresponds to the total time of the sequence.\n",
    "        total_time = times[-1]\n",
    "\n",
    "        # Input sequence X: START, Event1, Event2, ... EventN\n",
    "        # We predict the time *until* the event represented by the input token.\n",
    "        # So, the input sequence should be tokens[:-1] (START, Event1, ..., EventN-1)\n",
    "        x_seq = tokens[:-1]\n",
    "\n",
    "        # Target cumulative times Y: Time1, Time2, ... TimeN\n",
    "        # These are the cumulative times *at the end* of each step.\n",
    "        # These correspond to the time *at* the event represented by the token at the corresponding index in the input sequence.\n",
    "        # The first target time (times[1]) corresponds to the time of the first event (input token at index 1).\n",
    "        y_seq = times[1:]\n",
    "\n",
    "        # Calculate true time differences for proportion calculation\n",
    "        # time_diffs shape: (seq_len - 1) - corresponds to steps 1 to N\n",
    "        # These are the durations between events: duration[i] = time[i+1] - time[i]\n",
    "        time_diffs_unpadded = np.diff(times) # time_diffs[i] = times[i+1] - times[i]\n",
    "\n",
    "        # Calculate true proportions for the steps *after* the START token\n",
    "        # true_total is the last cumulative time\n",
    "        true_total = times[-1]\n",
    "        # Avoid division by zero\n",
    "        true_total_safe = true_total if true_total > 0 else 1.0\n",
    "        # true_props_unpadded shape: (seq_len - 1) - corresponds to steps 1 to N\n",
    "        # These are the proportions of the total time for each time difference.\n",
    "        true_props_unpadded = time_diffs_unpadded / true_total_safe\n",
    "\n",
    "        # Pad true_props to match input sequence length (X_list)\n",
    "        # The first position (corresponding to START token input at index 0) should have 0 proportion.\n",
    "        # The proportions for events 1 to N (indices 1 to N in input) are in true_props_unpadded.\n",
    "        true_props_padded = np.pad(true_props_unpadded, (1, 0), constant_values=0.0)\n",
    "\n",
    "        # Bin the true proportions\n",
    "        # Y_binned_seq shape: (seq_len) - corresponds to the input sequence length\n",
    "        y_binned_seq = get_bin_indices(true_props_padded, bin_edges)\n",
    "\n",
    "\n",
    "        # Mask: 1 for valid input tokens (not END_TOKEN), 0 otherwise\n",
    "        # The mask applies to the *input* sequence (X_list).\n",
    "        mask_seq = [1 if t != END_TOKEN else 0 for t in x_seq]\n",
    "\n",
    "        X_list.append(x_seq)\n",
    "        Y_list.append(y_seq) # Keep cumulative targets for CSV generation\n",
    "        masks_list.append(mask_seq)\n",
    "        total_times_list.append(total_time) # Keep total times for CSV generation\n",
    "        Y_binned_list.append(y_binned_seq) # Add binned targets\n",
    "\n",
    "\n",
    "    if not X_list:\n",
    "        print(\"No valid sequences found after preprocessing.\")\n",
    "        return np.array([]), np.array([]), np.array([]), np.array([]), np.array([])\n",
    "\n",
    "\n",
    "    # Determine max length based on the processed sequences\n",
    "    max_len = max(len(x) for x in X_list)\n",
    "    print(f\"Padding sequences to max length: {max_len}\")\n",
    "\n",
    "    # Pad sequences\n",
    "    # X_train: pad with END_TOKEN (mask_zero=True in embedding will ignore this)\n",
    "    X_train = pad_sequences(X_list, maxlen=max_len, padding='post', value=END_TOKEN)\n",
    "    # Y_cum_target: pad with 0.0\n",
    "    Y_cum_target = pad_sequences(Y_list, maxlen=max_len, padding='post', value=0.0)\n",
    "    # mask_train: pad with 0\n",
    "    mask_train = pad_sequences(masks_list, maxlen=max_len, padding='post', value=0)\n",
    "    # Y_binned_target: pad with a value that is within the valid bin range (e.g., 0)\n",
    "    # We will use the mask to ignore padded positions in the loss calculation\n",
    "    Y_binned_target = pad_sequences(Y_binned_list, maxlen=max_len, padding='post', value=0) # Changed padding value to 0\n",
    "\n",
    "    X_train = np.array(X_train, dtype=np.int32)\n",
    "    Y_cum_target = np.array(Y_cum_target, dtype=np.float32)\n",
    "    mask_train = np.array(mask_train, dtype=np.float32)\n",
    "    total_times = np.array(total_times_list, dtype=np.float32)\n",
    "    Y_binned_target = np.array(Y_binned_target, dtype=np.int32) # Binned targets are integers\n",
    "\n",
    "    print(f\"Prepared {X_train.shape[0]} sequences for training.\")\n",
    "    return X_train, Y_cum_target, mask_train, total_times, Y_binned_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a0d10f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Transformer Components (unchanged)\n",
    "# ----------------------------\n",
    "def positional_encoding(length, depth):\n",
    "    depth = depth / 2\n",
    "    positions = np.arange(length)[:, np.newaxis]\n",
    "    depths = np.arange(depth)[np.newaxis, :] / depth\n",
    "    angle_rates = 1 / (10000 ** depths)\n",
    "    angle_rads = positions * angle_rates\n",
    "    pos_encoding = np.concatenate([np.sin(angle_rads), np.cos(angle_rads)], axis=-1)\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)\n",
    "\n",
    "class PositionalEmbedding(layers.Layer):\n",
    "    def __init__(self, vocab_size, d_model, max_len=16384, use_embedding=True):\n",
    "        super(PositionalEmbedding, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.use_embedding = use_embedding\n",
    "        if self.use_embedding:\n",
    "            # Set mask_zero to the actual padding value (END_TOKEN)\n",
    "            self.embedding = layers.Embedding(vocab_size, d_model, mask_zero=END_TOKEN)\n",
    "        else:\n",
    "            # If not using embedding, assume input is already dense (e.g., time features)\n",
    "            self.embedding = layers.Dense(d_model, activation=\"relu\")\n",
    "        self.max_len = max_len\n",
    "        # Ensure pos_encoding is created once and is large enough\n",
    "        self.pos_encoding = positional_encoding(self.max_len, d_model)\n",
    "\n",
    "    # Correct compute_mask signature to accept optional mask argument\n",
    "    def compute_mask(self, x, mask=None):\n",
    "         # If using embedding with mask_zero, the mask is computed based on mask_zero value\n",
    "         if self.use_embedding:\n",
    "              # Return a boolean mask indicating which elements are NOT the mask_zero value\n",
    "              return tf.math.not_equal(x, self.embedding.mask_zero)\n",
    "         # Otherwise, assume all steps are valid unless explicitly masked later\n",
    "         return None\n",
    "\n",
    "    def call(self, x):\n",
    "        # x is assumed to be token IDs if use_embedding is True, otherwise dense features\n",
    "        if self.use_embedding:\n",
    "            # The embedding layer itself computes and propagates the mask because mask_zero is set\n",
    "            x = self.embedding(x)\n",
    "        else:\n",
    "             # Apply dense layer if input is not token IDs\n",
    "             x = self.embedding(x)\n",
    "\n",
    "        # Scale the embedding output\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "\n",
    "        # Add positional encoding\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        # Ensure positional encoding slice matches sequence length\n",
    "        x += self.pos_encoding[tf.newaxis, :seq_len, :]\n",
    "        return x\n",
    "\n",
    "class FeedForward(layers.Layer):\n",
    "    def __init__(self, d_model, dff, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.seq = tf.keras.Sequential([\n",
    "            layers.Dense(dff, activation='relu'),\n",
    "            layers.Dense(d_model),\n",
    "            layers.Dropout(dropout_rate)\n",
    "        ])\n",
    "        self.add = layers.Add()\n",
    "        self.layer_norm = layers.LayerNormalization()\n",
    "\n",
    "    def call(self, x):\n",
    "        # Apply feed forward network with residual connection and layer normalization\n",
    "        x = self.add([x, self.seq(x)])\n",
    "        x = self.layer_norm(x)\n",
    "        return x\n",
    "\n",
    "class CausalSelfAttention(layers.Layer):\n",
    "    def __init__(self, num_heads, d_model, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        # MultiHeadAttention layer with causal mask\n",
    "        self.mha = layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model, dropout=dropout_rate)\n",
    "        self.add = layers.Add()\n",
    "        self.layer_norm = layers.LayerNormalization()\n",
    "\n",
    "    def call(self, x):\n",
    "        # Apply multi-head self-attention\n",
    "        # Keras automatically uses the mask attached to the input 'x'\n",
    "        attn_output = self.mha(query=x, key=x, value=x, use_causal_mask=True)\n",
    "        # Add residual connection and layer normalization\n",
    "        x = self.add([x, attn_output])\n",
    "        x = self.layer_norm(x)\n",
    "        return x\n",
    "\n",
    "class SelfAttentionFeedForwardLayer(layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        # Composes CausalSelfAttention and FeedForward layers\n",
    "        self.self_attention = CausalSelfAttention(num_heads=num_heads, d_model=d_model, dropout_rate=dropout_rate)\n",
    "        self.ffn = FeedForward(d_model, dff, dropout_rate)\n",
    "\n",
    "    def call(self, x):\n",
    "        # Pass input through self-attention and then feed-forward network\n",
    "        # Mask from 'x' is propagated through these layers\n",
    "        x = self.self_attention(x)\n",
    "        x = self.ffn(x)\n",
    "        return x\n",
    "\n",
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, vocab_size, dropout_rate=0.1, max_len=16384):\n",
    "        super().__init__()\n",
    "        # Positional embedding for the input tokens\n",
    "        self.pos_embedding = PositionalEmbedding(vocab_size, d_model, max_len=max_len)\n",
    "        # Stack of encoder layers\n",
    "        self.enc_layers = [SelfAttentionFeedForwardLayer(d_model, num_heads, dff, dropout_rate)\n",
    "                           for _ in range(num_layers)]\n",
    "        self.dropout = layers.Dropout(dropout_rate)\n",
    "\n",
    "    def call(self, x):\n",
    "        # Apply positional embedding and dropout.\n",
    "        # The output 'x' from pos_embedding will carry the mask computed by PositionalEmbedding.compute_mask.\n",
    "        x = self.pos_embedding(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # Pass through encoder layers. Keras will automatically propagate the mask\n",
    "        # through the layers that support masking (like MultiHeadAttention).\n",
    "        for layer in self.enc_layers:\n",
    "            x = layer(x)\n",
    "\n",
    "        return x # The output tensor carries the mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "513c2d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeDiffTransformer(tf.keras.Model):\n",
    "    \"\"\"\n",
    "    Transformer model predicting proportions of total time for each sequence step.\n",
    "    This version predicts a probability distribution over bins for proportions.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, num_bins, dropout_rate=0.1, max_len=16384):\n",
    "        super().__init__()\n",
    "        # Encoder processes the input sequence of tokens\n",
    "        self.encoder = Encoder(num_layers, d_model, num_heads, dff, input_vocab_size, dropout_rate, max_len)\n",
    "\n",
    "        # Head to predict the probability distribution over bins for proportions\n",
    "        # Output is NUM_BINS values per sequence step with softmax activation\n",
    "        self.proportion_head = layers.Dense(num_bins, activation='softmax')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Pass input through the encoder\n",
    "        encoder_out = self.encoder(inputs) # encoder_out shape: (batch_size, seq_len, d_model)\n",
    "        # The mask from the embedding layer is propagated to encoder_out\n",
    "\n",
    "        # Predict probability distribution over bins for each step\n",
    "        # pred_bin_probs shape: (batch_size, seq_len, num_bins)\n",
    "        pred_bin_probs = self.proportion_head(encoder_out)\n",
    "\n",
    "        # Return the predicted bin probabilities\n",
    "        return pred_bin_probs # pred_bin_probs shape: (batch_size, seq_len, num_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b0b8175a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_transformer(data_file, epochs=50, batch_size=32, num_bins=NUM_BINS, bin_edges=BIN_EDGES):\n",
    "    \"\"\"\n",
    "    Trains the TimeDiffTransformer model with proportion binning.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load and preprocess data\n",
    "        sequences_tokens, sequences_times, sequences_sourceids = load_and_preprocess_data(data_file)\n",
    "\n",
    "        # Prepare data for training, including binned targets\n",
    "        X_train, Y_cum_target, mask_train, total_times, Y_binned_target = prepare_training_data(\n",
    "            sequences_tokens, sequences_times, bin_edges\n",
    "        )\n",
    "\n",
    "        if X_train.shape[0] == 0:\n",
    "            print(\"No data available for training after preprocessing.\")\n",
    "            return None, None, None, None, None, None, None\n",
    "\n",
    "        # Model parameters\n",
    "        vocab_size = max(ENCODING_LEGEND.values()) + 1\n",
    "        max_seq_len = X_train.shape[1]\n",
    "\n",
    "        # Instantiate the model (predicts probability distribution over bins)\n",
    "        model = TimeDiffTransformer(\n",
    "            num_layers=3,\n",
    "            d_model=64,\n",
    "            num_heads=8,\n",
    "            dff=128,\n",
    "            input_vocab_size=vocab_size,\n",
    "            num_bins=num_bins, # Pass number of bins\n",
    "            dropout_rate=0.1,\n",
    "            max_len=max_seq_len\n",
    "        )\n",
    "\n",
    "        # Optimizer\n",
    "        optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "        # Loss function for binned proportions (Sparse Categorical Crossentropy)\n",
    "        # Use from_logits=False because the output layer has softmax activation\n",
    "        proportion_loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "\n",
    "        @tf.function\n",
    "        def train_step(x, y_binned, mask): # Use binned targets and mask\n",
    "            with tf.GradientTape() as tape:\n",
    "                # Model predicts probability distribution over bins\n",
    "                pred_bin_probs = model(x) # pred_bin_probs shape: (batch_size, seq_len, num_bins)\n",
    "\n",
    "                # Compute masked proportion loss\n",
    "                # Only consider loss for steps where mask is 1\n",
    "                # y_binned shape: (batch_size, seq_len) - integer bin indices\n",
    "                # mask shape: (batch_size, seq_len) - float mask\n",
    "                # We need to apply the mask to both predictions and targets.\n",
    "                # For SparseCategoricalCrossentropy, we can use sample_weight.\n",
    "\n",
    "                # Ensure mask is float32\n",
    "                mask_float = tf.cast(mask, tf.float32)\n",
    "\n",
    "                # Compute loss, applying mask as sample_weight\n",
    "                # The loss function expects targets (y_binned) and predictions (pred_bin_probs)\n",
    "                masked_props_loss = proportion_loss_fn(\n",
    "                    y_binned,\n",
    "                    pred_bin_probs,\n",
    "                    sample_weight=mask_float # Apply mask as sample weight\n",
    "                )\n",
    "\n",
    "                total_loss = masked_props_loss # Total loss is just the proportion loss\n",
    "\n",
    "            # Compute gradients and apply optimizer\n",
    "            grads = tape.gradient(total_loss, model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "            return total_loss, masked_props_loss\n",
    "\n",
    "        # Training loop\n",
    "        print(\"Starting training...\")\n",
    "        # Pass binned targets and mask to train_step\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices((X_train, Y_binned_target, mask_train)).batch(batch_size)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            total_epoch_loss = 0\n",
    "            total_proportion_loss = 0\n",
    "            num_batches = 0\n",
    "            for step, (batch_x, batch_y_binned, batch_mask) in enumerate(train_dataset):\n",
    "                loss, props_loss = train_step(batch_x, batch_y_binned, batch_mask)\n",
    "                total_epoch_loss += loss\n",
    "                total_proportion_loss += props_loss\n",
    "                num_batches += 1\n",
    "\n",
    "            avg_epoch_loss = total_epoch_loss / num_batches if num_batches > 0 else 0\n",
    "            avg_proportion_loss = total_proportion_loss / num_batches if num_batches > 0 else 0\n",
    "\n",
    "            print(f\"Epoch {epoch+1}/{epochs} - Total Loss: {avg_epoch_loss.numpy():.4f} - Proportion Loss: {avg_proportion_loss.numpy():.4f}\")\n",
    "\n",
    "\n",
    "        print(\"Training finished.\")\n",
    "        # Return binned targets as well for potential analysis\n",
    "        return model, X_train, Y_cum_target, mask_train, total_times, sequences_sourceids, Y_binned_target\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in train_transformer: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None, None, None, None, None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fa84d146",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_time_differences(proportions, total_time, mask):\n",
    "    \"\"\"\n",
    "    Computes predicted increments and cumulative times from proportions and total time.\n",
    "    Applies masking to ignore padded steps.\n",
    "\n",
    "    Args:\n",
    "        proportions: Predicted proportions for each step (batch_size, seq_len).\n",
    "        total_time: The total time for each sequence (batch_size, 1).\n",
    "        mask: Mask indicating valid steps (batch_size, seq_len).\n",
    "\n",
    "    Returns:\n",
    "        proportions: Normalized proportions (batch_size, seq_len).\n",
    "        increments: Predicted time increments (batch_size, seq_len).\n",
    "        cumulative_times: Predicted cumulative times (batch_size, seq_len).\n",
    "    \"\"\"\n",
    "    # Apply mask to ensure only valid tokens contribute to calculations\n",
    "    proportions *= tf.cast(mask, tf.float32)\n",
    "\n",
    "    # Compute row-wise sum for normalization to handle variable-length sequences\n",
    "    # Sum across the sequence length dimension (axis=1)\n",
    "    row_sums = tf.reduce_sum(proportions, axis=1, keepdims=True)\n",
    "    # Prevent division by zero if a sequence is entirely masked (shouldn't happen with START token)\n",
    "    row_sums = tf.where(tf.equal(row_sums, 0), tf.ones_like(row_sums), row_sums)\n",
    "\n",
    "    # Normalize proportions so they sum to 1 over the valid (unmasked) steps\n",
    "    proportions /= row_sums\n",
    "\n",
    "    # Compute increments by multiplying normalized proportions by the total time\n",
    "    # total_time should have shape (batch_size, 1) for correct broadcasting\n",
    "    increments = proportions * total_time # Broadcasting total_time\n",
    "\n",
    "    # Compute cumulative times by summing increments along the sequence dimension\n",
    "    cumulative_times = tf.math.cumsum(increments, axis=1)\n",
    "\n",
    "    return proportions, increments, cumulative_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "49353d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_transformer(data_file, epochs=50, batch_size=32, num_bins=NUM_BINS, bin_edges=BIN_EDGES):\n",
    "    \"\"\"\n",
    "    Trains the TimeDiffTransformer model with proportion binning.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load and preprocess data\n",
    "        sequences_tokens, sequences_times, sequences_sourceids = load_and_preprocess_data(data_file)\n",
    "\n",
    "        # Prepare data for training, including binned targets\n",
    "        X_train, Y_cum_target, mask_train, total_times, Y_binned_target = prepare_training_data(\n",
    "            sequences_tokens, sequences_times, bin_edges\n",
    "        )\n",
    "\n",
    "        if X_train.shape[0] == 0:\n",
    "            print(\"No data available for training after preprocessing.\")\n",
    "            return None, None, None, None, None, None, None\n",
    "\n",
    "        # Model parameters\n",
    "        vocab_size = max(ENCODING_LEGEND.values()) + 1\n",
    "        max_seq_len = X_train.shape[1]\n",
    "\n",
    "        # Instantiate the model (predicts probability distribution over bins)\n",
    "        model = TimeDiffTransformer(\n",
    "            num_layers=3,\n",
    "            d_model=64,\n",
    "            num_heads=8,\n",
    "            dff=128,\n",
    "            input_vocab_size=vocab_size,\n",
    "            num_bins=num_bins, # Pass number of bins\n",
    "            dropout_rate=0.1,\n",
    "            max_len=max_seq_len\n",
    "        )\n",
    "\n",
    "        # Optimizer\n",
    "        optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "        # Loss function for binned proportions (Sparse Categorical Crossentropy)\n",
    "        # Use from_logits=False because the output layer has softmax activation\n",
    "        proportion_loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "\n",
    "        @tf.function\n",
    "        def train_step(x, y_binned, mask): # Use binned targets and mask\n",
    "            with tf.GradientTape() as tape:\n",
    "                # Model predicts probability distribution over bins\n",
    "                pred_bin_probs = model(x) # pred_bin_probs shape: (batch_size, seq_len, num_bins)\n",
    "\n",
    "                # Compute masked proportion loss\n",
    "                # Only consider loss for steps where mask is 1\n",
    "                # y_binned shape: (batch_size, seq_len) - integer bin indices\n",
    "                # mask shape: (batch_size, seq_len) - float mask\n",
    "                # We need to apply the mask to both predictions and targets.\n",
    "                # For SparseCategoricalCrossentropy, we can use sample_weight.\n",
    "\n",
    "                # Ensure mask is float32\n",
    "                mask_float = tf.cast(mask, tf.float32)\n",
    "\n",
    "                # Compute loss, applying mask as sample_weight\n",
    "                # The loss function expects targets (y_binned) and predictions (pred_bin_probs)\n",
    "                masked_props_loss = proportion_loss_fn(\n",
    "                    y_binned,\n",
    "                    pred_bin_probs,\n",
    "                    sample_weight=mask_float # Apply mask as sample weight\n",
    "                )\n",
    "\n",
    "                total_loss = masked_props_loss # Total loss is just the proportion loss\n",
    "\n",
    "            # Compute gradients and apply optimizer\n",
    "            grads = tape.gradient(total_loss, model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "            return total_loss, masked_props_loss\n",
    "\n",
    "        # Training loop\n",
    "        print(\"Starting training...\")\n",
    "        # Pass binned targets and mask to train_step\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices((X_train, Y_binned_target, mask_train)).batch(batch_size)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            total_epoch_loss = 0\n",
    "            total_proportion_loss = 0\n",
    "            num_batches = 0\n",
    "            for step, (batch_x, batch_y_binned, batch_mask) in enumerate(train_dataset):\n",
    "                loss, props_loss = train_step(batch_x, batch_y_binned, batch_mask)\n",
    "                total_epoch_loss += loss\n",
    "                total_proportion_loss += props_loss\n",
    "                num_batches += 1\n",
    "\n",
    "            avg_epoch_loss = total_epoch_loss / num_batches if num_batches > 0 else 0\n",
    "            avg_proportion_loss = total_proportion_loss / num_batches if num_batches > 0 else 0\n",
    "\n",
    "            print(f\"Epoch {epoch+1}/{epochs} - Total Loss: {avg_epoch_loss.numpy():.4f} - Proportion Loss: {avg_proportion_loss.numpy():.4f}\")\n",
    "\n",
    "\n",
    "        print(\"Training finished.\")\n",
    "        # Return binned targets as well for potential analysis\n",
    "        return model, X_train, Y_cum_target, mask_train, total_times, sequences_sourceids, Y_binned_target\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in train_transformer: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None, None, None, None, None, None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "87e14b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_predictions_csv(model, X_train, Y_cum_target, mask_train, total_times, sequences_sourceids, bin_edges):\n",
    "    \"\"\"\n",
    "    Generates predictions using the trained model and saves them to a CSV file,\n",
    "    correctly aligning SourceIDs with sequence steps.\n",
    "    Uses the *true* total_times to compute predicted increments/cumulative times\n",
    "    for comparison purposes, as the model no longer predicts total time.\n",
    "    Interprets binned proportion predictions.\n",
    "\n",
    "    Args:\n",
    "        model: The trained TimeDiffTransformer model (predicts bin probabilities).\n",
    "        X_train: The input sequences (padded).\n",
    "        Y_cum_target: The target cumulative times (padded).\n",
    "        mask_train: The mask indicating valid sequence positions.\n",
    "        total_times: The true total time for each sequence (NumPy array).\n",
    "        sequences_sourceids: A list of lists, where each inner list contains\n",
    "                             the original source IDs for a sequence.\n",
    "        bin_edges: The edges used for binning proportions.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: The DataFrame containing predictions and ground truth.\n",
    "    \"\"\"\n",
    "    if model is None:\n",
    "        print(\"Model is None, cannot generate predictions.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    print(\"Generating predictions...\")\n",
    "\n",
    "    # Predict probability distribution over bins using the model\n",
    "    # model(X_train) returns pred_bin_probs with shape (batch_size, seq_len, num_bins)\n",
    "    pred_bin_probs = model(X_train)\n",
    "\n",
    "    # Get the predicted bin index for each step by taking the argmax over the bin dimension\n",
    "    # predicted_bin_indices shape: (batch_size, seq_len)\n",
    "    predicted_bin_indices = tf.argmax(pred_bin_probs, axis=-1, output_type=tf.int32)\n",
    "\n",
    "    # Convert predicted bin indices back to continuous proportion values (e.g., using bin centers)\n",
    "    # predicted_proportions_continuous shape: (batch_size, seq_len)\n",
    "    predicted_proportions_continuous = get_bin_centers(predicted_bin_indices.numpy(), bin_edges)\n",
    "\n",
    "\n",
    "    # Compute predicted increments and cumulative times using the *true* total_times\n",
    "    # Ensure total_times is a TensorFlow tensor with a batch dimension\n",
    "    total_times_tf = tf.constant(total_times, dtype=tf.float32)\n",
    "    # Expand total_times to shape (batch_size, 1) for correct broadcasting\n",
    "    total_times_expanded = tf.expand_dims(total_times_tf, axis=1)\n",
    "\n",
    "    # Use compute_time_differences with predicted continuous proportions and true total time\n",
    "    # compute_time_differences expects proportions with shape (batch_size, seq_len)\n",
    "    proportions_pred_norm, increments_pred, cumulative_pred = compute_time_differences(\n",
    "        tf.constant(predicted_proportions_continuous, dtype=tf.float32), # Use predicted continuous proportions\n",
    "        total_times_expanded,\n",
    "        mask_train\n",
    "    )\n",
    "\n",
    "    # Convert TensorFlow tensors to NumPy arrays for easier handling\n",
    "    proportions_pred_np = proportions_pred_norm.numpy()\n",
    "    increments_pred_np = increments_pred.numpy()\n",
    "    cumulative_pred_np = cumulative_pred.numpy()\n",
    "    X_train_np = X_train # Already numpy\n",
    "    Y_cum_target_np = Y_cum_target # Already numpy\n",
    "    mask_train_np = mask_train # Already numpy\n",
    "\n",
    "    # Compute ground truth increments for comparison\n",
    "    # Handle the first element carefully (it's the time of the first event relative to start)\n",
    "    gt_increments = np.zeros_like(Y_cum_target_np)\n",
    "    # The first increment is the first cumulative time\n",
    "    gt_increments[:, 0] = Y_cum_target_np[:, 0]\n",
    "    # Subsequent increments are the differences between consecutive cumulative times\n",
    "    gt_increments[:, 1:] = Y_cum_target_np[:, 1:] - Y_cum_target_np[:, :-1]\n",
    "    # Apply mask to ground truth increments as well\n",
    "    gt_increments *= mask_train_np\n",
    "\n",
    "\n",
    "    # Collect predictions in a list of dictionaries for easy DataFrame creation\n",
    "    output_records = []\n",
    "\n",
    "    # Iterate through each sequence in the batch\n",
    "    for seq_idx in range(X_train_np.shape[0]):\n",
    "        # Find indices that are not padding (mask is 1)\n",
    "        valid_mask = mask_train_np[seq_idx] == 1\n",
    "        valid_indices = np.where(valid_mask)[0]\n",
    "\n",
    "        # Get the original source IDs for this sequence\n",
    "        # sequences_sourceids contains source IDs for steps *after* START token\n",
    "        safe_sourceids = sequences_sourceids[seq_idx] if seq_idx < len(sequences_sourceids) else []\n",
    "\n",
    "        step_counter = 1 # Initialize step counter for this sequence (starts from 1 for the first event)\n",
    "\n",
    "        # Iterate through the valid indices within this sequence\n",
    "        # valid_indices corresponds to positions in the padded sequence where mask is 1\n",
    "        # valid_idx = 0 corresponds to the START token input\n",
    "        # valid_idx = 1 corresponds to the first event input, etc.\n",
    "        for i in range(len(valid_indices)):\n",
    "            valid_idx = valid_indices[i] # The actual index in the padded sequence\n",
    "\n",
    "            # We want to output predictions for each *event* step, not the START token step.\n",
    "            # The predictions (proportions, increments, cumulative) at valid_idx\n",
    "            # correspond to the time *until* the event at that position (relative to the previous event for increments,\n",
    "            # or relative to the start for cumulative).\n",
    "            # The SourceID at step 'k' (1-indexed) corresponds to the input token at index 'k' in the original sequence,\n",
    "            # which is index 'k' in the padded input X_train, and index 'k-1' in the original sourceids list.\n",
    "            # The predictions at index `valid_idx` relate to the event *after* the token at `valid_idx`.\n",
    "            # So, prediction at `valid_idx` corresponds to the event with SourceID `safe_sourceids[valid_idx]`.\n",
    "\n",
    "            # Check if this index corresponds to an actual event (not the START token)\n",
    "            # The START token is at index 0 in the padded input.\n",
    "            # The first event's input is at index 1, second at index 2, etc.\n",
    "            # The predictions at index `j` correspond to the time *until* the event represented by the input token at index `j`.\n",
    "            # So, pred at index `j` corresponds to SourceID at `safe_sourceids[j-1]`.\n",
    "            # The valid_idx here is the index in the padded sequence.\n",
    "\n",
    "            # Let's align predictions with the event they predict the time *until*.\n",
    "            # Prediction at index `i` in padded sequence (where input is token `i`)\n",
    "            # predicts time until event `i`. Event `i` has SourceID `safe_sourceids[i-1]`.\n",
    "            # We should iterate through the *events*, which correspond to indices 1 onwards in the padded sequence.\n",
    "\n",
    "            # Iterate through the valid event indices (skip the START token at index 0)\n",
    "            if valid_idx > 0:\n",
    "                # The source ID for the event predicted at valid_idx is the one at index valid_idx - 1\n",
    "                source_id_index = valid_idx - 1\n",
    "\n",
    "                # Get the corresponding source ID safely\n",
    "                if source_id_index < len(safe_sourceids):\n",
    "                    source_id = safe_sourceids[source_id_index]\n",
    "                else:\n",
    "                    # This case indicates a potential mismatch or issue elsewhere\n",
    "                    source_id = f'Unknown_Mapping_Error_seq_{seq_idx}_idx_{source_id_index}'\n",
    "                    print(f\"Warning: Source ID index {source_id_index} out of bounds for sequence {seq_idx} with length {len(safe_sourceids)}\")\n",
    "\n",
    "                # Append record for this event step\n",
    "                output_records.append({\n",
    "                    'Sequence': seq_idx,\n",
    "                    'Step': step_counter, # Use the dedicated counter for event steps\n",
    "                    'SourceID': source_id,\n",
    "                    'Predicted_Proportion': proportions_pred_np[seq_idx, valid_idx],\n",
    "                    'Predicted_Increment': increments_pred_np[seq_idx, valid_idx],\n",
    "                    'Predicted_Cumulative': cumulative_pred_np[seq_idx, valid_idx],\n",
    "                    'GroundTruth_Increment': gt_increments[seq_idx, valid_idx],\n",
    "                    'GroundTruth_Cumulative': Y_cum_target_np[seq_idx, valid_idx]\n",
    "                })\n",
    "\n",
    "                step_counter += 1 # Increment step counter only for actual events added\n",
    "\n",
    "    # Create DataFrame from the collected records\n",
    "    if not output_records:\n",
    "        print(\"Warning: No valid prediction records generated.\")\n",
    "        predictions_df = pd.DataFrame(columns=[\n",
    "            'Sequence', 'Step', 'SourceID', 'Predicted_Proportion',\n",
    "            'Predicted_Increment', 'Predicted_Cumulative',\n",
    "            'GroundTruth_Increment', 'GroundTruth_Cumulative'\n",
    "        ])\n",
    "    else:\n",
    "        predictions_df = pd.DataFrame(output_records)\n",
    "\n",
    "    # Save the DataFrame to CSV\n",
    "    output_csv_path = 'predictions_transformer_182625.csv'\n",
    "    try:\n",
    "        predictions_df.to_csv(output_csv_path, index=False)\n",
    "        print(f\"Predictions saved successfully to {output_csv_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving predictions to CSV: {e}\")\n",
    "\n",
    "    return predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1ca18d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from data/182625/encoded_182625_condensed.csv...\n",
      "Loaded 186 sequences.\n",
      "Padding sequences to max length: 43\n",
      "Prepared 186 sequences for training.\n",
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lukis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'query' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lukis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'key' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lukis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'value' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lukis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'causal_self_attention_18' (of type CausalSelfAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lukis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'sequential_18' (of type Sequential) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lukis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'feed_forward_18' (of type FeedForward) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lukis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'self_attention_feed_forward_layer_18' (of type SelfAttentionFeedForwardLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lukis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'causal_self_attention_19' (of type CausalSelfAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lukis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'sequential_19' (of type Sequential) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lukis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'feed_forward_19' (of type FeedForward) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lukis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'self_attention_feed_forward_layer_19' (of type SelfAttentionFeedForwardLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lukis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'causal_self_attention_20' (of type CausalSelfAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lukis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'sequential_20' (of type Sequential) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lukis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'feed_forward_20' (of type FeedForward) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lukis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'self_attention_feed_forward_layer_20' (of type SelfAttentionFeedForwardLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 - Total Loss: 4.4964 - Proportion Loss: 4.4964\n",
      "Epoch 2/50 - Total Loss: 3.8421 - Proportion Loss: 3.8421\n",
      "Epoch 3/50 - Total Loss: 3.5636 - Proportion Loss: 3.5636\n",
      "Epoch 4/50 - Total Loss: 3.3462 - Proportion Loss: 3.3462\n",
      "Epoch 5/50 - Total Loss: 3.1984 - Proportion Loss: 3.1984\n",
      "Epoch 6/50 - Total Loss: 3.1084 - Proportion Loss: 3.1084\n",
      "Epoch 7/50 - Total Loss: 3.0613 - Proportion Loss: 3.0613\n",
      "Epoch 8/50 - Total Loss: 3.0303 - Proportion Loss: 3.0303\n",
      "Epoch 9/50 - Total Loss: 3.0079 - Proportion Loss: 3.0079\n",
      "Epoch 10/50 - Total Loss: 2.9788 - Proportion Loss: 2.9788\n",
      "Epoch 11/50 - Total Loss: 2.9502 - Proportion Loss: 2.9502\n",
      "Epoch 12/50 - Total Loss: 2.9240 - Proportion Loss: 2.9240\n",
      "Epoch 13/50 - Total Loss: 2.9002 - Proportion Loss: 2.9002\n",
      "Epoch 14/50 - Total Loss: 2.8770 - Proportion Loss: 2.8770\n",
      "Epoch 15/50 - Total Loss: 2.8578 - Proportion Loss: 2.8578\n",
      "Epoch 16/50 - Total Loss: 2.8398 - Proportion Loss: 2.8398\n",
      "Epoch 17/50 - Total Loss: 2.8062 - Proportion Loss: 2.8062\n",
      "Epoch 18/50 - Total Loss: 2.7819 - Proportion Loss: 2.7819\n",
      "Epoch 19/50 - Total Loss: 2.7649 - Proportion Loss: 2.7649\n",
      "Epoch 20/50 - Total Loss: 2.7320 - Proportion Loss: 2.7320\n",
      "Epoch 21/50 - Total Loss: 2.7087 - Proportion Loss: 2.7087\n",
      "Epoch 22/50 - Total Loss: 2.6801 - Proportion Loss: 2.6801\n",
      "Epoch 23/50 - Total Loss: 2.6544 - Proportion Loss: 2.6544\n",
      "Epoch 24/50 - Total Loss: 2.6240 - Proportion Loss: 2.6240\n",
      "Epoch 25/50 - Total Loss: 2.5823 - Proportion Loss: 2.5823\n",
      "Epoch 26/50 - Total Loss: 2.5564 - Proportion Loss: 2.5564\n",
      "Epoch 27/50 - Total Loss: 2.5269 - Proportion Loss: 2.5269\n",
      "Epoch 28/50 - Total Loss: 2.4968 - Proportion Loss: 2.4968\n",
      "Epoch 29/50 - Total Loss: 2.4744 - Proportion Loss: 2.4744\n",
      "Epoch 30/50 - Total Loss: 2.4479 - Proportion Loss: 2.4479\n",
      "Epoch 31/50 - Total Loss: 2.4249 - Proportion Loss: 2.4249\n",
      "Epoch 32/50 - Total Loss: 2.4082 - Proportion Loss: 2.4082\n",
      "Epoch 33/50 - Total Loss: 2.3843 - Proportion Loss: 2.3843\n",
      "Epoch 34/50 - Total Loss: 2.3748 - Proportion Loss: 2.3748\n",
      "Epoch 35/50 - Total Loss: 2.3539 - Proportion Loss: 2.3539\n",
      "Epoch 36/50 - Total Loss: 2.3346 - Proportion Loss: 2.3346\n",
      "Epoch 37/50 - Total Loss: 2.3103 - Proportion Loss: 2.3103\n",
      "Epoch 38/50 - Total Loss: 2.2730 - Proportion Loss: 2.2730\n",
      "Epoch 39/50 - Total Loss: 2.2522 - Proportion Loss: 2.2522\n",
      "Epoch 40/50 - Total Loss: 2.2201 - Proportion Loss: 2.2201\n",
      "Epoch 41/50 - Total Loss: 2.1943 - Proportion Loss: 2.1943\n",
      "Epoch 42/50 - Total Loss: 2.1700 - Proportion Loss: 2.1700\n",
      "Epoch 43/50 - Total Loss: 2.1438 - Proportion Loss: 2.1438\n",
      "Epoch 44/50 - Total Loss: 2.1255 - Proportion Loss: 2.1255\n",
      "Epoch 45/50 - Total Loss: 2.1059 - Proportion Loss: 2.1059\n",
      "Epoch 46/50 - Total Loss: 2.0753 - Proportion Loss: 2.0753\n",
      "Epoch 47/50 - Total Loss: 2.0435 - Proportion Loss: 2.0435\n",
      "Epoch 48/50 - Total Loss: 2.0002 - Proportion Loss: 2.0002\n",
      "Epoch 49/50 - Total Loss: 1.9671 - Proportion Loss: 1.9671\n",
      "Epoch 50/50 - Total Loss: 1.9311 - Proportion Loss: 1.9311\n",
      "Training finished.\n",
      "Generating predictions...\n",
      "Predictions saved successfully to predictions_transformer_182625.csv\n",
      "\n",
      "Sample Predictions:\n",
      "   Sequence  Step     SourceID  Predicted_Proportion  Predicted_Increment  \\\n",
      "0         0     1  MRI_MSR_104              0.005128             1.574359   \n",
      "1         0     2    MRI_FRR_2              0.076923            23.615385   \n",
      "2         0     3  MRI_FRR_257              0.025641             7.871795   \n",
      "3         0     4  MRI_FRR_264              0.056410            17.317949   \n",
      "4         0     5  MRI_FRR_264              0.087179            26.764105   \n",
      "5         0     6   MRI_CCS_11              0.148718            45.656410   \n",
      "6         0     7   MRI_CCS_11              0.005128             1.574359   \n",
      "7         0     8  MRI_FRR_257              0.128205            39.358978   \n",
      "8         0     9  MRI_FRR_264              0.005128             1.574359   \n",
      "9         0    10  MRI_FRR_264              0.066667            20.466667   \n",
      "\n",
      "   Predicted_Cumulative  GroundTruth_Increment  GroundTruth_Cumulative  \n",
      "0              3.148718                   40.0                    40.0  \n",
      "1             26.764103                    5.0                    45.0  \n",
      "2             34.635899                    7.0                    52.0  \n",
      "3             51.953850                   16.0                    68.0  \n",
      "4             78.717957                    9.0                    77.0  \n",
      "5            124.374367                    6.0                    83.0  \n",
      "6            125.948723                  130.0                   213.0  \n",
      "7            165.307709                    1.0                   214.0  \n",
      "8            166.882065                   10.0                   224.0  \n",
      "9            187.348724                    2.0                   226.0  \n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to run the training and prediction process.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Replace with your actual file path\n",
    "        data_file = \"data/182625/encoded_182625_condensed.csv\"\n",
    "        # Check if the data file exists\n",
    "        if not os.path.exists(data_file):\n",
    "            print(f\"Error: Data file not found at {data_file}\")\n",
    "            print(\"Please ensure the data file is in the correct location.\")\n",
    "            return\n",
    "\n",
    "        # Train model and get results\n",
    "        # Pass num_bins and bin_edges to train_transformer\n",
    "        result = train_transformer(data_file, num_bins=NUM_BINS, bin_edges=BIN_EDGES)\n",
    "\n",
    "        if result is None:\n",
    "            print(\"Model training failed or no data was available. Exiting.\")\n",
    "            return\n",
    "\n",
    "        # Unpack results, including Y_binned_target\n",
    "        model, X_train, Y_cum_target, mask_train, total_times, sequences_sourceids, Y_binned_target = result\n",
    "\n",
    "        # Generate predictions CSV\n",
    "        # Pass bin_edges to generate_predictions_csv\n",
    "        predictions_df = generate_predictions_csv(\n",
    "            model, X_train, Y_cum_target, mask_train, total_times, sequences_sourceids, BIN_EDGES\n",
    "        )\n",
    "\n",
    "        if not predictions_df.empty:\n",
    "            print(\"\\nSample Predictions:\")\n",
    "            print(predictions_df.head(10))\n",
    "        else:\n",
    "            print(\"\\nNo predictions were generated.\")\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in main: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Ensure TensorFlow is using eager execution (usually default)\n",
    "    # tf.config.run_functions_eagerly(True) # Uncomment for easier debugging if needed\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
