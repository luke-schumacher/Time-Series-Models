{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2836c7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3cdf4307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Constants and Configuration ---\n",
    "\n",
    "MAX_SEQ_LEN = 128\n",
    "# Use multiple features to give the model context for predicting increments\n",
    "FEATURE_COLUMNS = ['predicted_proportion', 'sourceID', 'Step']\n",
    "\n",
    "# --- 2. Data Loading and Preparation: Targeting Increments ---\n",
    "\n",
    "def load_and_prepare_data(file_path):\n",
    "    \"\"\"\n",
    "    Loads data and prepares it for an increment-prediction model.\n",
    "    The target variable 'y' is now a sequence of time increments for each step.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"❌ Error: Predictions file not found at '{file_path}'\")\n",
    "        return None, None, None, None\n",
    "\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # --- NEW TARGET: CALCULATE TIME INCREMENTS ---\n",
    "    # The model will learn to predict the duration of each individual step.\n",
    "    df['time_increment'] = df.groupby('SeqOrder')['timediff'].diff().fillna(df['timediff'])\n",
    "\n",
    "    grouped = df.groupby('SeqOrder')\n",
    "    sequences_X = []\n",
    "    sequences_y = [] # Target is now a sequence of increments\n",
    "    \n",
    "    print(f\"Processing {len(grouped)} sequences for the LSTM model...\")\n",
    "    for _, group in grouped:\n",
    "        sequences_X.append(group[FEATURE_COLUMNS].values)\n",
    "        sequences_y.append(group['time_increment'].values.reshape(-1, 1))\n",
    "\n",
    "    return sequences_X, sequences_y, df\n",
    "\n",
    "# --- 3. LSTM Model Architecture: Sequence-to-Sequence ---\n",
    "\n",
    "def build_seq2seq_lstm_model(input_shape):\n",
    "    \"\"\"\n",
    "    Builds a sequence-to-sequence LSTM model to predict an output for every timestep.\n",
    "    \"\"\"\n",
    "    inputs = layers.Input(shape=(None, input_shape[-1]))\n",
    "    masking = layers.Masking(mask_value=0.0)(inputs)\n",
    "    \n",
    "    # LSTM layers must return sequences to make a prediction for each step\n",
    "    lstm1 = layers.LSTM(64, return_sequences=True)(masking)\n",
    "    dropout1 = layers.Dropout(0.2)(lstm1)\n",
    "    lstm2 = layers.LSTM(32, return_sequences=True)(dropout1)\n",
    "    \n",
    "    # UPDATED: Replaced TimeDistributed wrapper with a direct Dense layer.\n",
    "    # In modern Keras, a Dense layer automatically applies to the last dimension\n",
    "    # (the features) of each time step, which is more robust and avoids the graph error.\n",
    "    outputs = layers.Dense(1)(lstm2)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "# --- 4. Visualization Function ---\n",
    "\n",
    "def create_visualizations(history, results_df):\n",
    "    \"\"\"\n",
    "    Generates and saves plots for model analysis.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Generating Visualizations ---\")\n",
    "    \n",
    "    output_plot_dir = 'sequence_plots'\n",
    "    os.makedirs(output_plot_dir, exist_ok=True)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Model Training and Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss (MSE)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig('training_loss_plot.png')\n",
    "    print(\"✅ Saved training loss plot.\")\n",
    "    plt.close()\n",
    "\n",
    "    all_seq_orders = results_df['SeqOrder'].unique()\n",
    "    print(f\"Generating comparison plots for {len(all_seq_orders)} sequences...\")\n",
    "\n",
    "    for seq_order in all_seq_orders:\n",
    "        sample_df = results_df[results_df['SeqOrder'] == seq_order]\n",
    "        plt.figure(figsize=(12, 7))\n",
    "        plt.plot(sample_df['Step'], sample_df['timediff'], label='True Cumulative Time', marker='o')\n",
    "        plt.plot(sample_df['Step'], sample_df['predicted_cumulative_time'], label='Predicted Cumulative Time', marker='x', linestyle='--')\n",
    "        plt.title(f'Cumulative Time Comparison for Sequence {seq_order}')\n",
    "        plt.xlabel('Step')\n",
    "        plt.ylabel('Time (s)')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.savefig(os.path.join(output_plot_dir, f'cumulative_time_comparison_seq_{seq_order}.png'))\n",
    "        plt.close()\n",
    "        \n",
    "        plt.figure(figsize=(12, 7))\n",
    "        plt.plot(sample_df['Step'], sample_df['time_increment'], label='True Time Increment', marker='o')\n",
    "        plt.plot(sample_df['Step'], sample_df['predicted_time_increment'], label='Predicted Time Increment', marker='x', linestyle='--')\n",
    "        plt.title(f'Time Increment Comparison for Sequence {seq_order}')\n",
    "        plt.xlabel('Step')\n",
    "        plt.ylabel('Time (s)')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.savefig(os.path.join(output_plot_dir, f'time_increment_comparison_seq_{seq_order}.png'))\n",
    "        plt.close()\n",
    "\n",
    "    print(f\"✅ Saved individual sequence plots to the '{output_plot_dir}' directory.\")\n",
    "    \n",
    "    # For total time, we need to calculate it from the final cumulative time\n",
    "    total_time_analysis = results_df.groupby('SeqOrder').agg(\n",
    "        true_total_time=('timediff', 'max'),\n",
    "        predicted_total_time=('predicted_cumulative_time', 'max')\n",
    "    ).reset_index()\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.scatter(total_time_analysis['true_total_time'], total_time_analysis['predicted_total_time'], alpha=0.6)\n",
    "    plt.plot([0, total_time_analysis['true_total_time'].max()], [0, total_time_analysis['true_total_time'].max()], color='red', linestyle='--')\n",
    "    plt.title('True vs. Predicted Total Time')\n",
    "    plt.xlabel('True Total Time (s)')\n",
    "    plt.ylabel('Predicted Total Time (s)')\n",
    "    plt.grid(True)\n",
    "    plt.axis('equal')\n",
    "    plt.savefig('total_time_prediction_analysis.png')\n",
    "    print(\"✅ Saved total time prediction analysis plot.\")\n",
    "    plt.close()\n",
    "\n",
    "# --- 5. Main Orchestration ---\n",
    "\n",
    "def main():\n",
    "    proportions_file = 'prediction_176401_proportions.csv'\n",
    "    output_file = 'predictions_total_time_176401.csv'\n",
    "    \n",
    "    sequences_X, sequences_y, original_df = load_and_prepare_data(proportions_file)\n",
    "    if sequences_X is None: return\n",
    "\n",
    "    indices = np.arange(len(sequences_X))\n",
    "    train_indices, val_indices = train_test_split(indices, test_size=0.2, random_state=42)\n",
    "\n",
    "    X_train_unpadded = [sequences_X[i] for i in train_indices]\n",
    "    y_train_unpadded = [sequences_y[i] for i in train_indices]\n",
    "    X_val_unpadded = [sequences_X[i] for i in val_indices]\n",
    "    y_val_unpadded = [sequences_y[i] for i in val_indices]\n",
    "\n",
    "    scaler_X = StandardScaler().fit(np.vstack(X_train_unpadded))\n",
    "    scaler_y = StandardScaler().fit(np.vstack(y_train_unpadded))\n",
    "\n",
    "    X_train_scaled = [scaler_X.transform(seq) for seq in X_train_unpadded]\n",
    "    y_train_scaled = [scaler_y.transform(seq) for seq in y_train_unpadded]\n",
    "    X_val_scaled = [scaler_X.transform(seq) for seq in X_val_unpadded]\n",
    "    y_val_scaled = [scaler_y.transform(seq) for seq in y_val_unpadded]\n",
    "\n",
    "    X_train = tf.keras.preprocessing.sequence.pad_sequences(X_train_scaled, maxlen=MAX_SEQ_LEN, padding='post', dtype='float32')\n",
    "    y_train = tf.keras.preprocessing.sequence.pad_sequences(y_train_scaled, maxlen=MAX_SEQ_LEN, padding='post', dtype='float32')\n",
    "    X_val = tf.keras.preprocessing.sequence.pad_sequences(X_val_scaled, maxlen=MAX_SEQ_LEN, padding='post', dtype='float32')\n",
    "    y_val = tf.keras.preprocessing.sequence.pad_sequences(y_val_scaled, maxlen=MAX_SEQ_LEN, padding='post', dtype='float32')\n",
    "\n",
    "    model = build_seq2seq_lstm_model(X_train.shape)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mean_squared_error')\n",
    "    model.summary()\n",
    "\n",
    "    print(\"\\n--- Starting LSTM Model Training ---\")\n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.00001)\n",
    "    ]\n",
    "    history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=100, batch_size=16, callbacks=callbacks)\n",
    "    print(\"--- LSTM Model Training Finished ---\\n\")\n",
    "\n",
    "    print(\"--- Generating predictions for all sequences ---\")\n",
    "    all_sequences_scaled = [scaler_X.transform(seq) for seq in sequences_X]\n",
    "    X_all_padded = tf.keras.preprocessing.sequence.pad_sequences(all_sequences_scaled, maxlen=MAX_SEQ_LEN, padding='post', dtype='float32')\n",
    "    \n",
    "    predictions_scaled = model.predict(X_all_padded)\n",
    "    \n",
    "    # Reshape predictions and inverse transform\n",
    "    num_samples = predictions_scaled.shape[0]\n",
    "    num_timesteps = predictions_scaled.shape[1]\n",
    "    predictions_reshaped = predictions_scaled.reshape(num_samples * num_timesteps, 1)\n",
    "    predictions_unscaled_reshaped = scaler_y.inverse_transform(predictions_reshaped)\n",
    "    predicted_increments_padded = predictions_unscaled_reshaped.reshape(num_samples, num_timesteps, 1)\n",
    "\n",
    "    # Add predicted increments to the original DataFrame\n",
    "    results_df = original_df.copy()\n",
    "    predicted_increments_list = []\n",
    "    for i, seq in enumerate(sequences_X):\n",
    "        actual_len = len(seq)\n",
    "        predicted_increments_list.extend(predicted_increments_padded[i, :actual_len, 0])\n",
    "    \n",
    "    results_df['predicted_time_increment'] = predicted_increments_list\n",
    "    results_df['predicted_cumulative_time'] = results_df.groupby('SeqOrder')['predicted_time_increment'].cumsum()\n",
    "\n",
    "    results_df.to_csv(output_file, index=False)\n",
    "    print(f\"✅ Final predictions saved to '{output_file}'\")\n",
    "    \n",
    "    create_visualizations(history, results_df)\n",
    "    \n",
    "    print(\"\\n--- Sample of Final Output ---\")\n",
    "    print(results_df[['SeqOrder', 'Step', 'timediff', 'predicted_cumulative_time', 'time_increment', 'predicted_time_increment']].head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95c77dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 35 sequences for the LSTM model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_4         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ masking_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Masking</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ any_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Any</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ not_equal_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">17,408</span> │ masking_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │                   │            │ any_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │                   │            │ any_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │ lstm_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_4         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ input_layer_4[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ masking_4 (\u001b[38;5;33mMasking\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ input_layer_4[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ any_4 (\u001b[38;5;33mAny\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ not_equal_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_8 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │     \u001b[38;5;34m17,408\u001b[0m │ masking_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                     │                   │            │ any_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ lstm_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_9 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)  │     \u001b[38;5;34m12,416\u001b[0m │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                     │                   │            │ any_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)   │         \u001b[38;5;34m33\u001b[0m │ lstm_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29,857</span> (116.63 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m29,857\u001b[0m (116.63 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29,857</span> (116.63 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m29,857\u001b[0m (116.63 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting LSTM Model Training ---\n",
      "Epoch 1/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 572ms/step - loss: 1.0017 - val_loss: 14.0093 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 1.1790 - val_loss: 13.9797 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.9701 - val_loss: 13.9756 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.7342 - val_loss: 13.9814 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.9493 - val_loss: 13.9720 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 1.0544 - val_loss: 13.9602 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.8949 - val_loss: 13.9589 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.9943 - val_loss: 13.9538 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.8092 - val_loss: 13.9499 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.7475 - val_loss: 13.9324 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 1.1588 - val_loss: 13.8997 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 1.0789 - val_loss: 13.8778 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 0.8846 - val_loss: 13.8660 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.8584 - val_loss: 13.8483 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 0.7747 - val_loss: 13.8284 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.8590 - val_loss: 13.7989 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.9527 - val_loss: 13.7645 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.6877 - val_loss: 13.7513 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - loss: 0.8882 - val_loss: 13.7361 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.6787 - val_loss: 13.7497 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.8451 - val_loss: 13.7362 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 1.0215 - val_loss: 13.7144 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.9212 - val_loss: 13.7043 - learning_rate: 0.0010\n",
      "Epoch 24/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.9259 - val_loss: 13.6821 - learning_rate: 0.0010\n",
      "Epoch 25/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.8641 - val_loss: 13.6561 - learning_rate: 0.0010\n",
      "Epoch 26/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 1.1099 - val_loss: 13.6235 - learning_rate: 0.0010\n",
      "Epoch 27/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.9289 - val_loss: 13.6224 - learning_rate: 0.0010\n",
      "Epoch 28/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.8482 - val_loss: 13.6465 - learning_rate: 0.0010\n",
      "Epoch 29/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.7375 - val_loss: 13.6807 - learning_rate: 0.0010\n",
      "Epoch 30/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.7802 - val_loss: 13.6054 - learning_rate: 0.0010\n",
      "Epoch 31/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.9131 - val_loss: 13.5263 - learning_rate: 0.0010\n",
      "Epoch 32/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.7755 - val_loss: 13.4695 - learning_rate: 0.0010\n",
      "Epoch 33/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.8256 - val_loss: 13.4693 - learning_rate: 0.0010\n",
      "Epoch 34/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 1.0914 - val_loss: 13.4984 - learning_rate: 0.0010\n",
      "Epoch 35/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.8020 - val_loss: 13.5338 - learning_rate: 0.0010\n",
      "Epoch 36/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.8129 - val_loss: 13.5252 - learning_rate: 0.0010\n",
      "Epoch 37/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.8835 - val_loss: 13.4846 - learning_rate: 0.0010\n",
      "Epoch 38/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 1.0275 - val_loss: 13.3428 - learning_rate: 0.0010\n",
      "Epoch 39/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.8365 - val_loss: 13.3999 - learning_rate: 0.0010\n",
      "Epoch 40/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 1.0553 - val_loss: 13.4770 - learning_rate: 0.0010\n",
      "Epoch 41/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.9569 - val_loss: 13.5780 - learning_rate: 0.0010\n",
      "Epoch 42/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.7286 - val_loss: 13.6049 - learning_rate: 0.0010\n",
      "Epoch 43/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.9269 - val_loss: 13.3731 - learning_rate: 0.0010\n",
      "Epoch 44/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.6826 - val_loss: 13.3863 - learning_rate: 2.0000e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.7835 - val_loss: 13.3848 - learning_rate: 2.0000e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.7180 - val_loss: 13.3797 - learning_rate: 2.0000e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.9713 - val_loss: 13.3502 - learning_rate: 2.0000e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.9426 - val_loss: 13.3614 - learning_rate: 2.0000e-04\n",
      "--- LSTM Model Training Finished ---\n",
      "\n",
      "--- Generating predictions for all sequences ---\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 344ms/step\n",
      "✅ Final predictions saved to 'predictions_total_time_176401.csv'\n",
      "\n",
      "--- Generating Visualizations ---\n",
      "✅ Saved training loss plot.\n",
      "Generating comparison plots for 35 sequences...\n",
      "✅ Saved individual sequence plots to the 'sequence_plots' directory.\n",
      "✅ Saved total time prediction analysis plot.\n",
      "\n",
      "--- Sample of Final Output ---\n",
      "    SeqOrder  Step  timediff  predicted_cumulative_time  time_increment  \\\n",
      "0          0     0         0                   6.276213             0.0   \n",
      "1          0     1         4                   8.507768             4.0   \n",
      "2          0     2        13                   8.925238             9.0   \n",
      "3          0     3        14                  10.051905             1.0   \n",
      "4          0     4        28                  14.427940            14.0   \n",
      "5          0     5        28                  31.167133             0.0   \n",
      "6          0     6        36                  64.739723             8.0   \n",
      "7          0     7        45                 111.901810             9.0   \n",
      "8          0     8       106                 161.382660            61.0   \n",
      "9          0     9       140                 199.522354            34.0   \n",
      "10         0    10       195                 225.555939            55.0   \n",
      "11         0    11       269                 240.583145            74.0   \n",
      "12         0    12       270                 248.415726             1.0   \n",
      "13         0    13       276                 252.426559             6.0   \n",
      "14         0    14       276                 255.179428             0.0   \n",
      "15         0    15       278                 257.341064             2.0   \n",
      "16         0    16       279                 261.057068             1.0   \n",
      "17         0    17       279                 264.146088             0.0   \n",
      "18         0    18       279                 267.241302             0.0   \n",
      "19         0    19       285                 270.268463             6.0   \n",
      "\n",
      "    predicted_time_increment  \n",
      "0                   6.276213  \n",
      "1                   2.231555  \n",
      "2                   0.417470  \n",
      "3                   1.126667  \n",
      "4                   4.376036  \n",
      "5                  16.739193  \n",
      "6                  33.572590  \n",
      "7                  47.162083  \n",
      "8                  49.480862  \n",
      "9                  38.139683  \n",
      "10                 26.033581  \n",
      "11                 15.027214  \n",
      "12                  7.832580  \n",
      "13                  4.010833  \n",
      "14                  2.752870  \n",
      "15                  2.161640  \n",
      "16                  3.715985  \n",
      "17                  3.089034  \n",
      "18                  3.095227  \n",
      "19                  3.027138  \n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
