{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy version: 1.26.4\n",
      "tensorflow version: 2.18.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Output library versions\n",
    "print(f\"numpy version: {np.__version__}\")\n",
    "print(f\"tensorflow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Constants and Encoding Legend\n",
    "# ----------------------------\n",
    "START_TOKEN = 13\n",
    "END_TOKEN = 14\n",
    "\n",
    "ENCODING_LEGEND = {\n",
    "    'MRI_CCS_11': 1, 'MRI_EXU_95': 2, 'MRI_FRR_18': 3, 'MRI_FRR_257': 4,\n",
    "    'MRI_FRR_264': 5, 'MRI_FRR_3': 6, 'MRI_FRR_34': 7, 'MRI_MPT_1005': 8,\n",
    "    'MRI_MSR_100': 9, 'MRI_MSR_104': 10, 'MRI_MSR_21': 11, 'MRI_MSR_34': 12,\n",
    "    'START': START_TOKEN,\n",
    "    'END': END_TOKEN\n",
    "}\n",
    "# Build reverse mapping for decoding:\n",
    "reverse_encoding = {v: k for k, v in ENCODING_LEGEND.items()}\n",
    "\n",
    "CHAR_TO_INT = {\n",
    "    '0': 0,\n",
    "    '1': 1,\n",
    "    '2': 2,\n",
    "    '3': 3,\n",
    "    '4': 4,\n",
    "    '5': 5,\n",
    "    '6': 6,\n",
    "    '7': 7,\n",
    "    '8': 8,\n",
    "    '9': 9,\n",
    "    '10': 10,\n",
    "    '11': 11,\n",
    "    '12': 12,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded CSV with columns: ['SeqOrder', 'sourceID', 'timediff', 'PTAB', 'BodyGroup_from', 'BodyGroup_to']\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# Data Loading and Preparation\n",
    "# ----------------------------\n",
    "data_file = \"encoded_182625.csv\"  # Ensure this file is in your working directory.\n",
    "data = pd.read_csv(data_file)\n",
    "print(\"Loaded CSV with columns:\", data.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We assume the CSV contains columns \"sourceID\" and \"timediff\"\n",
    "source_ids = data['sourceID'].dropna().astype(float).tolist()\n",
    "cumulative_times = data['timediff'].dropna().astype(float).tolist()\n",
    "\n",
    "# Create a token sequence: add START at the beginning and END at the end.\n",
    "sequence = [START_TOKEN] + [int(s) for s in source_ids] + [END_TOKEN]\n",
    "\n",
    "# Adjust cumulative times:\n",
    "# Always prepend 0 and then, if necessary, append the last cumulative time so that\n",
    "# the number of cumulative times equals the number of tokens in 'sequence'.\n",
    "cumulative_times = [0.0] + cumulative_times  # Prepend 0 unconditionally.\n",
    "if len(sequence) != len(cumulative_times):\n",
    "    cumulative_times = cumulative_times + [cumulative_times[-1]]\n",
    "\n",
    "# Now, sequence and cumulative_times both have length = n + 2.\n",
    "# For training, we shift the data:\n",
    "# Use all tokens except the last as input.\n",
    "# Use cumulative times from the second token onward as targets.\n",
    "X_train = np.expand_dims(np.array(sequence[:-1], dtype=np.int32), axis=0)       # shape: (1, n+1)\n",
    "Y_cum_target = np.expand_dims(np.array(cumulative_times[1:], dtype=np.float32), axis=0)  # shape: (1, n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Target Computation Function\n",
    "# ----------------------------\n",
    "def compute_true_targets(cumulative_times):\n",
    "    \"\"\"\n",
    "    Given cumulative times (shape: [batch, L_target]), compute:\n",
    "      - true_proportions: the incremental differences normalized by total time.\n",
    "      - true_total: the total time (last cumulative value) per sample.\n",
    "    \"\"\"\n",
    "    # Compute increments: first value plus differences.\n",
    "    diffs = cumulative_times[:, 0:1]  # shape: (batch, 1)\n",
    "    diffs = tf.concat([diffs, cumulative_times[:, 1:] - cumulative_times[:, :-1]], axis=1)\n",
    "    true_total = cumulative_times[:, -1:]\n",
    "    true_total_safe = tf.where(true_total == 0, tf.ones_like(true_total), true_total)\n",
    "    true_proportions = diffs / true_total_safe\n",
    "    return true_proportions, true_total\n",
    "\n",
    "true_prop, true_total = compute_true_targets(tf.convert_to_tensor(Y_cum_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Transformer Components\n",
    "# ----------------------------\n",
    "def positional_encoding(length, depth):\n",
    "    depth = depth / 2\n",
    "    positions = np.arange(length)[:, np.newaxis]      # shape: (length, 1)\n",
    "    depths = np.arange(depth)[np.newaxis, :] / depth    # shape: (1, depth)\n",
    "    angle_rates = 1 / (10000 ** depths)\n",
    "    angle_rads = positions * angle_rates\n",
    "    pos_encoding = np.concatenate([np.sin(angle_rads), np.cos(angle_rads)], axis=-1)\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEmbedding(layers.Layer):\n",
    "    def __init__(self, vocab_size, d_model, max_len=4096, use_embedding=True):\n",
    "        super(PositionalEmbedding, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.use_embedding = use_embedding\n",
    "        if self.use_embedding:\n",
    "            self.embedding = layers.Embedding(vocab_size, d_model, mask_zero=True)\n",
    "        else:\n",
    "            self.embedding = layers.Dense(d_model, activation=\"relu\")\n",
    "        self.max_len = max_len\n",
    "        self.pos_encoding = positional_encoding(self.max_len, d_model)\n",
    "    \n",
    "    def compute_mask(self, *args, **kwargs):\n",
    "        if self.use_embedding:\n",
    "            return self.embedding.compute_mask(*args, **kwargs)\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    def call(self, x):\n",
    "        # x shape: (batch, seq_len)\n",
    "        x = self.embedding(x)  # (batch, seq_len, d_model)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        x += self.pos_encoding[tf.newaxis, :seq_len, :]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(layers.Layer):\n",
    "    def __init__(self, d_model, dff, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.seq = tf.keras.Sequential([\n",
    "            layers.Dense(dff, activation='relu'),\n",
    "            layers.Dense(d_model),\n",
    "            layers.Dropout(dropout_rate)\n",
    "        ])\n",
    "        self.add = layers.Add()\n",
    "        self.layer_norm = layers.LayerNormalization()\n",
    "    \n",
    "    def call(self, x):\n",
    "        x = self.add([x, self.seq(x)])\n",
    "        x = self.layer_norm(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalSelfAttention(layers.Layer):\n",
    "    def __init__(self, num_heads, d_model, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.mha = layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model, dropout=dropout_rate)\n",
    "        self.add = layers.Add()\n",
    "        self.layer_norm = layers.LayerNormalization()\n",
    "    \n",
    "    def call(self, x):\n",
    "        attn_output = self.mha(query=x, key=x, value=x, use_causal_mask=True)\n",
    "        x = self.add([x, attn_output])\n",
    "        x = self.layer_norm(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttentionFeedForwardLayer(layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.self_attention = CausalSelfAttention(num_heads=num_heads, d_model=d_model, dropout_rate=dropout_rate)\n",
    "        self.ffn = FeedForward(d_model, dff, dropout_rate)\n",
    "    \n",
    "    def call(self, x):\n",
    "        x = self.self_attention(x)\n",
    "        x = self.ffn(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, vocab_size, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.pos_embedding = PositionalEmbedding(vocab_size, d_model)\n",
    "        self.enc_layers = [SelfAttentionFeedForwardLayer(d_model, num_heads, dff, dropout_rate)\n",
    "                           for _ in range(num_layers)]\n",
    "        self.dropout = layers.Dropout(dropout_rate)\n",
    "    \n",
    "    def call(self, x):\n",
    "        x = self.pos_embedding(x)\n",
    "        x = self.dropout(x)\n",
    "        for layer in self.enc_layers:\n",
    "            x = layer(x)\n",
    "        return x  # (batch, seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, vocab_size, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.pos_embedding = PositionalEmbedding(vocab_size, d_model)\n",
    "        self.dropout = layers.Dropout(dropout_rate)\n",
    "        self.dec_layers = [SelfAttentionFeedForwardLayer(d_model, num_heads, dff, dropout_rate)\n",
    "                           for _ in range(num_layers)]\n",
    "    \n",
    "    def call(self, x, context):\n",
    "        x = self.pos_embedding(x)\n",
    "        x = self.dropout(x)\n",
    "        for layer in self.dec_layers:\n",
    "            x = layer(x)\n",
    "        return x  # (batch, seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# TimeDiffTransformer Model\n",
    "# ----------------------------\n",
    "class TimeDiffTransformer(tf.keras.Model):\n",
    "    \"\"\"\n",
    "    This model takes a sequence input (tokenized examination steps) and predicts:\n",
    "      1. A sequence of per-step proportions (via softmax so they sum to 1).\n",
    "      2. An overall total time (a nonnegative scalar via ReLU).\n",
    "    The predicted per-step time differences (increments) are computed by multiplying\n",
    "    the proportions with the total time.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(num_layers, d_model, num_heads, dff, input_vocab_size, dropout_rate)\n",
    "        self.decoder = Decoder(num_layers, d_model, num_heads, dff, input_vocab_size, dropout_rate)\n",
    "        self.proportion_head = layers.Dense(1)  # one value per token\n",
    "        self.total_time_head = layers.Dense(1, activation='relu')  # one scalar per sample\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        encoder_out = self.encoder(inputs)              # (batch, seq_len, d_model)\n",
    "        decoder_out = self.decoder(inputs, encoder_out)   # (batch, seq_len, d_model)\n",
    "        proportions_logits = self.proportion_head(decoder_out)  # (batch, seq_len, 1)\n",
    "        proportions_logits = tf.squeeze(proportions_logits, axis=-1)  # (batch, seq_len)\n",
    "        proportions = tf.nn.softmax(proportions_logits, axis=-1)\n",
    "        pooled_encoder = tf.reduce_mean(encoder_out, axis=1)  # (batch, d_model)\n",
    "        total_time = self.total_time_head(pooled_encoder)       # (batch, 1)\n",
    "        return proportions, total_time\n",
    "    \n",
    "    def predict_time_differences(self, inputs):\n",
    "        proportions, total_time = self(inputs)\n",
    "        pred_increments = proportions * total_time  # (batch, seq_len)\n",
    "        pred_cumulative = tf.math.cumsum(pred_increments, axis=1)\n",
    "        return proportions, pred_increments, pred_cumulative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Loss Functions\n",
    "# ----------------------------\n",
    "def proportion_loss(y_true, y_pred):\n",
    "    return tf.keras.losses.MeanSquaredError()(y_true, y_pred)\n",
    "\n",
    "def total_time_loss(y_true, y_pred):\n",
    "    return tf.keras.losses.MeanSquaredError()(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'query' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'key' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'value' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'causal_self_attention_66' (of type CausalSelfAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'sequential_66' (of type Sequential) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'feed_forward_66' (of type FeedForward) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'self_attention_feed_forward_layer_66' (of type SelfAttentionFeedForwardLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'causal_self_attention_67' (of type CausalSelfAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'sequential_67' (of type Sequential) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'feed_forward_67' (of type FeedForward) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'self_attention_feed_forward_layer_67' (of type SelfAttentionFeedForwardLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'causal_self_attention_68' (of type CausalSelfAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'sequential_68' (of type Sequential) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'feed_forward_68' (of type FeedForward) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'self_attention_feed_forward_layer_68' (of type SelfAttentionFeedForwardLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'causal_self_attention_69' (of type CausalSelfAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'sequential_69' (of type Sequential) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'feed_forward_69' (of type FeedForward) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'self_attention_feed_forward_layer_69' (of type SelfAttentionFeedForwardLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'causal_self_attention_70' (of type CausalSelfAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'sequential_70' (of type Sequential) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'feed_forward_70' (of type FeedForward) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'self_attention_feed_forward_layer_70' (of type SelfAttentionFeedForwardLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'causal_self_attention_71' (of type CausalSelfAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'sequential_71' (of type Sequential) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'feed_forward_71' (of type FeedForward) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lukis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'self_attention_feed_forward_layer_71' (of type SelfAttentionFeedForwardLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"time_diff_transformer_11\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"time_diff_transformer_11\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ encoder_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Encoder</span>)            │ ?                      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">126,624</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ decoder_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Decoder</span>)            │ ?                      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">126,624</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_166 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3801</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)           │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_167 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ encoder_11 (\u001b[38;5;33mEncoder\u001b[0m)            │ ?                      │       \u001b[38;5;34m126,624\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ decoder_11 (\u001b[38;5;33mDecoder\u001b[0m)            │ ?                      │       \u001b[38;5;34m126,624\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_166 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m3801\u001b[0m, \u001b[38;5;34m1\u001b[0m)           │            \u001b[38;5;34m33\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_167 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">253,314</span> (989.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m253,314\u001b[0m (989.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">253,314</span> (989.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m253,314\u001b[0m (989.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19s/step - loss: 1545049.0000 - proportion_loss_loss: 0.0121 - total_time_loss_loss: 1545049.0000\n",
      "Epoch 2/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 1545049.0000 - proportion_loss_loss: 0.0121 - total_time_loss_loss: 1545049.0000\n",
      "Epoch 3/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 1545049.0000 - proportion_loss_loss: 0.0121 - total_time_loss_loss: 1545049.0000\n",
      "Epoch 4/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 1545049.0000 - proportion_loss_loss: 0.0121 - total_time_loss_loss: 1545049.0000\n",
      "Epoch 5/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 1545049.0000 - proportion_loss_loss: 0.0121 - total_time_loss_loss: 1545049.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1e20e25eef0>"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# Model Instantiation, Compilation, and Training\n",
    "# ----------------------------\n",
    "vocab_size = max(ENCODING_LEGEND.values()) + 1  # e.g., 15\n",
    "model = TimeDiffTransformer(num_layers=3, d_model=32, num_heads=8, dff=128,\n",
    "                            input_vocab_size=vocab_size, dropout_rate=0.1)\n",
    "\n",
    "# Force a forward pass to build the model's weights.\n",
    "_ = model(X_train)\n",
    "model.summary()\n",
    "\n",
    "# Compile with two losses.\n",
    "model.compile(optimizer='adam', loss=[proportion_loss, total_time_loss])\n",
    "\n",
    "# Train the model.\n",
    "# (For demonstration; for real use, you will need more sequences.)\n",
    "model.fit(X_train, [true_prop, true_total], epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictions saved to predictions.csv\n",
      "\n",
      "Sample predictions:\n",
      "   Step     SourceID  Predicted_Proportion  Predicted_Increment   \n",
      "0     1  MRI_MSR_104              0.000382                  0.0  \\\n",
      "1     2       UNK(0)              0.000155                  0.0   \n",
      "2     3  MRI_FRR_257              0.000171                  0.0   \n",
      "3     4  MRI_FRR_264              0.000234                  0.0   \n",
      "4     5  MRI_FRR_264              0.000441                  0.0   \n",
      "5     6   MRI_CCS_11              0.000879                  0.0   \n",
      "6     7   MRI_CCS_11              0.000702                  0.0   \n",
      "7     8  MRI_FRR_257              0.000406                  0.0   \n",
      "8     9  MRI_FRR_264              0.000307                  0.0   \n",
      "9    10  MRI_FRR_264              0.000303                  0.0   \n",
      "\n",
      "   Predicted_Cumulative  GroundTruth_Increment  GroundTruth_Cumulative  \n",
      "0                   0.0                    0.0                     0.0  \n",
      "1                   0.0                   40.0                    40.0  \n",
      "2                   0.0                    5.0                    45.0  \n",
      "3                   0.0                    7.0                    52.0  \n",
      "4                   0.0                   16.0                    68.0  \n",
      "5                   0.0                    9.0                    77.0  \n",
      "6                   0.0                    6.0                    83.0  \n",
      "7                   0.0                  130.0                   213.0  \n",
      "8                   0.0                    1.0                   214.0  \n",
      "9                   0.0                   10.0                   224.0  \n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# Inference and CSV Output\n",
    "# ----------------------------\n",
    "proportions_pred, increments_pred, cumulative_pred = model.predict_time_differences(X_train)\n",
    "\n",
    "# Convert predictions to numpy arrays.\n",
    "proportions_pred = proportions_pred.numpy()[0]  # shape: (L,)\n",
    "increments_pred = increments_pred.numpy()[0]    # shape: (L,)\n",
    "cumulative_pred = cumulative_pred.numpy()[0]    # shape: (L,)\n",
    "\n",
    "# Ground truth for the shifted targets.\n",
    "ground_truth_increments = np.concatenate([Y_cum_target[:, 0:1], Y_cum_target[:, 1:] - Y_cum_target[:, :-1]], axis=1)[0]\n",
    "ground_truth_cumulative = Y_cum_target[0]\n",
    "\n",
    "# Decode the sourceIDs corresponding to the target steps (i.e., excluding the START token).\n",
    "decoded_sourceIDs = []\n",
    "for token in sequence[1:]:\n",
    "    if token == END_TOKEN:\n",
    "        decoded_sourceIDs.append(\"END\")\n",
    "    else:\n",
    "        decoded_sourceIDs.append(reverse_encoding.get(token, f\"UNK({token})\"))\n",
    "\n",
    "# Create an output DataFrame.\n",
    "output_df = pd.DataFrame({\n",
    "    \"Step\": np.arange(1, len(sequence)),\n",
    "    \"SourceID\": decoded_sourceIDs,\n",
    "    \"Predicted_Proportion\": proportions_pred,\n",
    "    \"Predicted_Increment\": increments_pred,\n",
    "    \"Predicted_Cumulative\": cumulative_pred,\n",
    "    \"GroundTruth_Increment\": ground_truth_increments,\n",
    "    \"GroundTruth_Cumulative\": ground_truth_cumulative\n",
    "})\n",
    "\n",
    "# Save predictions to CSV.\n",
    "output_csv = \"predictions.csv\"\n",
    "output_df.to_csv(output_csv, index=False)\n",
    "print(f\"\\nPredictions saved to {output_csv}\")\n",
    "print(\"\\nSample predictions:\")\n",
    "print(output_df.head(10))\n",
    "\n",
    "# Model needs to be split into 2 parts, one part that predicts propotions and the other part that predicts total time.\n",
    "# The model is trained with 2 loss functions, one for the proportions and the other for the total time.\n",
    "# The model is trained with the true proportions and total time as targets?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
