{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants and Encoding\n",
    "START_TOKEN = 13\n",
    "END_TOKEN = 14\n",
    "ENCODING_LEGEND = {\n",
    "    'MRI_CCS_11': 1, 'MRI_EXU_95': 2, 'MRI_FRR_18': 3, 'MRI_FRR_257': 4,\n",
    "    'MRI_FRR_264': 5, 'MRI_FRR_2': 6, 'MRI_FRR_3': 7, 'MRI_FRR_34': 8, 'MRI_MPT_1005': 9,\n",
    "    'MRI_MSR_100': 10, 'MRI_MSR_104': 11, 'MRI_MSR_21': 12,\n",
    "    'START': START_TOKEN, 'END': END_TOKEN\n",
    "}\n",
    "reverse_encoding = {v: k for k, v in ENCODING_LEGEND.items()}\n",
    "\n",
    "# Define valid source IDs for filtering (excluding START and END tokens)\n",
    "VALID_SOURCE_IDS = set([k for k in ENCODING_LEGEND.keys() if k not in ['START', 'END']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data(data_file):\n",
    "    \"\"\"\n",
    "    Loads and preprocesses data from a CSV file, filtering out invalid sourceIDs.\n",
    "    Splits data into sequences based on SeqOrder.\n",
    "    \"\"\"\n",
    "    print(f\"Loading data from {data_file}...\")\n",
    "    data = pd.read_csv(data_file)\n",
    "\n",
    "    all_sequences_tokens = []\n",
    "    all_sequences_times = []\n",
    "    all_sequences_sourceids = []\n",
    "\n",
    "    current_tokens = []\n",
    "    current_times = []\n",
    "    current_sourceids = []\n",
    "\n",
    "    for idx, row in data.iterrows():\n",
    "        seq_order = row['SeqOrder']\n",
    "        s_id = str(row['sourceID']) # Ensure s_id is string for lookup\n",
    "        t_diff = float(row['timediff'])\n",
    "\n",
    "        # Filter: Only process rows with valid sourceIDs\n",
    "        if s_id not in VALID_SOURCE_IDS:\n",
    "            # print(f\"Skipping row with invalid sourceID: {s_id}\") # Optional: uncomment for debugging\n",
    "            continue\n",
    "\n",
    "        if seq_order == 0 and current_tokens:\n",
    "            # Finalize previous sequence if it exists and we are starting a new one\n",
    "            token_seq = [START_TOKEN] + [int(ENCODING_LEGEND[x]) for x in current_tokens] + [END_TOKEN]\n",
    "            time_seq = [0.0] + current_times\n",
    "\n",
    "            all_sequences_tokens.append(token_seq)\n",
    "            all_sequences_times.append(time_seq)\n",
    "            all_sequences_sourceids.append(current_sourceids)\n",
    "\n",
    "            # Reset for the new sequence\n",
    "            current_tokens = []\n",
    "            current_times = []\n",
    "            current_sourceids = []\n",
    "\n",
    "        # Append current valid token and time difference\n",
    "        current_tokens.append(s_id)\n",
    "        current_times.append(t_diff)\n",
    "        current_sourceids.append(s_id) # Store the original string sourceID\n",
    "\n",
    "    # Add the last sequence if data is not empty\n",
    "    if current_tokens:\n",
    "        token_seq = [START_TOKEN] + [int(ENCODING_LEGEND[x]) for x in current_tokens] + [END_TOKEN]\n",
    "        time_seq = [0.0] + current_times\n",
    "\n",
    "        all_sequences_tokens.append(token_seq)\n",
    "        all_sequences_times.append(time_seq)\n",
    "        all_sequences_sourceids.append(current_sourceids)\n",
    "\n",
    "    print(f\"Loaded {len(all_sequences_tokens)} sequences.\")\n",
    "    return all_sequences_tokens, all_sequences_times, all_sequences_sourceids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_training_data(sequences_tokens, sequences_times):\n",
    "    \"\"\"\n",
    "    Prepares sequences for transformer training, including padding and masks.\n",
    "    Calculates target cumulative times and total times.\n",
    "    \"\"\"\n",
    "    X_list, Y_list, masks_list, total_times_list = [], [], [], []\n",
    "\n",
    "    for tokens, times in zip(sequences_tokens, sequences_times):\n",
    "        # Ensure sequence has at least START and END tokens plus one event\n",
    "        if len(tokens) < 3:\n",
    "            # print(f\"Skipping short sequence with {len(tokens)} tokens.\") # Optional: uncomment for debugging\n",
    "            continue\n",
    "\n",
    "        # The last element in times should be the cumulative time of the last event\n",
    "        # which corresponds to the total time of the sequence.\n",
    "        total_time = times[-1]\n",
    "\n",
    "        # Input sequence X: START, Event1, Event2, ... EventN\n",
    "        x_seq = tokens[:-1]\n",
    "\n",
    "        # Target cumulative times Y: Time1, Time2, ... TimeN\n",
    "        # These are the cumulative times *at the end* of each step.\n",
    "        y_seq = times[1:]\n",
    "\n",
    "        # Mask: 1 for valid input tokens (not END_TOKEN), 0 otherwise\n",
    "        # The mask applies to the *input* sequence (X_list).\n",
    "        mask_seq = [1 if t != END_TOKEN else 0 for t in x_seq]\n",
    "\n",
    "        X_list.append(x_seq)\n",
    "        Y_list.append(y_seq)\n",
    "        masks_list.append(mask_seq)\n",
    "        total_times_list.append(total_time)\n",
    "\n",
    "    if not X_list:\n",
    "        print(\"No valid sequences found after preprocessing.\")\n",
    "        return np.array([]), np.array([]), np.array([]), np.array([])\n",
    "\n",
    "\n",
    "    # Determine max length based on the processed sequences\n",
    "    max_len = max(len(x) for x in X_list)\n",
    "    print(f\"Padding sequences to max length: {max_len}\")\n",
    "\n",
    "    # Pad sequences\n",
    "    # X_train: pad with END_TOKEN (mask_zero=True in embedding will ignore this)\n",
    "    X_train = pad_sequences(X_list, maxlen=max_len, padding='post', value=END_TOKEN)\n",
    "    # Y_cum_target: pad with 0.0\n",
    "    Y_cum_target = pad_sequences(Y_list, maxlen=max_len, padding='post', value=0.0)\n",
    "    # mask_train: pad with 0\n",
    "    mask_train = pad_sequences(masks_list, maxlen=max_len, padding='post', value=0)\n",
    "\n",
    "    X_train = np.array(X_train, dtype=np.int32)\n",
    "    Y_cum_target = np.array(Y_cum_target, dtype=np.float32)\n",
    "    mask_train = np.array(mask_train, dtype=np.float32)\n",
    "    total_times = np.array(total_times_list, dtype=np.float32)\n",
    "\n",
    "    print(f\"Prepared {X_train.shape[0]} sequences for training.\")\n",
    "    return X_train, Y_cum_target, mask_train, total_times\n",
    "\n",
    "# %%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Transformer Components (unchanged)\n",
    "# ----------------------------\n",
    "def positional_encoding(length, depth):\n",
    "    depth = depth / 2\n",
    "    positions = np.arange(length)[:, np.newaxis]\n",
    "    depths = np.arange(depth)[np.newaxis, :] / depth\n",
    "    angle_rates = 1 / (10000 ** depths)\n",
    "    angle_rads = positions * angle_rates\n",
    "    pos_encoding = np.concatenate([np.sin(angle_rads), np.cos(angle_rads)], axis=-1)\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)\n",
    "\n",
    "class PositionalEmbedding(layers.Layer):\n",
    "    def __init__(self, vocab_size, d_model, max_len=16384, use_embedding=True):\n",
    "        super(PositionalEmbedding, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.use_embedding = use_embedding\n",
    "        if self.use_embedding:\n",
    "            # Set mask_zero to the actual padding value (END_TOKEN)\n",
    "            self.embedding = layers.Embedding(vocab_size, d_model, mask_zero=END_TOKEN)\n",
    "        else:\n",
    "            # If not using embedding, assume input is already dense (e.g., time features)\n",
    "            self.embedding = layers.Dense(d_model, activation=\"relu\")\n",
    "        self.max_len = max_len\n",
    "        # Ensure pos_encoding is created once and is large enough\n",
    "        self.pos_encoding = positional_encoding(self.max_len, d_model)\n",
    "\n",
    "    # Correct compute_mask signature to accept optional mask argument\n",
    "    def compute_mask(self, x, mask=None):\n",
    "         # If using embedding with mask_zero, the mask is computed based on mask_zero value\n",
    "         if self.use_embedding:\n",
    "              # Return a boolean mask indicating which elements are NOT the mask_zero value\n",
    "              return tf.math.not_equal(x, self.embedding.mask_zero)\n",
    "         # Otherwise, assume all steps are valid unless explicitly masked later\n",
    "         return None\n",
    "\n",
    "    def call(self, x):\n",
    "        # x is assumed to be token IDs if use_embedding is True, otherwise dense features\n",
    "        if self.use_embedding:\n",
    "            # The embedding layer itself computes and propagates the mask because mask_zero is set\n",
    "            x = self.embedding(x)\n",
    "        else:\n",
    "             # Apply dense layer if input is not token IDs\n",
    "             x = self.embedding(x)\n",
    "\n",
    "        # Scale the embedding output\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "\n",
    "        # Add positional encoding\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        # Ensure positional encoding slice matches sequence length\n",
    "        x += self.pos_encoding[tf.newaxis, :seq_len, :]\n",
    "        return x\n",
    "\n",
    "class FeedForward(layers.Layer):\n",
    "    def __init__(self, d_model, dff, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.seq = tf.keras.Sequential([\n",
    "            layers.Dense(dff, activation='relu'),\n",
    "            layers.Dense(d_model),\n",
    "            layers.Dropout(dropout_rate)\n",
    "        ])\n",
    "        self.add = layers.Add()\n",
    "        self.layer_norm = layers.LayerNormalization()\n",
    "\n",
    "    def call(self, x):\n",
    "        # Apply feed forward network with residual connection and layer normalization\n",
    "        x = self.add([x, self.seq(x)])\n",
    "        x = self.layer_norm(x)\n",
    "        return x\n",
    "\n",
    "class CausalSelfAttention(layers.Layer):\n",
    "    def __init__(self, num_heads, d_model, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        # MultiHeadAttention layer with causal mask\n",
    "        self.mha = layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model, dropout=dropout_rate)\n",
    "        self.add = layers.Add()\n",
    "        self.layer_norm = layers.LayerNormalization()\n",
    "\n",
    "    def call(self, x):\n",
    "        # Apply multi-head self-attention\n",
    "        # Keras automatically uses the mask attached to the input 'x'\n",
    "        attn_output = self.mha(query=x, key=x, value=x, use_causal_mask=True)\n",
    "        # Add residual connection and layer normalization\n",
    "        x = self.add([x, attn_output])\n",
    "        x = self.layer_norm(x)\n",
    "        return x\n",
    "\n",
    "class SelfAttentionFeedForwardLayer(layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        # Composes CausalSelfAttention and FeedForward layers\n",
    "        self.self_attention = CausalSelfAttention(num_heads=num_heads, d_model=d_model, dropout_rate=dropout_rate)\n",
    "        self.ffn = FeedForward(d_model, dff, dropout_rate)\n",
    "\n",
    "    def call(self, x):\n",
    "        # Pass input through self-attention and then feed-forward network\n",
    "        # Mask from 'x' is propagated through these layers\n",
    "        x = self.self_attention(x)\n",
    "        x = self.ffn(x)\n",
    "        return x\n",
    "\n",
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, vocab_size, dropout_rate=0.1, max_len=16384):\n",
    "        super().__init__()\n",
    "        # Positional embedding for the input tokens\n",
    "        self.pos_embedding = PositionalEmbedding(vocab_size, d_model, max_len=max_len)\n",
    "        # Stack of encoder layers\n",
    "        self.enc_layers = [SelfAttentionFeedForwardLayer(d_model, num_heads, dff, dropout_rate)\n",
    "                           for _ in range(num_layers)]\n",
    "        self.dropout = layers.Dropout(dropout_rate)\n",
    "\n",
    "    def call(self, x):\n",
    "        # Apply positional embedding and dropout.\n",
    "        # The output 'x' from pos_embedding will carry the mask computed by PositionalEmbedding.compute_mask.\n",
    "        x = self.pos_embedding(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # Pass through encoder layers. Keras will automatically propagate the mask\n",
    "        # through the layers that support masking (like MultiHeadAttention).\n",
    "        for layer in self.enc_layers:\n",
    "            x = layer(x)\n",
    "\n",
    "        return x # The output tensor carries the mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeDiffTransformer(tf.keras.Model):\n",
    "    \"\"\"\n",
    "    Transformer model predicting proportions of total time for each sequence step.\n",
    "    This version removes the total time prediction head.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, dropout_rate=0.1, max_len=16384):\n",
    "        super().__init__()\n",
    "        # Encoder processes the input sequence of tokens\n",
    "        self.encoder = Encoder(num_layers, d_model, num_heads, dff, input_vocab_size, dropout_rate, max_len)\n",
    "\n",
    "        # Head to predict the proportion of time for each step in the sequence\n",
    "        # Output is a single value per sequence step before softmax\n",
    "        self.proportion_head = layers.Dense(1)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Pass input through the encoder\n",
    "        encoder_out = self.encoder(inputs) # encoder_out shape: (batch_size, seq_len, d_model)\n",
    "        # The mask from the embedding layer is propagated to encoder_out\n",
    "\n",
    "        # Predict proportions for each step\n",
    "        # proportions shape: (batch_size, seq_len, 1)\n",
    "        proportions = self.proportion_head(encoder_out)\n",
    "\n",
    "        # Remove the last dimension, proportions shape: (batch_size, seq_len)\n",
    "        proportions = tf.squeeze(proportions, axis=-1)\n",
    "\n",
    "        # Apply softmax across the sequence dimension to get proportions that sum to 1\n",
    "        # Keras Softmax layer can handle masks if the input tensor has one.\n",
    "        proportions = tf.nn.softmax(proportions, axis=1)\n",
    "\n",
    "        # Return only the predicted proportions\n",
    "        return proportions # proportions shape: (batch_size, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_time_differences(proportions, total_time, mask):\n",
    "    \"\"\"\n",
    "    Computes predicted increments and cumulative times from proportions and total time.\n",
    "    Applies masking to ignore padded steps.\n",
    "\n",
    "    Args:\n",
    "        proportions: Predicted proportions for each step (batch_size, seq_len).\n",
    "        total_time: The total time for each sequence (batch_size, 1).\n",
    "        mask: Mask indicating valid steps (batch_size, seq_len).\n",
    "\n",
    "    Returns:\n",
    "        proportions: Normalized proportions (batch_size, seq_len).\n",
    "        increments: Predicted time increments (batch_size, seq_len).\n",
    "        cumulative_times: Predicted cumulative times (batch_size, seq_len).\n",
    "    \"\"\"\n",
    "    # Apply mask to ensure only valid tokens contribute to calculations\n",
    "    proportions *= tf.cast(mask, tf.float32)\n",
    "\n",
    "    # Compute row-wise sum for normalization to handle variable-length sequences\n",
    "    # Sum across the sequence length dimension (axis=1)\n",
    "    row_sums = tf.reduce_sum(proportions, axis=1, keepdims=True)\n",
    "    # Prevent division by zero if a sequence is entirely masked (shouldn't happen with START token)\n",
    "    row_sums = tf.where(tf.equal(row_sums, 0), tf.ones_like(row_sums), row_sums)\n",
    "\n",
    "    # Normalize proportions so they sum to 1 over the valid (unmasked) steps\n",
    "    proportions /= row_sums\n",
    "\n",
    "    # Compute increments by multiplying normalized proportions by the total time\n",
    "    # total_time should have shape (batch_size, 1) for correct broadcasting\n",
    "    increments = proportions * total_time # Broadcasting total_time\n",
    "\n",
    "    # Compute cumulative times by summing increments along the sequence dimension\n",
    "    cumulative_times = tf.math.cumsum(increments, axis=1)\n",
    "\n",
    "    return proportions, increments, cumulative_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_transformer(data_file, epochs=50, batch_size=32):\n",
    "    \"\"\"\n",
    "    Trains the TimeDiffTransformer model.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load and preprocess data\n",
    "        sequences_tokens, sequences_times, sequences_sourceids = load_and_preprocess_data(data_file)\n",
    "\n",
    "        # Prepare data for training\n",
    "        X_train, Y_cum_target, mask_train, total_times = prepare_training_data(sequences_tokens, sequences_times)\n",
    "\n",
    "        if X_train.shape[0] == 0:\n",
    "            print(\"No data available for training after preprocessing.\")\n",
    "            return None, None, None, None, None, None\n",
    "\n",
    "        # Model parameters\n",
    "        # Vocab size needs to include all possible token IDs + 1 for potential 0 padding if mask_zero wasn't used,\n",
    "        # but with mask_zero=END_TOKEN, the padding value is handled. Still good practice to have vocab_size cover all IDs.\n",
    "        vocab_size = max(ENCODING_LEGEND.values()) + 1\n",
    "        max_seq_len = X_train.shape[1]\n",
    "\n",
    "        # Instantiate the model (now only predicts proportions)\n",
    "        model = TimeDiffTransformer(\n",
    "            num_layers=3,\n",
    "            d_model=64,\n",
    "            num_heads=8,\n",
    "            dff=128,\n",
    "            input_vocab_size=vocab_size,\n",
    "            dropout_rate=0.1,\n",
    "            max_len=max_seq_len # Pass max_len to the model\n",
    "        )\n",
    "\n",
    "        # Optimizer\n",
    "        optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "        # Loss function for proportions (Mean Squared Error)\n",
    "        # We will compute true proportions within the train step\n",
    "        proportion_loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "        @tf.function\n",
    "        def train_step(x, y_cum, mask): # Removed total_time from inputs\n",
    "            with tf.GradientTape() as tape:\n",
    "                # Model predicts proportions\n",
    "                pred_props = model(x) # pred_props shape: (batch_size, seq_len)\n",
    "\n",
    "                # Compute true time differences and total time from cumulative targets\n",
    "                # time_diffs shape: (batch_size, seq_len - 1)\n",
    "                time_diffs = y_cum[:, 1:] - y_cum[:, :-1]\n",
    "                # true_total shape: (batch_size,)\n",
    "                true_total = y_cum[:, -1] # Total time is the last cumulative time\n",
    "\n",
    "                # Compute true proportions for the steps *after* the START token\n",
    "                # true_total_expanded shape: (batch_size, 1)\n",
    "                true_total_expanded = tf.where(\n",
    "                    tf.equal(true_total, 0),\n",
    "                    tf.ones_like(true_total),\n",
    "                    true_total\n",
    "                )[:, tf.newaxis]\n",
    "\n",
    "                # true_props_unpadded shape: (batch_size, seq_len - 1) - corresponds to steps 1 to N\n",
    "                true_props_unpadded = time_diffs / true_total_expanded\n",
    "\n",
    "                # Pad true_props to match pred_props shape (batch_size, seq_len)\n",
    "                # The first position (corresponding to START token input) should have 0 proportion\n",
    "                true_props_padded = tf.pad(true_props_unpadded, [[0, 0], [1, 0]], constant_values=0.0)\n",
    "\n",
    "                # Apply mask to both predicted and true proportions for loss calculation\n",
    "                # Mask applies to the input sequence, which aligns with predicted proportions\n",
    "                # Ensure mask is float32 for multiplication\n",
    "                mask_float = tf.cast(mask, tf.float32)\n",
    "\n",
    "                # Compute masked proportion loss\n",
    "                # Only consider loss for steps where mask is 1\n",
    "                masked_props_loss = proportion_loss_fn(true_props_padded * mask_float, pred_props * mask_float)\n",
    "\n",
    "                total_loss = masked_props_loss # Total loss is just the proportion loss\n",
    "\n",
    "            # Compute gradients and apply optimizer\n",
    "            grads = tape.gradient(total_loss, model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "            return total_loss, masked_props_loss\n",
    "\n",
    "        # Training loop\n",
    "        print(\"Starting training...\")\n",
    "        for epoch in range(epochs):\n",
    "            # Pass only necessary data to train_step\n",
    "            loss, props_loss = train_step(X_train, Y_cum_target, mask_train)\n",
    "            print(f\"Epoch {epoch+1}/{epochs} - Total Loss: {loss.numpy():.4f} - Proportion Loss: {props_loss.numpy():.4f}\")\n",
    "\n",
    "        print(\"Training finished.\")\n",
    "        return model, X_train, Y_cum_target, mask_train, total_times, sequences_sourceids\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in train_transformer: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None, None, None, None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_predictions_csv(model, X_train, Y_cum_target, mask_train, total_times, sequences_sourceids):\n",
    "    \"\"\"\n",
    "    Generates predictions using the trained model and saves them to a CSV file,\n",
    "    correctly aligning SourceIDs with sequence steps.\n",
    "    Uses the *true* total_times to compute predicted increments/cumulative times\n",
    "    for comparison purposes, as the model no longer predicts total time.\n",
    "\n",
    "    Args:\n",
    "        model: The trained TimeDiffTransformer model (only predicts proportions).\n",
    "        X_train: The input sequences (padded).\n",
    "        Y_cum_target: The target cumulative times (padded).\n",
    "        mask_train: The mask indicating valid sequence positions.\n",
    "        total_times: The true total time for each sequence (NumPy array).\n",
    "        sequences_sourceids: A list of lists, where each inner list contains\n",
    "                             the original source IDs for a sequence.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: The DataFrame containing predictions and ground truth.\n",
    "    \"\"\"\n",
    "    if model is None:\n",
    "        print(\"Model is None, cannot generate predictions.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    print(\"Generating predictions...\")\n",
    "\n",
    "    # Predict proportions using the model\n",
    "    # model(X_train) returns proportions with shape (batch_size, seq_len)\n",
    "    proportions_pred = model(X_train)\n",
    "\n",
    "    # Compute predicted increments and cumulative times using the *true* total_times\n",
    "    # Ensure total_times is a TensorFlow tensor with a batch dimension\n",
    "    total_times_tf = tf.constant(total_times, dtype=tf.float32)\n",
    "    # Expand total_times to shape (batch_size, 1) for correct broadcasting\n",
    "    total_times_expanded = tf.expand_dims(total_times_tf, axis=1)\n",
    "\n",
    "    # Use compute_time_differences with predicted proportions and true total time\n",
    "    # compute_time_differences expects total_time with shape (batch_size, 1)\n",
    "    proportions_pred_norm, increments_pred, cumulative_pred = compute_time_differences(\n",
    "        proportions_pred, total_times_expanded, mask_train\n",
    "    )\n",
    "\n",
    "    # Convert TensorFlow tensors to NumPy arrays for easier handling\n",
    "    proportions_pred_np = proportions_pred_norm.numpy()\n",
    "    increments_pred_np = increments_pred.numpy()\n",
    "    cumulative_pred_np = cumulative_pred.numpy()\n",
    "    X_train_np = X_train # Already numpy\n",
    "    Y_cum_target_np = Y_cum_target # Already numpy\n",
    "    mask_train_np = mask_train # Already numpy\n",
    "\n",
    "    # Compute ground truth increments for comparison\n",
    "    # Handle the first element carefully (it's the time of the first event relative to start)\n",
    "    gt_increments = np.zeros_like(Y_cum_target_np)\n",
    "    # The first increment is the first cumulative time\n",
    "    gt_increments[:, 0] = Y_cum_target_np[:, 0]\n",
    "    # Subsequent increments are the differences between consecutive cumulative times\n",
    "    gt_increments[:, 1:] = Y_cum_target_np[:, 1:] - Y_cum_target_np[:, :-1]\n",
    "    # Apply mask to ground truth increments as well\n",
    "    gt_increments *= mask_train_np\n",
    "\n",
    "\n",
    "    # Collect predictions in a list of dictionaries for easy DataFrame creation\n",
    "    output_records = []\n",
    "\n",
    "    # Iterate through each sequence in the batch\n",
    "    for seq_idx in range(X_train_np.shape[0]):\n",
    "        # Find indices that are not padding (mask is 1)\n",
    "        valid_mask = mask_train_np[seq_idx] == 1\n",
    "        valid_indices = np.where(valid_mask)[0]\n",
    "\n",
    "        # Get the original source IDs for this sequence\n",
    "        # sequences_sourceids contains source IDs for steps *after* START token\n",
    "        safe_sourceids = sequences_sourceids[seq_idx] if seq_idx < len(sequences_sourceids) else []\n",
    "\n",
    "        step_counter = 1 # Initialize step counter for this sequence (starts from 1 for the first event)\n",
    "\n",
    "        # Iterate through the valid indices within this sequence\n",
    "        # valid_indices corresponds to positions in the padded sequence where mask is 1\n",
    "        # valid_idx = 0 corresponds to the START token input\n",
    "        # valid_idx = 1 corresponds to the first event input, etc.\n",
    "        for i in range(len(valid_indices)):\n",
    "            valid_idx = valid_indices[i] # The actual index in the padded sequence\n",
    "\n",
    "            # We want to output predictions for each *event* step, not the START token step.\n",
    "            # The predictions (proportions, increments, cumulative) at valid_idx\n",
    "            # correspond to the time *until* the event at that position (relative to the previous event for increments,\n",
    "            # or relative to the start for cumulative).\n",
    "            # The SourceID at step 'k' (1-indexed) corresponds to the input token at index 'k' in the original sequence,\n",
    "            # which is index 'k' in the padded input X_train, and index 'k-1' in the original sourceids list.\n",
    "            # The predictions at index `valid_idx` relate to the event *after* the token at `valid_idx`.\n",
    "            # So, prediction at `valid_idx` corresponds to the event with SourceID `safe_sourceids[valid_idx]`.\n",
    "\n",
    "            # Check if this index corresponds to an actual event (not the START token)\n",
    "            # The START token is at index 0 in the padded input.\n",
    "            # The first event's input is at index 1, second at index 2, etc.\n",
    "            # The predictions at index `j` correspond to the time *until* the event represented by the input token at index `j`.\n",
    "            # So, pred at index `j` corresponds to SourceID at `safe_sourceids[j-1]`.\n",
    "            # The valid_idx here is the index in the padded sequence.\n",
    "\n",
    "            # Let's align predictions with the event they predict the time *until*.\n",
    "            # Prediction at index `i` in padded sequence (where input is token `i`)\n",
    "            # predicts time until event `i`. Event `i` has SourceID `safe_sourceids[i-1]`.\n",
    "            # We should iterate through the *events*, which correspond to indices 1 onwards in the padded sequence.\n",
    "\n",
    "            # Iterate through the valid event indices (skip the START token at index 0)\n",
    "            if valid_idx > 0:\n",
    "                # The source ID for the event predicted at valid_idx is the one at index valid_idx - 1\n",
    "                source_id_index = valid_idx - 1\n",
    "\n",
    "                # Get the corresponding source ID safely\n",
    "                if source_id_index < len(safe_sourceids):\n",
    "                    source_id = safe_sourceids[source_id_index]\n",
    "                else:\n",
    "                    # This case indicates a potential mismatch or issue elsewhere\n",
    "                    source_id = f'Unknown_Mapping_Error_seq_{seq_idx}_idx_{source_id_index}'\n",
    "                    print(f\"Warning: Source ID index {source_id_index} out of bounds for sequence {seq_idx} with length {len(safe_sourceids)}\")\n",
    "\n",
    "                # Append record for this event step\n",
    "                output_records.append({\n",
    "                    'Sequence': seq_idx,\n",
    "                    'Step': step_counter, # Use the dedicated counter for event steps\n",
    "                    'SourceID': source_id,\n",
    "                    'Predicted_Proportion': proportions_pred_np[seq_idx, valid_idx],\n",
    "                    'Predicted_Increment': increments_pred_np[seq_idx, valid_idx],\n",
    "                    'Predicted_Cumulative': cumulative_pred_np[seq_idx, valid_idx],\n",
    "                    'GroundTruth_Increment': gt_increments[seq_idx, valid_idx],\n",
    "                    'GroundTruth_Cumulative': Y_cum_target_np[seq_idx, valid_idx]\n",
    "                })\n",
    "\n",
    "                step_counter += 1 # Increment step counter only for actual events added\n",
    "\n",
    "    # Create DataFrame from the collected records\n",
    "    if not output_records:\n",
    "        print(\"Warning: No valid prediction records generated.\")\n",
    "        predictions_df = pd.DataFrame(columns=[\n",
    "            'Sequence', 'Step', 'SourceID', 'Predicted_Proportion',\n",
    "            'Predicted_Increment', 'Predicted_Cumulative',\n",
    "            'GroundTruth_Increment', 'GroundTruth_Cumulative'\n",
    "        ])\n",
    "    else:\n",
    "        predictions_df = pd.DataFrame(output_records)\n",
    "\n",
    "    # Save the DataFrame to CSV\n",
    "    output_csv_path = 'predictions_transformer_175974.csv'\n",
    "    try:\n",
    "        predictions_df.to_csv(output_csv_path, index=False)\n",
    "        print(f\"Predictions saved successfully to {output_csv_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving predictions to CSV: {e}\")\n",
    "\n",
    "    return predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from data/182625/encoded_182625_condensed.csv...\n",
      "Loaded 1 sequences.\n",
      "Padding sequences to max length: 3620\n",
      "Prepared 1 sequences for training.\n",
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lukis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'query' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lukis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'key' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lukis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'value' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lukis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'causal_self_attention_12' (of type CausalSelfAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lukis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'sequential_12' (of type Sequential) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lukis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'feed_forward_12' (of type FeedForward) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lukis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'self_attention_feed_forward_layer_12' (of type SelfAttentionFeedForwardLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lukis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'causal_self_attention_13' (of type CausalSelfAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lukis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'sequential_13' (of type Sequential) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lukis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'feed_forward_13' (of type FeedForward) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lukis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'self_attention_feed_forward_layer_13' (of type SelfAttentionFeedForwardLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lukis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'causal_self_attention_14' (of type CausalSelfAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lukis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'sequential_14' (of type Sequential) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lukis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'feed_forward_14' (of type FeedForward) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lukis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'self_attention_feed_forward_layer_14' (of type SelfAttentionFeedForwardLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 - Total Loss: 20100.2363 - Proportion Loss: 20100.2363\n",
      "Epoch 2/50 - Total Loss: 20100.2246 - Proportion Loss: 20100.2246\n",
      "Epoch 3/50 - Total Loss: 20100.2207 - Proportion Loss: 20100.2207\n",
      "Epoch 4/50 - Total Loss: 20100.2148 - Proportion Loss: 20100.2148\n",
      "Epoch 5/50 - Total Loss: 20100.1973 - Proportion Loss: 20100.1973\n",
      "Epoch 6/50 - Total Loss: 20100.1348 - Proportion Loss: 20100.1348\n",
      "Epoch 7/50 - Total Loss: 20099.9785 - Proportion Loss: 20099.9785\n",
      "Epoch 8/50 - Total Loss: 20099.8047 - Proportion Loss: 20099.8047\n",
      "Epoch 9/50 - Total Loss: 20099.7695 - Proportion Loss: 20099.7695\n",
      "Epoch 10/50 - Total Loss: 20099.7441 - Proportion Loss: 20099.7441\n",
      "Epoch 11/50 - Total Loss: 20099.7441 - Proportion Loss: 20099.7441\n",
      "Epoch 12/50 - Total Loss: 20099.7441 - Proportion Loss: 20099.7441\n",
      "Epoch 13/50 - Total Loss: 20099.7383 - Proportion Loss: 20099.7383\n",
      "Epoch 14/50 - Total Loss: 20099.7383 - Proportion Loss: 20099.7383\n",
      "Epoch 15/50 - Total Loss: 20099.7383 - Proportion Loss: 20099.7383\n",
      "Epoch 16/50 - Total Loss: 20099.7383 - Proportion Loss: 20099.7383\n",
      "Epoch 17/50 - Total Loss: 20099.7383 - Proportion Loss: 20099.7383\n",
      "Epoch 18/50 - Total Loss: 20099.7383 - Proportion Loss: 20099.7383\n",
      "Epoch 19/50 - Total Loss: 20099.7383 - Proportion Loss: 20099.7383\n",
      "Epoch 20/50 - Total Loss: 20099.7383 - Proportion Loss: 20099.7383\n",
      "Epoch 21/50 - Total Loss: 20099.7383 - Proportion Loss: 20099.7383\n",
      "Epoch 22/50 - Total Loss: 20099.7383 - Proportion Loss: 20099.7383\n",
      "Epoch 23/50 - Total Loss: 20099.7383 - Proportion Loss: 20099.7383\n",
      "Epoch 24/50 - Total Loss: 20099.7383 - Proportion Loss: 20099.7383\n",
      "Epoch 25/50 - Total Loss: 20099.7383 - Proportion Loss: 20099.7383\n",
      "Epoch 26/50 - Total Loss: 20099.7383 - Proportion Loss: 20099.7383\n",
      "Epoch 27/50 - Total Loss: 20099.7383 - Proportion Loss: 20099.7383\n",
      "Epoch 28/50 - Total Loss: 20099.7383 - Proportion Loss: 20099.7383\n",
      "Epoch 29/50 - Total Loss: 20099.7383 - Proportion Loss: 20099.7383\n",
      "Epoch 30/50 - Total Loss: 20099.7383 - Proportion Loss: 20099.7383\n",
      "Epoch 31/50 - Total Loss: 20099.7383 - Proportion Loss: 20099.7383\n",
      "Epoch 32/50 - Total Loss: 20099.7383 - Proportion Loss: 20099.7383\n",
      "Epoch 33/50 - Total Loss: 20099.7383 - Proportion Loss: 20099.7383\n",
      "Epoch 34/50 - Total Loss: 20099.7383 - Proportion Loss: 20099.7383\n",
      "Epoch 35/50 - Total Loss: 20099.7383 - Proportion Loss: 20099.7383\n",
      "Epoch 36/50 - Total Loss: 20099.7383 - Proportion Loss: 20099.7383\n",
      "Epoch 37/50 - Total Loss: 20099.7383 - Proportion Loss: 20099.7383\n",
      "Epoch 38/50 - Total Loss: 20099.7383 - Proportion Loss: 20099.7383\n",
      "Epoch 39/50 - Total Loss: 20099.7383 - Proportion Loss: 20099.7383\n",
      "Epoch 40/50 - Total Loss: 20099.7383 - Proportion Loss: 20099.7383\n",
      "Epoch 41/50 - Total Loss: 20099.7383 - Proportion Loss: 20099.7383\n",
      "Epoch 42/50 - Total Loss: 20099.7383 - Proportion Loss: 20099.7383\n",
      "Epoch 43/50 - Total Loss: 20099.7383 - Proportion Loss: 20099.7383\n",
      "Epoch 44/50 - Total Loss: 20099.7383 - Proportion Loss: 20099.7383\n",
      "Epoch 45/50 - Total Loss: 20099.7383 - Proportion Loss: 20099.7383\n",
      "Epoch 46/50 - Total Loss: 20099.7383 - Proportion Loss: 20099.7383\n",
      "Epoch 47/50 - Total Loss: 20099.7383 - Proportion Loss: 20099.7383\n",
      "Epoch 48/50 - Total Loss: 20099.7383 - Proportion Loss: 20099.7383\n",
      "Epoch 49/50 - Total Loss: 20099.7383 - Proportion Loss: 20099.7383\n",
      "Epoch 50/50 - Total Loss: 20099.7383 - Proportion Loss: 20099.7383\n",
      "Training finished.\n",
      "Generating predictions...\n",
      "Predictions saved successfully to predictions_transformer_175974.csv\n",
      "\n",
      "Sample Predictions:\n",
      "   Sequence  Step     SourceID  Predicted_Proportion  Predicted_Increment  \\\n",
      "0         0     1  MRI_MSR_104          4.262938e-09             0.000005   \n",
      "1         0     2    MRI_FRR_2          5.174918e-09             0.000006   \n",
      "2         0     3  MRI_FRR_257          5.419762e-09             0.000007   \n",
      "3         0     4  MRI_FRR_264          5.250349e-09             0.000007   \n",
      "4         0     5  MRI_FRR_264          4.851918e-09             0.000006   \n",
      "5         0     6   MRI_CCS_11          5.228364e-09             0.000006   \n",
      "6         0     7   MRI_CCS_11          4.701654e-09             0.000006   \n",
      "7         0     8  MRI_FRR_257          4.157806e-09             0.000005   \n",
      "8         0     9  MRI_FRR_264          3.595428e-09             0.000004   \n",
      "9         0    10  MRI_FRR_264          3.562083e-09             0.000004   \n",
      "\n",
      "   Predicted_Cumulative  GroundTruth_Increment  GroundTruth_Cumulative  \n",
      "0              0.000010                   40.0                    40.0  \n",
      "1              0.000017                    5.0                    45.0  \n",
      "2              0.000023                    7.0                    52.0  \n",
      "3              0.000030                   16.0                    68.0  \n",
      "4              0.000036                    9.0                    77.0  \n",
      "5              0.000043                    6.0                    83.0  \n",
      "6              0.000048                  130.0                   213.0  \n",
      "7              0.000054                    1.0                   214.0  \n",
      "8              0.000058                   10.0                   224.0  \n",
      "9              0.000062                    2.0                   226.0  \n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to run the training and prediction process.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Replace with your actual file path\n",
    "        data_file = \"data/182625/encoded_182625_condensed.csv\"\n",
    "        # Check if the data file exists\n",
    "        if not os.path.exists(data_file):\n",
    "            print(f\"Error: Data file not found at {data_file}\")\n",
    "            print(\"Please ensure the data file is in the correct location.\")\n",
    "            return\n",
    "\n",
    "        # Train model and get results\n",
    "        model, X_train, Y_cum_target, mask_train, total_times, sequences_sourceids = train_transformer(data_file)\n",
    "\n",
    "        if model is None:\n",
    "            print(\"Model training failed or no data was available. Exiting.\")\n",
    "            return\n",
    "\n",
    "        # Generate predictions CSV\n",
    "        predictions_df = generate_predictions_csv(\n",
    "            model, X_train, Y_cum_target, mask_train, total_times, sequences_sourceids\n",
    "        )\n",
    "\n",
    "        if not predictions_df.empty:\n",
    "            print(\"\\nSample Predictions:\")\n",
    "            print(predictions_df.head(10))\n",
    "        else:\n",
    "            print(\"\\nNo predictions were generated.\")\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in main: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Ensure TensorFlow is using eager execution (usually default)\n",
    "    # tf.config.run_functions_eagerly(True) # Uncomment for easier debugging if needed\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
