{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Constants and Configuration ---\n",
    "\n",
    "# The maximum number of steps we'll consider in a single sequence.\n",
    "# Sequences longer than this will be truncated, shorter ones will be padded.\n",
    "MAX_SEQ_LEN = 128\n",
    "\n",
    "# The features from the CSV file that the model will use as input.\n",
    "FEATURE_COLUMNS = [\n",
    "    'sourceID', 'PTAB', 'BodyGroup_from', 'BodyGroup_to',\n",
    "    'Position_encoded', 'Direction_encoded'\n",
    "]\n",
    "\n",
    "# --- 2. Data Loading and Preprocessing ---\n",
    "\n",
    "def load_and_preprocess_data(file_path):\n",
    "    \"\"\"\n",
    "    Loads data, calculates time proportions, and groups it into sequences.\n",
    "    This function returns unpadded lists of sequences.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"❌ Error: Data file not found at '{file_path}'\")\n",
    "        return None, None, None\n",
    "\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # --- Calculate Time Proportions (The Target Variable) ---\n",
    "    df['total_time'] = df.groupby('SeqOrder')['timediff'].transform('sum')\n",
    "    df['time_proportion'] = df['timediff'] / (df['total_time'] + 1e-9)\n",
    "\n",
    "    # Group data by sequence\n",
    "    grouped = df.groupby('SeqOrder')\n",
    "    sequences = []\n",
    "    proportions = []\n",
    "    \n",
    "    print(f\"Processing {len(grouped)} sequences...\")\n",
    "\n",
    "    for _, group in grouped:\n",
    "        seq_features = group[FEATURE_COLUMNS].values\n",
    "        seq_proportions = group['time_proportion'].values.reshape(-1, 1)\n",
    "        sequences.append(seq_features)\n",
    "        proportions.append(seq_proportions)\n",
    "\n",
    "    return sequences, proportions, df\n",
    "\n",
    "# --- 3. Transformer Model Architecture ---\n",
    "\n",
    "class PositionalEmbedding(layers.Layer):\n",
    "    \"\"\"Adds positional information to the input embeddings.\"\"\"\n",
    "    def __init__(self, max_len, embed_dim):\n",
    "        super(PositionalEmbedding, self).__init__()\n",
    "        self.pos_encoding = self.positional_encoding(max_len, embed_dim)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        return config\n",
    "\n",
    "    def positional_encoding(self, max_len, embed_dim):\n",
    "        pos = np.arange(max_len)[:, np.newaxis]\n",
    "        i = np.arange(embed_dim)[np.newaxis, :]\n",
    "        angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(embed_dim))\n",
    "        angle_rads = pos * angle_rates\n",
    "        angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "        angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "        pos_encoding = angle_rads[np.newaxis, ...]\n",
    "        return tf.cast(pos_encoding, dtype=tf.float32)\n",
    "\n",
    "    def call(self, x):\n",
    "        return x + self.pos_encoding[:, :tf.shape(x)[1], :]\n",
    "\n",
    "class TransformerEncoder(layers.Layer):\n",
    "    \"\"\"Transformer Encoder Block.\"\"\"\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerEncoder, self).__init__()\n",
    "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = tf.keras.Sequential([\n",
    "            layers.Dense(ff_dim, activation=\"relu\"),\n",
    "            layers.Dense(embed_dim),\n",
    "        ])\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        return config\n",
    "\n",
    "    def call(self, inputs, training=False, mask=None):\n",
    "        # The attention layer will use the mask to ignore padded inputs\n",
    "        attn_output = self.att(inputs, inputs, attention_mask=mask)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "def build_transformer_model(input_shape, num_heads=4, ff_dim=32, embed_dim=32, num_transformer_blocks=2):\n",
    "    \"\"\"Builds the Transformer model for proportion prediction.\"\"\"\n",
    "    num_features = input_shape[-1]\n",
    "    \n",
    "    inputs = layers.Input(shape=(None, num_features))\n",
    "    \n",
    "    # This layer creates a mask that is passed to all subsequent layers.\n",
    "    # It masks timesteps where all features are 0 (our padding value).\n",
    "    masking_layer = layers.Masking(mask_value=0.)(inputs)\n",
    "    \n",
    "    dense_proj = layers.Dense(embed_dim, activation=\"relu\")(masking_layer)\n",
    "    x = PositionalEmbedding(max_len=MAX_SEQ_LEN, embed_dim=embed_dim)(dense_proj)\n",
    "    \n",
    "    for _ in range(num_transformer_blocks):\n",
    "        x = TransformerEncoder(embed_dim, num_heads, ff_dim)(x)\n",
    "        \n",
    "    time_step_logits = layers.Dense(1, name=\"time_step_logits\")(x)\n",
    "    proportions_output = layers.Softmax(axis=1, name=\"proportions_output\")(time_step_logits)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=inputs, outputs=proportions_output)\n",
    "    return model\n",
    "\n",
    "# --- 4. Custom Loss Function ---\n",
    "\n",
    "def asymmetric_mse(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Custom Mean Squared Error loss function that penalizes underestimation more heavily.\n",
    "    \"\"\"\n",
    "    error = y_true - y_pred\n",
    "    is_underestimation = error > 0\n",
    "    penalty_weight = 10.0\n",
    "    loss = tf.where(is_underestimation, penalty_weight * tf.square(error), tf.square(error))\n",
    "    mask = tf.cast(tf.not_equal(y_true, 0), dtype=tf.float32)\n",
    "    loss *= mask\n",
    "    return tf.reduce_sum(loss) / tf.reduce_sum(mask)\n",
    "\n",
    "\n",
    "# --- 5. Training and Prediction Orchestration ---\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to run the data processing, training, and prediction.\"\"\"\n",
    "    \n",
    "    data_file = 'data/176401/encoded_176401_condensed.csv'\n",
    "    output_predictions_file = 'prediction_176401_proportions.csv'\n",
    "    \n",
    "    sequences, proportions, original_df = load_and_preprocess_data(data_file)\n",
    "    if sequences is None:\n",
    "        return\n",
    "\n",
    "    # --- Prepare data for training and prediction ---\n",
    "    sequence_indices = np.arange(len(sequences))\n",
    "    train_indices, val_indices = train_test_split(sequence_indices, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Create training and validation sets for model fitting\n",
    "    X_train_unpadded = [sequences[i] for i in train_indices]\n",
    "    y_train_unpadded = [proportions[i] for i in train_indices]\n",
    "    X_val_unpadded = [sequences[i] for i in val_indices]\n",
    "    y_val_unpadded = [proportions[i] for i in val_indices]\n",
    "\n",
    "    X_train = tf.keras.preprocessing.sequence.pad_sequences(X_train_unpadded, maxlen=MAX_SEQ_LEN, padding='post', dtype='float32')\n",
    "    y_train = tf.keras.preprocessing.sequence.pad_sequences(y_train_unpadded, maxlen=MAX_SEQ_LEN, padding='post', dtype='float32')\n",
    "    X_val = tf.keras.preprocessing.sequence.pad_sequences(X_val_unpadded, maxlen=MAX_SEQ_LEN, padding='post', dtype='float32')\n",
    "    y_val = tf.keras.preprocessing.sequence.pad_sequences(y_val_unpadded, maxlen=MAX_SEQ_LEN, padding='post', dtype='float32')\n",
    "    \n",
    "    # Pad the entire dataset for final predictions after training\n",
    "    X_all_padded = tf.keras.preprocessing.sequence.pad_sequences(sequences, maxlen=MAX_SEQ_LEN, padding='post', dtype='float32')\n",
    "    \n",
    "    print(f\"\\nData shapes: X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "    print(f\"Data shapes: X_val: {X_val.shape}, y_val: {y_val.shape}\")\n",
    "\n",
    "    input_shape = X_train.shape[1:]\n",
    "    model = build_transformer_model(input_shape)\n",
    "    \n",
    "    model.compile(optimizer=\"adam\", loss=asymmetric_mse)\n",
    "    model.summary()\n",
    "    \n",
    "    print(\"\\n--- Starting Model Training ---\")\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=50,\n",
    "        batch_size=32,\n",
    "        callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)]\n",
    "    )\n",
    "    print(\"--- Model Training Finished ---\\n\")\n",
    "\n",
    "    # --- Generate Predictions for the ENTIRE Dataset ---\n",
    "    print(\"--- Generating predictions for the entire dataset ---\")\n",
    "    predictions = model.predict(X_all_padded)\n",
    "    \n",
    "    results = []\n",
    "    unique_seq_orders = original_df['SeqOrder'].unique()\n",
    "    \n",
    "    # Loop over all sequences to build the final results\n",
    "    for i, original_seq_index in enumerate(sequence_indices):\n",
    "        actual_len = len(sequences[original_seq_index])\n",
    "        seq_order_val = unique_seq_orders[original_seq_index]\n",
    "        \n",
    "        true_props = proportions[original_seq_index].flatten()\n",
    "        pred_props = predictions[i, :actual_len, 0]\n",
    "        \n",
    "        seq_data = original_df[original_df['SeqOrder'] == seq_order_val]\n",
    "        \n",
    "        for j in range(actual_len):\n",
    "            results.append({\n",
    "                'SeqOrder': seq_order_val,\n",
    "                'Step': j,\n",
    "                'sourceID': seq_data.iloc[j]['sourceID'],\n",
    "                'timediff': seq_data.iloc[j]['timediff'],\n",
    "                'true_proportion': true_props[j],\n",
    "                'predicted_proportion': pred_props[j]\n",
    "            })\n",
    "            \n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    # Sort the final results and save to CSV\n",
    "    results_df = results_df.sort_values(by=['SeqOrder', 'Step']).reset_index(drop=True)\n",
    "    results_df.to_csv(output_predictions_file, index=False)\n",
    "    print(f\"✅ Predictions for all sequences saved to '{output_predictions_file}'\")\n",
    "\n",
    "\n",
    "    print(\"\\n--- Sample of Predictions ---\")\n",
    "    print(results_df.head(20))\n",
    "\n",
    "    print(\"\\n--- Verifying Proportions Sum to 1 (for first 5 sequences) ---\")\n",
    "    print(results_df.groupby('SeqOrder')['predicted_proportion'].sum().head())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 35 sequences...\n",
      "\n",
      "Data shapes: X_train: (28, 128, 6), y_train: (28, 128, 1)\n",
      "Data shapes: X_val: (7, 128, 6), y_val: (7, 128, 1)\n",
      "WARNING:tensorflow:From C:\\Users\\lukis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:204: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lukis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'positional_embedding' (of type PositionalEmbedding) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ masking (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Masking</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ positional_embedding            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEmbedding</span>)           │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_encoder             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">19,040</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_encoder_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">19,040</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_step_logits (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ proportions_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Softmax</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ masking (\u001b[38;5;33mMasking\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │           \u001b[38;5;34m224\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ positional_embedding            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mPositionalEmbedding\u001b[0m)           │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_encoder             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │        \u001b[38;5;34m19,040\u001b[0m │\n",
       "│ (\u001b[38;5;33mTransformerEncoder\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_encoder_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │        \u001b[38;5;34m19,040\u001b[0m │\n",
       "│ (\u001b[38;5;33mTransformerEncoder\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_step_logits (\u001b[38;5;33mDense\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)        │            \u001b[38;5;34m33\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ proportions_output (\u001b[38;5;33mSoftmax\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">38,337</span> (149.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m38,337\u001b[0m (149.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">38,337</span> (149.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m38,337\u001b[0m (149.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Model Training ---\n",
      "Epoch 1/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step - loss: 0.0202 - val_loss: 0.0174\n",
      "Epoch 2/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0158 - val_loss: 0.0170\n",
      "Epoch 3/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0151 - val_loss: 0.0177\n",
      "Epoch 4/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0151 - val_loss: 0.0175\n",
      "Epoch 5/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0145 - val_loss: 0.0161\n",
      "Epoch 6/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0134 - val_loss: 0.0134\n",
      "Epoch 7/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0118 - val_loss: 0.0115\n",
      "Epoch 8/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0104 - val_loss: 0.0111\n",
      "Epoch 9/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0096 - val_loss: 0.0107\n",
      "Epoch 10/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0094 - val_loss: 0.0105\n",
      "Epoch 11/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0090 - val_loss: 0.0104\n",
      "Epoch 12/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0092 - val_loss: 0.0103\n",
      "Epoch 13/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0092 - val_loss: 0.0104\n",
      "Epoch 14/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0094 - val_loss: 0.0103\n",
      "Epoch 15/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0094 - val_loss: 0.0103\n",
      "Epoch 16/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0092 - val_loss: 0.0103\n",
      "Epoch 17/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0090 - val_loss: 0.0103\n",
      "Epoch 18/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0092 - val_loss: 0.0104\n",
      "Epoch 19/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0089 - val_loss: 0.0104\n",
      "Epoch 20/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0090 - val_loss: 0.0104\n",
      "Epoch 21/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0089 - val_loss: 0.0103\n",
      "--- Model Training Finished ---\n",
      "\n",
      "--- Generating predictions for the entire dataset ---\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 390ms/step\n",
      "✅ Predictions for all sequences saved to 'prediction_176401_proportions.csv'\n",
      "\n",
      "--- Sample of Predictions ---\n",
      "    SeqOrder  Step  sourceID  timediff  true_proportion  predicted_proportion\n",
      "0          0     0        11         0         0.000000              0.045209\n",
      "1          0     1         4         4         0.000850              0.032027\n",
      "2          0     2         5        13         0.002763              0.032027\n",
      "3          0     3         5        14         0.002976              0.032027\n",
      "4          0     4         5        28         0.005951              0.032027\n",
      "5          0     5         0        28         0.005951              0.032027\n",
      "6          0     6         1        36         0.007651              0.032027\n",
      "7          0     7         1        45         0.009564              0.032027\n",
      "8          0     8         1       106         0.022529              0.032027\n",
      "9          0     9         5       140         0.029756              0.032027\n",
      "10         0    10         1       195         0.041445              0.032027\n",
      "11         0    11         4       269         0.057173              0.053309\n",
      "12         0    12         5       270         0.057386              0.053309\n",
      "13         0    13         5       276         0.058661              0.053309\n",
      "14         0    14         4       276         0.058661              0.037994\n",
      "15         0    15         5       278         0.059086              0.037994\n",
      "16         0    16         0       279         0.059299              0.037994\n",
      "17         0    17         8       279         0.059299              0.037994\n",
      "18         0    18         4       279         0.059299              0.037543\n",
      "19         0    19         5       285         0.060574              0.037543\n",
      "\n",
      "--- Verifying Proportions Sum to 1 (for first 5 sequences) ---\n",
      "SeqOrder\n",
      "0    0.940182\n",
      "1    0.923861\n",
      "2    0.957926\n",
      "3    0.943743\n",
      "4    0.961507\n",
      "Name: predicted_proportion, dtype: float32\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
