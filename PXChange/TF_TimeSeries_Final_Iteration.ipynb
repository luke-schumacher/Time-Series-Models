{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Constants and Configuration ---\n",
    "\n",
    "# The maximum number of steps we'll consider in a single sequence.\n",
    "# Sequences longer than this will be truncated, shorter ones will be padded.\n",
    "MAX_SEQ_LEN = 128\n",
    "\n",
    "# The features from the CSV file that the model will use as input.\n",
    "FEATURE_COLUMNS = [\n",
    "    'sourceID', 'PTAB', 'BodyGroup_from', 'BodyGroup_to',\n",
    "    'Position_encoded', 'Direction_encoded'\n",
    "]\n",
    "\n",
    "\n",
    "# --- 2. Data Loading and Preprocessing (Corrected based on new rules) ---\n",
    "\n",
    "def load_and_preprocess_data(file_path):\n",
    "    \"\"\"\n",
    "    Loads data with cumulative timestamps, calculates individual step durations and time \n",
    "    proportions based on specific sequence rules, and groups the data into sequences.\n",
    "    This version PRESERVES the original file order to respect the cumulative timediff logic.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"❌ Error: Data file not found at '{file_path}'\")\n",
    "        return None, None, None\n",
    "\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # --- Correctly Calculate Step Durations and Proportions ---\n",
    "    \n",
    "    # DO NOT sort the dataframe. The original order is crucial for the cumulative timediff logic.\n",
    "    \n",
    "    # Robustly create the 'Step' column in case it doesn't exist.\n",
    "    df['Step'] = df.groupby('SeqOrder').cumcount()\n",
    "    \n",
    "    # Rule 1: Create a new 'step_duration' column. This is the true time difference for each step.\n",
    "    # It's calculated by taking the difference from the previous cumulative 'timediff'.\n",
    "    df['step_duration'] = df.groupby('SeqOrder')['timediff'].diff().fillna(df['timediff'])\n",
    "    # Ensure no negative durations, which can happen if a timer resets.\n",
    "    df['step_duration'] = df['step_duration'].clip(lower=0)\n",
    "    \n",
    "    # Rule 2: The business logic states the FIRST step with sourceID == 10 is the true end marker.\n",
    "    # Find the step number of this marker for each sequence.\n",
    "    end_marker_step = df[df['sourceID'] == 10].groupby('SeqOrder')['Step'].first()\n",
    "    df['end_marker_step'] = df['SeqOrder'].map(end_marker_step)\n",
    "\n",
    "    # Any step AFTER the end marker is considered post-sequence and should have a duration of 0.\n",
    "    df.loc[df['Step'] > df['end_marker_step'], 'step_duration'] = 0\n",
    "\n",
    "    # Rule 3: The total time for the sequence (the denominator for proportions) is the SUM\n",
    "    # of all the now-corrected step durations. This ensures the proportions sum to 1.\n",
    "    df['total_time'] = df.groupby('SeqOrder')['step_duration'].transform('sum')\n",
    "\n",
    "    # Rule 4: Calculate the final, correct proportion using the correct step duration and total time.\n",
    "    # This ensures the target proportions for each sequence are valid and based on the rules.\n",
    "    df['true_proportion'] = df['step_duration'] / (df['total_time'] + 1e-9)\n",
    "\n",
    "\n",
    "    # Group data by sequence for the model\n",
    "    grouped = df.groupby('SeqOrder')\n",
    "    sequences = []\n",
    "    proportions = []\n",
    "    \n",
    "    print(f\"Processing {len(grouped)} sequences...\")\n",
    "\n",
    "    for _, group in grouped:\n",
    "        seq_features = group[FEATURE_COLUMNS].values\n",
    "        seq_proportions = group['true_proportion'].values.reshape(-1, 1)\n",
    "        \n",
    "        sequences.append(seq_features)\n",
    "        proportions.append(seq_proportions)\n",
    "\n",
    "    # Return the processed dataframe for creating the final output file\n",
    "    return sequences, proportions, df\n",
    "\n",
    "\n",
    "# --- 3. Transformer Model Architecture ---\n",
    "\n",
    "class PositionalEmbedding(layers.Layer):\n",
    "    \"\"\"Adds positional information to the input embeddings.\"\"\"\n",
    "    def __init__(self, max_len, embed_dim):\n",
    "        super(PositionalEmbedding, self).__init__()\n",
    "        self.pos_encoding = self.positional_encoding(max_len, embed_dim)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'max_len': self.pos_encoding.shape[1],\n",
    "            'embed_dim': self.pos_encoding.shape[2]\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def positional_encoding(self, max_len, embed_dim):\n",
    "        pos = np.arange(max_len)[:, np.newaxis]\n",
    "        i = np.arange(embed_dim)[np.newaxis, :]\n",
    "        angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(embed_dim))\n",
    "        angle_rads = pos * angle_rates\n",
    "        angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "        angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "        pos_encoding = angle_rads[np.newaxis, ...]\n",
    "        return tf.cast(pos_encoding, dtype=tf.float32)\n",
    "\n",
    "    def call(self, x):\n",
    "        return x + self.pos_encoding[:, :tf.shape(x)[1], :]\n",
    "\n",
    "class TransformerEncoder(layers.Layer):\n",
    "    \"\"\"Transformer Encoder Block.\"\"\"\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerEncoder, self).__init__()\n",
    "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = tf.keras.Sequential([\n",
    "            layers.Dense(ff_dim, activation=\"relu\"),\n",
    "            layers.Dense(embed_dim),\n",
    "        ])\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'embed_dim': self.att.key_dim,\n",
    "            'num_heads': self.att.num_heads,\n",
    "            'ff_dim': self.ffn.layers[0].units,\n",
    "            'rate': self.dropout1.rate\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        # The mask is implicitly passed through the layers.\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "class MaskedSoftmax(layers.Layer):\n",
    "    \"\"\"Applies softmax activation while respecting the mask.\"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super(MaskedSoftmax, self).__init__(**kwargs)\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        if mask is None:\n",
    "            return tf.keras.activations.softmax(inputs, axis=1)\n",
    "\n",
    "        # Expand mask dimensions to match inputs\n",
    "        mask = tf.expand_dims(mask, -1)\n",
    "        \n",
    "        # Set logits for masked steps to a large negative number\n",
    "        masked_inputs = tf.where(mask, inputs, -1e9)\n",
    "        \n",
    "        return tf.keras.activations.softmax(masked_inputs, axis=1)\n",
    "        \n",
    "def build_transformer_model(input_shape, num_heads=4, ff_dim=32, embed_dim=32, num_transformer_blocks=2):\n",
    "    \"\"\"\n",
    "    Builds the single-output Transformer model for proportion prediction.\n",
    "    \"\"\"\n",
    "    num_features = input_shape[-1]\n",
    "    \n",
    "    inputs = layers.Input(shape=(None, num_features), name=\"input_features\")\n",
    "    \n",
    "    # This layer creates a mask that is passed to all subsequent layers.\n",
    "    # It masks timesteps where all features are 0 (our padding value).\n",
    "    masking_layer = layers.Masking(mask_value=0.)(inputs)\n",
    "    \n",
    "    dense_proj = layers.Dense(embed_dim, activation=\"relu\")(masking_layer)\n",
    "    x = PositionalEmbedding(max_len=MAX_SEQ_LEN, embed_dim=embed_dim)(dense_proj)\n",
    "    \n",
    "    for _ in range(num_transformer_blocks):\n",
    "        x = TransformerEncoder(embed_dim, num_heads, ff_dim)(x)\n",
    "    \n",
    "    # --- Output Branch: Proportions ---\n",
    "    time_step_logits = layers.Dense(1, name=\"time_step_logits\")(x)\n",
    "    proportions_output = MaskedSoftmax(name=\"proportions_output\")(time_step_logits)\n",
    "    \n",
    "    model = tf.keras.Model(\n",
    "        inputs=inputs, \n",
    "        outputs=proportions_output\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "# --- 4. Training and Prediction Orchestration ---\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to run the data processing, training, and prediction.\"\"\"\n",
    "    \n",
    "    data_file = 'data/176401/encoded_176401_condensed_full.csv'\n",
    "    output_predictions_file = 'prediction_176401_proportions_final_all.csv'\n",
    "    \n",
    "    sequences, proportions, processed_df = load_and_preprocess_data(data_file)\n",
    "    if sequences is None:\n",
    "        return\n",
    "\n",
    "    # --- Prepare data for training and prediction ---\n",
    "    sequence_indices = np.arange(len(sequences))\n",
    "    train_indices, val_indices = train_test_split(sequence_indices, test_size=0.2, random_state=42)\n",
    "\n",
    "    X_train_unpadded = [sequences[i] for i in train_indices]\n",
    "    y_prop_train_unpadded = [proportions[i] for i in train_indices]\n",
    "    \n",
    "    X_val_unpadded = [sequences[i] for i in val_indices]\n",
    "    y_prop_val_unpadded = [proportions[i] for i in val_indices]\n",
    "\n",
    "    X_train = tf.keras.preprocessing.sequence.pad_sequences(X_train_unpadded, maxlen=MAX_SEQ_LEN, padding='post', dtype='float32')\n",
    "    y_prop_train = tf.keras.preprocessing.sequence.pad_sequences(y_prop_train_unpadded, maxlen=MAX_SEQ_LEN, padding='post', dtype='float32')\n",
    "    X_val = tf.keras.preprocessing.sequence.pad_sequences(X_val_unpadded, maxlen=MAX_SEQ_LEN, padding='post', dtype='float32')\n",
    "    y_prop_val = tf.keras.preprocessing.sequence.pad_sequences(y_prop_val_unpadded, maxlen=MAX_SEQ_LEN, padding='post', dtype='float32')\n",
    "    \n",
    "    X_all_padded = tf.keras.preprocessing.sequence.pad_sequences(sequences, maxlen=MAX_SEQ_LEN, padding='post', dtype='float32')\n",
    "    \n",
    "    print(f\"\\nData shapes (Train): X={X_train.shape}, y_proportions={y_prop_train.shape}\")\n",
    "    print(f\"Data shapes (Val):   X={X_val.shape}, y_proportions={y_prop_val.shape}\")\n",
    "\n",
    "    input_shape = X_train.shape[1:]\n",
    "    model = build_transformer_model(input_shape)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=\"adam\", \n",
    "        loss=tf.keras.losses.KLDivergence()\n",
    "    )\n",
    "    model.summary()\n",
    "    \n",
    "    print(\"\\n--- Starting Model Training ---\")\n",
    "    model.fit(\n",
    "        X_train, \n",
    "        y_prop_train,\n",
    "        validation_data=(X_val, y_prop_val),\n",
    "        epochs=50,\n",
    "        batch_size=32,\n",
    "        callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)]\n",
    "    )\n",
    "    print(\"--- Model Training Finished ---\\n\")\n",
    "\n",
    "    # --- Generate Predictions and Create Final Output ---\n",
    "    print(\"--- Generating predictions for the entire dataset ---\")\n",
    "    pred_proportions_padded = model.predict(X_all_padded)\n",
    "    \n",
    "    # Add the predicted proportions back to the original dataframe for easy output generation\n",
    "    # First, create a placeholder column\n",
    "    processed_df['predicted_proportion'] = 0.0\n",
    "    \n",
    "    unique_seq_orders = processed_df['SeqOrder'].unique()\n",
    "    \n",
    "    for i, seq_order_val in enumerate(unique_seq_orders):\n",
    "        # Get the slice of the dataframe for the current sequence\n",
    "        seq_indices = processed_df[processed_df['SeqOrder'] == seq_order_val].index\n",
    "        actual_len = len(seq_indices)\n",
    "        \n",
    "        # Get the corresponding predictions\n",
    "        pred_props = pred_proportions_padded[i, :actual_len, 0]\n",
    "        \n",
    "        # Assign the predictions to the correct rows in the dataframe\n",
    "        processed_df.loc[seq_indices, 'predicted_proportion'] = pred_props\n",
    "            \n",
    "    # Select and order columns for the final output file for clarity and verification\n",
    "    output_columns = [\n",
    "        'SeqOrder',\n",
    "        'Step',\n",
    "        'sourceID',\n",
    "        'timediff', # Original cumulative timediff for verification\n",
    "        'step_duration', # The calculated individual step duration\n",
    "        'true_proportion',\n",
    "        'predicted_proportion'\n",
    "    ]\n",
    "    \n",
    "    final_df = processed_df[output_columns]\n",
    "\n",
    "    final_df.to_csv(output_predictions_file, index=False)\n",
    "    print(f\"✅ Predictions for all sequences saved to '{output_predictions_file}'\")\n",
    "\n",
    "    print(\"\\n--- Sample of Predictions ---\")\n",
    "    print(final_df.head(20))\n",
    "\n",
    "    print(\"\\n--- Verifying Predicted Proportions Sum to 1 (for first 5 sequences) ---\")\n",
    "    print(final_df.groupby('SeqOrder')['predicted_proportion'].sum().head())\n",
    "    \n",
    "    print(\"\\n--- Verifying True Proportions Sum to 1 (for first 5 sequences) ---\")\n",
    "    print(final_df.groupby('SeqOrder')['true_proportion'].sum().head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 223 sequences...\n",
      "\n",
      "Data shapes (Train): X=(178, 128, 6), y_proportions=(178, 128, 1)\n",
      "Data shapes (Val):   X=(45, 128, 6), y_proportions=(45, 128, 1)\n",
      "WARNING:tensorflow:From C:\\Users\\lukis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:204: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lukis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\layers\\layer.py:932: UserWarning: Layer 'positional_embedding' (of type PositionalEmbedding) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_features (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ masking (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Masking</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ positional_embedding            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEmbedding</span>)           │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_encoder             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">19,040</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_encoder_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">19,040</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_step_logits (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ proportions_output              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaskedSoftmax</span>)                 │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_features (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ masking (\u001b[38;5;33mMasking\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │           \u001b[38;5;34m224\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ positional_embedding            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mPositionalEmbedding\u001b[0m)           │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_encoder             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │        \u001b[38;5;34m19,040\u001b[0m │\n",
       "│ (\u001b[38;5;33mTransformerEncoder\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_encoder_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │        \u001b[38;5;34m19,040\u001b[0m │\n",
       "│ (\u001b[38;5;33mTransformerEncoder\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_step_logits (\u001b[38;5;33mDense\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)        │            \u001b[38;5;34m33\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ proportions_output              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mMaskedSoftmax\u001b[0m)                 │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">38,337</span> (149.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m38,337\u001b[0m (149.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">38,337</span> (149.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m38,337\u001b[0m (149.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Model Training ---\n",
      "Epoch 1/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 110ms/step - loss: 0.0244 - val_loss: 0.0133\n",
      "Epoch 2/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0150 - val_loss: 0.0118\n",
      "Epoch 3/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0131 - val_loss: 0.0130\n",
      "Epoch 4/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0144 - val_loss: 0.0128\n",
      "Epoch 5/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0134 - val_loss: 0.0126\n",
      "Epoch 6/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0132 - val_loss: 0.0126\n",
      "Epoch 7/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0135 - val_loss: 0.0127\n",
      "Epoch 8/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0132 - val_loss: 0.0111\n",
      "Epoch 9/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0118 - val_loss: 0.0102\n",
      "Epoch 10/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0110 - val_loss: 0.0096\n",
      "Epoch 11/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0110 - val_loss: 0.0095\n",
      "Epoch 12/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0106 - val_loss: 0.0093\n",
      "Epoch 13/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0103 - val_loss: 0.0093\n",
      "Epoch 14/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0103 - val_loss: 0.0094\n",
      "Epoch 15/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0098 - val_loss: 0.0093\n",
      "Epoch 16/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0099 - val_loss: 0.0093\n",
      "Epoch 17/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0099 - val_loss: 0.0092\n",
      "Epoch 18/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0098 - val_loss: 0.0095\n",
      "Epoch 19/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0098 - val_loss: 0.0097\n",
      "Epoch 20/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0099 - val_loss: 0.0092\n",
      "Epoch 21/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0100 - val_loss: 0.0092\n",
      "Epoch 22/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0098 - val_loss: 0.0093\n",
      "Epoch 23/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0101 - val_loss: 0.0093\n",
      "Epoch 24/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0100 - val_loss: 0.0092\n",
      "Epoch 25/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0094 - val_loss: 0.0092\n",
      "Epoch 26/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0094 - val_loss: 0.0092\n",
      "Epoch 27/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0095 - val_loss: 0.0092\n",
      "Epoch 28/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0097 - val_loss: 0.0092\n",
      "Epoch 29/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0095 - val_loss: 0.0092\n",
      "Epoch 30/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0094 - val_loss: 0.0092\n",
      "Epoch 31/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0095 - val_loss: 0.0092\n",
      "Epoch 32/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0095 - val_loss: 0.0092\n",
      "Epoch 33/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0098 - val_loss: 0.0092\n",
      "Epoch 34/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0095 - val_loss: 0.0092\n",
      "Epoch 35/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0105 - val_loss: 0.0092\n",
      "Epoch 36/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0097 - val_loss: 0.0093\n",
      "Epoch 37/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0099 - val_loss: 0.0093\n",
      "Epoch 38/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0097 - val_loss: 0.0094\n",
      "Epoch 39/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0097 - val_loss: 0.0095\n",
      "Epoch 40/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0100 - val_loss: 0.0094\n",
      "--- Model Training Finished ---\n",
      "\n",
      "--- Generating predictions for the entire dataset ---\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step\n",
      "✅ Predictions for all sequences saved to 'prediction_176401_proportions_final_all.csv'\n",
      "\n",
      "--- Sample of Predictions ---\n",
      "    SeqOrder  Step  sourceID  timediff  step_duration  true_proportion  \\\n",
      "0          0     0        11         0            0.0         0.000000   \n",
      "1          0     1         4         4            4.0         0.011799   \n",
      "2          0     2         5        13            9.0         0.026549   \n",
      "3          0     3         5        14            1.0         0.002950   \n",
      "4          0     4         5        28           14.0         0.041298   \n",
      "5          0     5         0        28            0.0         0.000000   \n",
      "6          0     6         1        36            8.0         0.023599   \n",
      "7          0     7         1        45            9.0         0.026549   \n",
      "8          0     8         1       106           61.0         0.179941   \n",
      "9          0     9         5       140           34.0         0.100295   \n",
      "10         0    10         1       195           55.0         0.162242   \n",
      "11         0    11         4       269           74.0         0.218289   \n",
      "12         0    12         5       270            1.0         0.002950   \n",
      "13         0    13         5       276            6.0         0.017699   \n",
      "14         0    14         4       276            0.0         0.000000   \n",
      "15         0    15         5       278            2.0         0.005900   \n",
      "16         0    16         0       279            1.0         0.002950   \n",
      "17         0    17         8       279            0.0         0.000000   \n",
      "18         0    18         4       279            0.0         0.000000   \n",
      "19         0    19         5       285            6.0         0.017699   \n",
      "\n",
      "    predicted_proportion  \n",
      "0               0.022637  \n",
      "1               0.050908  \n",
      "2               0.050908  \n",
      "3               0.050908  \n",
      "4               0.050908  \n",
      "5               0.050907  \n",
      "6               0.050907  \n",
      "7               0.050907  \n",
      "8               0.050907  \n",
      "9               0.050907  \n",
      "10              0.050907  \n",
      "11              0.030270  \n",
      "12              0.030270  \n",
      "13              0.030270  \n",
      "14              0.033662  \n",
      "15              0.033662  \n",
      "16              0.033662  \n",
      "17              0.033662  \n",
      "18              0.034597  \n",
      "19              0.034597  \n",
      "\n",
      "--- Verifying Predicted Proportions Sum to 1 (for first 5 sequences) ---\n",
      "SeqOrder\n",
      "0    0.999345\n",
      "1    0.999147\n",
      "2    0.999353\n",
      "3    0.999210\n",
      "4    0.999309\n",
      "Name: predicted_proportion, dtype: float64\n",
      "\n",
      "--- Verifying True Proportions Sum to 1 (for first 5 sequences) ---\n",
      "SeqOrder\n",
      "0    1.0\n",
      "1    1.0\n",
      "2    1.0\n",
      "3    1.0\n",
      "4    1.0\n",
      "Name: true_proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
